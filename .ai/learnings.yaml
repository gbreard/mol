# Proyecto: MOL - Monitor de Ofertas Laborales
# Claude Code lee esto AUTOMATICAMENTE al inicio de cada conversacion
# ACTUALIZAR SIEMPRE QUE HAYA UN CAMBIO SIGNIFICATIVO

# ============================================
# ESTADO ACTUAL DEL TRABAJO (LEER PRIMERO)
# ============================================
current_state:
  fecha_actualizacion: "2026-01-28 17:10"

  # Modelo de 3 Fases - ver docs/reference/ARQUITECTURA_3_FASES.md
  fase_actual: "presentacion"  # adquisicion | procesamiento | presentacion
  fase_detalle: "Dashboard con auth funcionando, 4 usuarios registrados, pendiente sync ofertas a Supabase"

  # Protección de Ofertas Validadas v2.0 (2026-01-20)
  proteccion_validadas:
    version: "2.0"
    estado: "ACTIVO - triggers instalados"
    ofertas_protegidas: 119
    capas:
      - "Query filtrada en export_validation_excel.py:476"
      - "Query filtrada en auto_validator.py:590"
      - "Error explícito en match_ofertas_v3.py:1368"
      - "Triggers BD: protect_validated_matching, protect_validated_status"
    scripts:
      verificar: "python scripts/check_validated_protection.py"
      desbloquear: "python scripts/admin_unlock_validated.py --ids X --motivo 'razón'"
    migracion: "migrations/016_protect_validated_offers.sql (aplicada)"

  clae_integration:
    estado: "Fase 3 completada - catálogo de empresas integrado"
    nomenclador: "config/clae_nomenclador.json (950 actividades)"
    keywords_map: "config/clae_keywords_map.json (v1.2 - 50 sectores directos)"
    empresas_catalogo: "config/empresas_catalogo.json (81 empleadores + 164 intermediarios)"
    migracion: "migrations/007,008,009 (CLAE + sector_confianza + es_intermediario)"
    postprocessor: "database/nlp_postprocessor.py - _classify_clae() + _lookup_empresa_catalogo()"
    validation_rules: "V16-V22 (CLAE + sector sospechoso)"
    resultados_110: "8 alta confianza (catálogo), 22 intermediarios flaggeados"
    proximo_paso: "Sync a Supabase con nuevas columnas"

  ofertas_bd: 13170  # Total en BD despues de scraping
  ofertas_validadas: 119  # Verificado con check_validated_protection.py
  estado_ofertas: "validado"  # Listas para produccion

  matching_version: "v3.4.2"
  matching_arquitectura: "ESCO-First - ESCO es target, ISCO derivado. Reglas GANAN sobre semantico."
  matching_cambios_v342:
    - "ESCO es el target primario, ISCO se deriva del catalogo"
    - "Reglas de negocio tienen PRIORIDAD sobre semantico"
    - "124/130 reglas con esco_label valido"
    - "Labels ESCO exactos del catalogo (no inventados)"
    - "Funcion _find_occupation_by_esco_label() para busqueda exacta"

  # Tracking de convergencia (v3.3.3)
  tracking_tables:
    ofertas_matching_history: "Historial de cada matching (no sobrescribe)"
    run_ofertas: "Relación run <-> ofertas procesadas"
    ofertas_nlp_history: "Versiones NLP por oferta (ya existía)"
    learning_history: "Eventos de aprendizaje del sistema (auto-sync)"
  tracking_views:
    v_ofertas_problematicas: "Ofertas con múltiples reprocesos matching"
    v_matching_timeline: "Historial completo por oferta"
    v_nlp_convergencia: "Versiones NLP por oferta"

  # Auto-sync de learnings.yaml + Reporte de Fases + Supabase (v2.1)
  auto_sync:
    enabled: true
    version: "2.1"
    script: "scripts/sync_learnings.py"
    hook_session_start: true  # .claude/settings.json configurado
    triggers:
      - "Al iniciar sesión Claude Code (SessionStart hook)"
      - "Al final de run_validated_pipeline.py"
    output_al_iniciar:
      - "Reporte de estado de las 3 fases"
      - "Métricas: ofertas, NLP, matching, validación, errores"
      - "Sugerencia automática de qué fase necesita atención"
    logica_sugerencia:
      prioridad_1: "Errores sin resolver en Fase 2"
      prioridad_2: "Ofertas pendientes validación > 50"
      prioridad_3: "Scraping desactualizado > 3 días"
      prioridad_4: "Ofertas pendientes sync a Supabase"
      prioridad_5: "Ofertas sin NLP > 100"
    # Colaboración via Supabase
    supabase_sync:
      enabled: true
      tabla: "sistema_estado"
      vista: "v_sistema_estado_actual"
      query_colaborador: "SELECT * FROM v_sistema_estado_actual"
      proposito: "Compañero puede ver estado de fases sin acceso local"
    campos_sincronizados:
      - "conteos.* ← config/*.json"
      - "estadisticas_actuales ← BD"
      - "learning_evolution ← BD"
    eventos_registrados: "learning_history table"

# ============================================
# CONTEOS OFICIALES (SINGLE SOURCE OF TRUTH)
# ============================================
# REGLA: Cuando se modifique un config, actualizar estos conteos.
# La documentación (CLAUDE.md, PIPELINE.md, etc.) referencia aquí.
conteos:
  reglas_negocio: 129  # config/matching_rules_business.json > reglas_forzar_isco (v2.6 actualizado 2026-01-16)
  reglas_validacion: 22  # config/validation_rules.json > reglas_validacion (V23 dual_decision agregada 2026-01-20)
  sinonimos_argentinos: 13  # config/sinonimos_argentinos_esco.json > ocupaciones_titulo
  empresas_catalogo: 247  # config/empresas_catalogo.json (81 empleadores + 164 intermediarios)
  skills_esco: 14257            # database/embeddings/esco_skills_full.json
  ocupaciones_esco: 3046        # database/embeddings/esco_occupations_full.json
  ultima_verificacion: 2026-01-28

  supabase:
    integrado: true
    url: "https://uywzoyhjjofsvvsrrnek.supabase.co"
    sync_script: "scripts/exports/sync_to_supabase.py"
    dashboard: "https://mol-nextjs.vercel.app/"

  esco_extraction:
    source: "RDF v1.2.0 local (D:/Trabajos en PY/EPH-ESCO/01_datos_originales)"
    ocupaciones: 3046
    skills: 14257
    categorias_skill: 889  # S, S1, S1.5, K, T
    relaciones_ocu_skill: 129004  # essential + optional
    cobertura_L1: "97.7%"  # skills con categoria L1

  ultimo_trabajo:
    - "Dashboard Fase 3: Sistema de usuarios completado"
    - "API /api/admin/users con service_role_key para listar/crear usuarios"
    - "Middleware corregido para permitir rutas API sin redirección"
    - "Flujo deploy Vercel actualizado con alias obligatorio"
    - "Usuarios creados (4 super_admin):"
    - "  - Gerardo Breard (gbreard@gmail.com)"
    - "  - Sergio Rodriguez (srodriguezunq@gmail.com)"
    - "  - David Trajtemberg (DTRAJTEM@trabajo.gob.ar)"
    - "  - Diego Schleser (DSCHLESE@trabajo.gob.ar)"

  proximo_paso: "Sincronizar ofertas validadas a Supabase para poblar dashboard"

  estadisticas_actuales:
    ofertas_validadas: 0  # validadas anteriormente
    ofertas_pendientes: 538  # nuevo lote procesado
    reglas_negocio: 129
    tasa_aprendizaje: "0.0% (0 reglas / 1 ofertas)"
    convergencia: "CONVERGIDO (tasa < 5%)"
    cobertura_reglas: "85% (81 reglas + 4 diccionario)"
    fallback_semantico: "15% (15 ofertas)"

  aprendizaje_proceso:
    problema: "Claude ejecutó matching sin NLP, improvisó pasos del pipeline"
    causa: "No distinguió entre EJECUTAR pipeline vs INVESTIGAR/DIAGNOSTICAR"
    solucion: "Sección en CLAUDE.md con reglas claras"
    reglas:
      - "EJECUTAR pipeline → SOLO scripts documentados"
      - "INVESTIGAR/DIAGNOSTICAR → queries manuales OK"
      - "CREAR REGLAS → necesita ver datos, queries OK"
    pregunta_clave: "¿Estoy EJECUTANDO o INVESTIGANDO?"

  # Métricas de evolución del aprendizaje
  learning_evolution:
    total_runs: 122
    ofertas_con_historial_nlp: 5474  # ofertas en ofertas_nlp_history
    ofertas_con_matching: 538  # ofertas distintas en ofertas_esco_matching

    # Distribución real de reprocesos (datos de ofertas_nlp_history)
    distribucion_reprocesos:
      convergieron_1_intento: 5308  # 97% - funcionaron de una
      necesitaron_2_intentos: 144   # 3%
      necesitaron_3_intentos: 11
      necesitaron_4_intentos: 6
      necesitaron_5_intentos: 4
      caso_mas_dificil: "2154549 Contador Auditoría (12 intentos)"

    reglas_inicio: 22  # 2026-01-13 baseline
    reglas_actual: 129
    reglas_agregadas: "+96 durante optimización"
    tasa_convergencia: "47% -> 27% -> 2.7% -> 7.5% -> 0%"
    estado: "CONVERGIDO (tasa = 0%)"
    matching_versiones: "3.2.3 -> 3.3.2"
    ultimo_run: "run_20260116_1831 (100 ofertas nuevas, 0 reglas nuevas)"

    # Sistema de Estados (v2.2)
    flujo_estados:
      umbral_convergencia: "5%"  # tasa < 5% = convergido
      estados_validos:
        - "optimizacion: Claude iterando, creando reglas"
        - "listo_validacion: Convergido, esperando humano"
        - "en_validacion: Humano revisando en Google Sheets"
        - "validado: Humano aprobó → producción"
        - "rechazado: Humano pidió más trabajo → volver a optimizar"
      flujo: "optimizacion → (check_convergence) → listo_validacion → (send_to_human) → en_validacion → (complete_validation) → validado"

    # Comandos
    comandos:
      ver_lotes: "python scripts/show_learning_evolution.py --batches"
      ver_diario: "python scripts/show_learning_evolution.py --daily"
      ver_timeline: "python scripts/show_learning_evolution.py"

    # Métodos RunTracker (v2.2)
    metodos_estado:
      check_convergence: "tracker.check_convergence(lote_id) - verifica tasa y actualiza estado"
      send_to_human: "tracker.send_to_human_validation(lote_id) - marca para revision humana"
      complete_validation: "tracker.complete_human_validation(lote_id, aprobado=True/False)"
      reopen_batch: "tracker.reopen_batch_for_optimization(lote_id) - si fue rechazado"
      get_state: "tracker.get_batch_state(lote_id) - estado actual con siguiente accion"

  integracion_completada:
    - "Supabase sync inicial: 110 ofertas + 1916 skills + 60 ocupaciones ESCO"
    - "skill_categorizer.py v2.0 - sin hardcoding, usa esco_skills_full.json"
    - "Cobertura L1/L2: 97.5% via esco_rdf directo"
    - "auto_validator.py funcional con 22 reglas (V01-V22)"
    - "esco_associations table = 129k relaciones (67k essential + 61k optional)"
    - "Catálogo de empresas integrado en pipeline NLP (sector alta confianza)"
    - "Intermediarios flaggeados (es_intermediario=1) para excluir de análisis por sector"

  problemas_conocidos:
    - "327 skills (2.3%) sin L1 - son top-level sin broader"
    - "Encoding scraping: algunos caracteres acentuados corruptos (Cordoba, Rio Negro)"

# ============================================
# ARCHIVOS CLAVE (no buscar, usar estos)
# ============================================
archivos_clave:
  pipeline_completo: "scripts/run_validated_pipeline.py"  # ENTRY POINT PRINCIPAL
  matching: "database/match_ofertas_v3.py"
  auto_validator: "database/auto_validator.py"
  auto_corrector: "database/auto_corrector.py"
  export_excel: "scripts/exports/export_validation_excel.py"
  run_tracking: "scripts/run_tracking.py"  # v2.1.0 con métricas de aprendizaje
  learning_evolution: "scripts/show_learning_evolution.py"  # visualizar evolución
  reglas_negocio: "config/matching_rules_business.json"
  diccionario_arg: "config/sinonimos_argentinos_esco.json"
  validacion_rules: "config/validation_rules.json"
  # Datos ESCO extraidos del RDF
  esco_ocupaciones: "database/embeddings/esco_occupations_full.json"
  esco_skills: "database/embeddings/esco_skills_full.json"
  esco_jerarquia: "database/embeddings/esco_skill_hierarchy.json"
  esco_relaciones: "database/embeddings/esco_occupation_skills.json"
  esco_extractor: "scripts/extract_esco_complete.py"

# ============================================
# COMANDOS FRECUENTES
# ============================================
comandos:
  pipeline_completo: "python scripts/run_validated_pipeline.py --limit 100"
  pipeline_con_markdown: "python scripts/run_validated_pipeline.py --limit 100 --export-markdown"
  reprocesar_ids: "python scripts/run_validated_pipeline.py --ids X,Y,Z"
  export_excel: "python scripts/exports/export_validation_excel.py --etapa completo --ids X"
  ver_estado: "python scripts/validar_ofertas.py --status"
  ver_errores_bd: "SELECT * FROM v_errores_pendientes"
  # Evolución del aprendizaje
  ver_convergencia: "python scripts/show_learning_evolution.py --batches"
  ver_evolucion_diaria: "python scripts/show_learning_evolution.py --daily"
  ver_timeline: "python scripts/show_learning_evolution.py"
  comparar_runs: "python scripts/compare_runs.py --latest"

# ============================================
# APRENDIZAJES DEL PROYECTO
# ============================================
learnings:
  - context: "Prioridad de matching"
    learning: "Reglas de negocio deben ejecutarse ANTES que diccionario argentino"
    date: 2026-01-14

  - context: "Export Excel L2"
    learning: "L1, L2, es_digital vienen del JSON source_classification, no de columnas directas"
    date: 2026-01-14

  - context: "Compactacion de conversacion"
    learning: "Actualizar learnings.yaml SIEMPRE despues de cambios significativos para no perder estado"
    date: 2026-01-14

  - context: "Run Tracking"
    learning: "SIEMPRE usar run_matching_pipeline(), NUNCA match_and_persist() directo. v3.3.2 emite WARNING si se llama sin run_id"
    date: 2026-01-14

  - context: "Codigos ESCO numericos"
    learning: "ESCO SI tiene codigos numericos (ej: 5244.1). Se extraen del RDF con skos:notation. Archivo: esco_occupations_full.json (3046 ocupaciones)"
    date: 2026-01-14

  - context: "Labels ISCO vs ESCO"
    learning: "isco_label es el grupo ISCO-08 (ej: Vendedores por telefono). esco_label es la ocupacion especifica (ej: vendedor de centros de contacto). Distincion importante para dashboard"
    date: 2026-01-14

  - context: "Extraccion ESCO del RDF"
    learning: "Usar rdflib+SPARQL sobre RDF local (1.3GB). skos:notation para codigos, skos:broader para jerarquia. Script: extract_esco_complete.py. Para skills sin L1, caminar jerarquia con _walk_hierarchy_for_code()"
    date: 2026-01-14

  - context: "Jerarquia skills ESCO"
    learning: "Skills tienen broader -> categoria con codigo (S1, S1.5, K, T). 2.3% no tienen broader (top-level). L1 = codigo nivel 2 (S1, K, T1), L2 = codigo nivel 3 (S1.5, K, T1.1)"
    date: 2026-01-14

  - context: "Categorizer sin hardcoding"
    learning: "skill_categorizer.py v2.0 hace lookup directo por URI en esco_skills_full.json. 97.5% cobertura vs ~50% anterior. NO vectorizar relaciones ocu-skill, son para lookup/filtrado"
    date: 2026-01-14

  - context: "Tabla esco_associations"
    learning: "match_by_skills.py usa tabla esco_associations (no JSON). Para actualizar relaciones ESCO: truncar tabla + insertar desde esco_occupation_skills.json. Backup antes de actualizar."
    date: 2026-01-14

  - context: "Pipeline supervision"
    learning: "auto_validator.py lee validation_rules.json (15 reglas). Query debe partir de ofertas_esco_matching (no ofertas) para validar solo las procesadas. Regex V07 necesita negative lookahead para excluir terminos tech."
    date: 2026-01-14

  - context: "Encoding provincias scraping"
    learning: "Algunas provincias con acentos vienen corruptas del scraping (Cordoba, Rio Negro). El postprocessor no puede parsearlas. Solucion: UPDATE manual en ofertas_nlp o fix en scraping."
    date: 2026-01-14

  - context: "Expansion Gold Set"
    learning: "Para expandir: seleccionar ofertas diversas (IT, Ventas, Salud, Logistica, etc. + distintas regiones). Procesar NLP, luego Matching, luego validar. Si hay errores: agregar reglas de negocio + corregir provincias."
    date: 2026-01-14

  - context: "Pipeline supervision completo"
    learning: |
      Flujo: auto_validator.py (15 reglas) -> si error -> Claude revisa cadena completa (review_offer_chain.py) -> diagnostica punto falla -> modifica config/*.json o BD -> re-procesa -> valida.
      Claude NO hace trabajo del LLM, solo supervisa y crea reglas para que el sistema aprenda.
    date: 2026-01-15

  - context: "Reglas negocio requieren activa=true"
    learning: "Las reglas en matching_rules_business.json necesitan 'activa': true para ser evaluadas. Sin este flag, se ignoran."
    date: 2026-01-15

  - context: "Integracion Supabase"
    learning: |
      Dashboard Next.js consume de Supabase. Sync manual con sync_to_supabase.py.
      Soporta --since para incremental, --dry-run para preview.
      Free tier: ~50k ofertas. Ejecutar schema SQL primero en Supabase Dashboard.
    date: 2026-01-15

  - context: "Clasificacion CLAE sector"
    learning: |
      CLAE = Clasificador de Actividades Económicas Argentina (AFIP).
      Estructura: 6 dígitos (950 actividades) → 3 dígitos (224 grupos) → Letra (20 secciones).
      Prioridad clasificación: sector_empresa > titulo > descripcion.
      Keywords genéricos como "sistemas" o "desarrollo" causan falsos positivos con IT.
      Usar sector_directo en clae_keywords_map.json para mapeo exacto de sector_empresa.
    date: 2026-01-15

  - context: "Metodología sector_empresa"
    learning: |
      CRÍTICO: sector_empresa es el sector del EMPLEADOR, no del puesto.
      - Banco contrata vigilante → sector=Finanzas (no Seguridad)
      - Hospital contrata contador → sector=Salud (no Finanzas)

      Niveles de confianza:
      - alta: Frase explícita "somos empresa de [sector]"
      - media: LLM extrajo (sin verificar fuente)
      - baja: Keyword suelto (NO USAR - genera falsos positivos)

      Para análisis de demanda de skills por sector: filtrar sector_confianza IN ('alta','media').
      Ver docs/guides/METODOLOGIA_SECTOR_EMPRESA.md
    date: 2026-01-15

  - context: "Catálogo de empresas para sector"
    learning: |
      Archivo: config/empresas_catalogo.json
      - empleadores: empresas conocidas con sector verificable → sector_confianza='alta'
      - intermediarios: consultoras RRHH (Manpower, Randstad, etc.) → es_intermediario=1

      Flujo en postprocessor:
      1. _lookup_empresa_catalogo() busca por id_empresa (del scraping)
      2. Si es empleador conocido → asigna sector + CLAE del catálogo (alta confianza)
      3. Si es intermediario → flaggea, sector_empresa NO representa al empleador real

      Script para actualización batch: scripts/update_sector_from_catalog.py
    date: 2026-01-15

  - context: "Reglas ubicación exterior"
    learning: |
      Las reglas V04-V06 (Paraguay, Uruguay, Chile) ahora verifican que provincia
      NO sea una provincia argentina válida antes de marcar como exterior.
      Evita falsos positivos cuando localidad="Asunción" pero provincia="Buenos Aires".
    date: 2026-01-16

  - context: "Inferencia área Seguridad"
    learning: |
      Agregada regla en nlp_inference_rules.json para forzar area_funcional="Seguridad"
      cuando titulo contiene: vigilador, vigilante, guardia de seguridad, custodio, sereno.
      Caso: ID 2171959 "Vigilador General" tenía area=Marketing (error LLM).
    date: 2026-01-16

  - context: "Seniority oficios técnicos"
    learning: |
      Oficios técnicos (mecánico, tornero, soldador, electricista, etc.) sin indicador
      explícito de seniority → default "semisenior" porque requieren experiencia.
      Regla en nlp_inference_rules.json > nivel_seniority > prioridad_por_titulo.
    date: 2026-01-16

  - context: "Excel pestaña Control"
    learning: |
      Excel de validación ahora tiene pestaña "Control" con 17 columnas clave para
      revisión rápida humana. Definida en config/excel_export_schema.json.
      Columnas: id, titulo, empresa, isco, esco, match_score, ubicación, sector, clae, area, seniority.
    date: 2026-01-16

  - context: "Feedback Loop via Markdown"
    learning: |
      Sistema alternativo al Excel para validación humana versionada en git.
      1. export_validation_markdown.py genera validation/feedback_*.md
      2. Humano edita columnas: resultado (OK|ERROR|REVISAR), isco_correcto, comentario
      3. Claude lee el archivo y crea reglas basadas en errores marcados
      Ventaja: feedback queda en historial git, visible para todo el equipo en GitHub.
    date: 2026-01-16

  - context: "Tracking histórico de matching"
    learning: |
      v3.3.3 agrega tracking completo de convergencia:
      - ofertas_matching_history: INSERT en cada matching (no sobrescribe como ofertas_esco_matching)
      - run_ofertas: qué ofertas se procesaron en cada run

      Vistas útiles:
      - v_ofertas_problematicas: ofertas con múltiples ISCOs (las que más costaron)
      - v_matching_timeline: historial completo por oferta
      - v_nlp_convergencia: versiones NLP por oferta (97% convergen en 1 intento)

      Query para ofertas difíciles:
      SELECT * FROM v_ofertas_problematicas ORDER BY veces_procesada DESC;
    date: 2026-01-16

  - context: "Pipeline de validación integrado"
    learning: |
      SIEMPRE usar run_validated_pipeline.py como entry point único para procesar ofertas.
      Ejecuta TODO automáticamente:
      1. Matching (match_ofertas_v3.py)
      2. Validación (auto_validator.py) - detecta errores, persiste en tabla validation_errors
      3. Corrección (auto_corrector.py) - arregla lo que puede, marca corregido=1 en BD
      4. Reporte (genera cola_claude.json si hay errores escalados)
      5. Export Markdown (opcional con --export-markdown)

      Errores se persisten en tabla validation_errors con campos:
      - corregido: 1 si auto_corrector lo arregló
      - escalado_claude: 1 si requiere regla nueva
      - resuelto: 1 si se resolvió (auto o manual)

      Vistas útiles: v_errores_pendientes, v_errores_por_tipo
    date: 2026-01-16

  - context: "Métricas de evolución del aprendizaje"
    learning: |
      Cada run ahora registra automáticamente:
      - reglas_negocio_count: cantidad de reglas en matching_rules_business.json
      - reglas_validacion_count: cantidad de reglas de validación
      - sinonimos_count: cantidad de sinónimos argentinos
      - delta_reglas: diferencia respecto al run anterior

      Comandos útiles:
      - python scripts/show_learning_evolution.py → timeline completo
      - python scripts/show_learning_evolution.py --daily → resumen por día
      - python scripts/show_learning_evolution.py --chart → gráfico ASCII

      Tabla learning_history registra eventos de aprendizaje individuales.
      Vista v_learning_evolution para queries SQL.

      RunTracker v2.1.0 (scripts/run_tracking.py) calcula métricas automáticamente.
    date: 2026-01-16

  - context: "Sistema de lotes para medir convergencia"
    learning: |
      Lotes agrupan runs relacionados para medir el aprendizaje por iteración.

      Tablas:
      - learning_batches: lotes con métricas de convergencia
      - batch_runs: relación lote -> runs

      Métricas clave por lote:
      - tasa_aprendizaje: reglas_agregadas / ofertas_total (menor = más maduro)
      - cobertura_estimada: % ofertas cubiertas por reglas existentes

      Umbrales de madurez:
      - Tasa > 15%: En aprendizaje activo
      - Tasa 5-15%: Convergiendo
      - Tasa < 5%: Sistema maduro para producción

      Comando: python scripts/show_learning_evolution.py --batches

      RunTracker métodos: create_batch(), add_run_to_batch(), finalize_batch()
    date: 2026-01-16

  - context: "Auto-sync de learnings.yaml"
    learning: |
      El archivo learnings.yaml se actualiza AUTOMATICAMENTE:
      1. Al ejecutar run_validated_pipeline.py → llama sync_learnings_yaml()
      2. Al completar un run → save_results() registra en learning_history

      Script: scripts/sync_learnings.py
      - Lee conteos de config/*.json (reglas, sinónimos, empresas)
      - Lee métricas de BD (runs, ofertas con matching)
      - Actualiza secciones: conteos, estadisticas_actuales, learning_evolution

      Tabla learning_history: registra eventos (run_completado, regla_agregada, etc.)
      Ya NO es necesario que Claude actualice manualmente los conteos.

      Para ejecutar manualmente: python scripts/sync_learnings.py
    date: 2026-01-17

  - context: "Dual Matching v3.4.0"
    learning: |
      Sistema de matching ejecuta AMBOS métodos (semántico Y reglas) y guarda ambos resultados.

      Columnas nuevas en ofertas_esco_matching:
      - isco_regla, isco_semantico, score_semantico
      - regla_aplicada, dual_coinciden, decision_metodo

      Flujo:
      1. match() ejecuta semántico completo (diccionario/skills/titulo)
      2. _evaluate_rule_only() evalúa reglas sin bypass
      3. Guarda ambos en metadata del MatchResult
      4. save_matching_result() persiste los 6 campos
      5. V23_dual_decision detecta cuando dual_coinciden=0
      6. auto_corrector._aplicar_decidir_dual_match() decide:
         - score >= 0.75 → semántico gana
         - regla >= 5 casos validados → regla gana
         - default → semántico gana

      Vistas de monitoreo:
      - v_dual_decisions: distribución de decisiones
      - v_reglas_problematicas: reglas que difieren >50%
      - v_reglas_efectividad: análisis por regla

      Archivos modificados:
      - database/match_ofertas_v3.py (v3.4.0)
      - database/auto_corrector.py (+_aplicar_decidir_dual_match)
      - config/validation_rules.json (+V23)
      - config/auto_correction_map.json (+discrepancia_dual)
      - migrations/015_dual_decision_tracking.sql
    date: 2026-01-20

  - context: "Protección de ofertas validadas v2.0"
    learning: |
      GAP CRÍTICO encontrado: export_validation_excel.py:474 no filtraba por estado_validacion,
      causando que ofertas YA VALIDADAS volvieran a aparecer en lotes nuevos.

      Solución implementada (4 capas):
      1. Query filtrada en export_validation_excel.py:476 - excluye validadas de selección
      2. Query filtrada en auto_validator.py:590 - excluye validadas de validación
      3. Error explícito en match_ofertas_v3.py:1368 - lanza ValueError si hay validadas
      4. Triggers BD (migrations/016_protect_validated_offers.sql):
         - protect_validated_matching: bloquea UPDATE en ofertas validadas
         - protect_validated_status: solo permite validado → en_revision

      Scripts nuevos:
      - scripts/check_validated_protection.py: verifica estado de protección
      - scripts/admin_unlock_validated.py: desbloquea con justificación obligatoria

      REGLA ABSOLUTA: Ofertas con estado_validacion='validado' NUNCA deben aparecer en lotes nuevos.
      Para desbloquear: python scripts/admin_unlock_validated.py --ids X --motivo "razón"
    date: 2026-01-20

# ============================================
# DECISIONES TOMADAS
# ============================================
decisions:
  - decision: "Matching v3.3.2 con prioridad Reglas > Diccionario > Semantico"
    reason: "El semantico solo no es confiable, las reglas especificas deben tener prioridad"
    date: 2026-01-14

  - decision: "100 ofertas para validacion inicial"
    reason: "Suficiente para encontrar patrones de error antes de escalar"
    date: 2026-01-14

  - decision: "Extraer ESCO del RDF local en lugar de API"
    reason: "RDF tiene datos completos (skills, jerarquias, relaciones), API es limitada y lenta"
    date: 2026-01-14

  - decision: "CLAE convive con sector_empresa (no reemplaza)"
    reason: "sector_empresa es texto libre útil para debugging, CLAE es código oficial para agregación"
    date: 2026-01-15

  - decision: "CLAE usa sector_directo primero, keywords como fallback"
    reason: "Keywords genéricos causan falsos positivos. sector_empresa ya fue inferido por NLP, es más confiable"
    date: 2026-01-15

  - decision: "Intermediarios (consultoras) flaggeados pero no excluidos"
    reason: "El sector de una consultora (ej: Manpower) no representa al empleador real. es_intermediario=1 permite filtrar en análisis por sector sin perder datos"
    date: 2026-01-15

  - decision: "Catálogo de empresas con id_empresa del scraping"
    reason: "id_empresa de Bumeran es persistente y permite identificar 81 empleadores conocidos + 164 intermediarios sin depender de parsing de texto"
    date: 2026-01-15

  - decision: "Pipeline integrado como entry point único (run_validated_pipeline.py)"
    reason: "Scripts fragmentados (matching → validator → corrector) nunca se ejecutaban completos. Un solo comando garantiza que todo se ejecute y errores se persistan en BD."
    date: 2026-01-16

  - decision: "Errores de validación persisten en tabla validation_errors"
    reason: "Errores solo en memoria se perdían entre sesiones. Persistir permite tracking histórico, métricas y feedback loop completo."
    date: 2026-01-16

  - decision: "Auto-sync de learnings.yaml via script"
    reason: "Las instrucciones para que Claude actualizara manualmente no funcionaban consistentemente. Script automatiza la sincronización de conteos y métricas desde BD/configs."
    date: 2026-01-17

  - decision: "Dual matching v3.4.0 - ejecutar AMBOS métodos siempre"
    reason: "Usuario pidió enfoque más flexible que 'reglas ganan siempre'. Ahora semántico Y reglas se ejecutan, auto_corrector decide automáticamente basado en score y casos validados. 100% automático sin intervención humana."
    date: 2026-01-20

# ============================================
# COSAS QUE NO FUNCIONARON
# ============================================
failures:
  - attempt: "Diccionario argentino con prioridad sobre reglas"
    problem: "Casos especificos como 'operador sim' matcheaban con 'operador' generico"
    date: 2026-01-14

  - attempt: "Llamar match_and_persist() directo sin run_id"
    problem: "93 ofertas quedaron sin tracking, imposible comparar corridas"
    date: 2026-01-14

  - attempt: "Instrucciones en CLAUDE.md para que Claude actualizara learnings.yaml manualmente"
    problem: "register_learning_event() existía pero nunca se llamaba. learning_history tenía 0 registros. La 'automatización' era solo texto para Claude, no código real."
    date: 2026-01-17

  - attempt: "Pipeline fragmentado (matching, validator, corrector como scripts separados)"
    problem: "Claude nunca ejecutaba el pipeline completo a menos que se pidiera explícitamente. Errores no se persistían en BD."
    date: 2026-01-16
