# Proyecto: MOL - Monitor de Ofertas Laborales
# Claude Code lee esto AUTOMATICAMENTE al inicio de cada conversacion
# ACTUALIZAR SIEMPRE QUE HAYA UN CAMBIO SIGNIFICATIVO

# ============================================
# ESTADO ACTUAL DEL TRABAJO (LEER PRIMERO)
# ============================================
current_state:
  fecha_actualizacion: "2026-01-15"

  # Modelo de 3 Fases - ver docs/reference/ARQUITECTURA_3_FASES.md
  fase_actual: "presentacion"  # adquisicion | procesamiento | presentacion
  fase_detalle: "Verificar dashboard Next.js consume datos de Supabase"

  ofertas_bd: 13170  # Total en BD despues de scraping
  ofertas_validadas: 110  # 100 inicial + 10 expansion
  estado_ofertas: "validado"  # Listas para produccion

  matching_version: "v3.3.2"
  matching_arquitectura: "Reglas negocio -> Diccionario argentino -> Semantico"
  reglas_negocio: 104  # R1-R101 activas

  supabase:
    integrado: true
    url: "https://uywzoyhjjofsvvsrrnek.supabase.co"
    sync_script: "scripts/exports/sync_to_supabase.py"
    dashboard: "https://mol-nextjs.vercel.app/"

  esco_extraction:
    source: "RDF v1.2.0 local (D:/Trabajos en PY/EPH-ESCO/01_datos_originales)"
    ocupaciones: 3046
    skills: 14257
    categorias_skill: 889  # S, S1, S1.5, K, T
    relaciones_ocu_skill: 129004  # essential + optional
    cobertura_L1: "97.7%"  # skills con categoria L1

  ultimo_trabajo:
    - "Sync inicial Supabase completado: 110 ofertas, 1916 skills, 60 ocupaciones"
    - "Schema SQL ejecutado en Supabase Dashboard"
    - "Politicas RLS configuradas (lectura publica, escritura con anon_key)"
    - "Script corregido para columnas lowercase (l1, l2, l1_nombre, l2_nombre)"

  proximo_paso: "Verificar dashboard Next.js consume datos de Supabase correctamente"

  integracion_completada:
    - "Supabase sync inicial: 110 ofertas + 1916 skills + 60 ocupaciones ESCO"
    - "skill_categorizer.py v2.0 - sin hardcoding, usa esco_skills_full.json"
    - "Cobertura L1/L2: 97.5% via esco_rdf directo"
    - "auto_validator.py funcional con 15 reglas"
    - "esco_associations table = 129k relaciones (67k essential + 61k optional)"

  problemas_conocidos:
    - "327 skills (2.3%) sin L1 - son top-level sin broader"
    - "Encoding scraping: algunos caracteres acentuados corruptos (Cordoba, Rio Negro)"

# ============================================
# ARCHIVOS CLAVE (no buscar, usar estos)
# ============================================
archivos_clave:
  matching: "database/match_ofertas_v3.py"
  export_excel: "scripts/exports/export_validation_excel.py"
  reglas_negocio: "config/matching_rules_business.json"
  diccionario_arg: "config/sinonimos_argentinos_esco.json"
  validacion_rules: "config/validation_rules.json"
  # Datos ESCO extraidos del RDF
  esco_ocupaciones: "database/embeddings/esco_occupations_full.json"
  esco_skills: "database/embeddings/esco_skills_full.json"
  esco_jerarquia: "database/embeddings/esco_skill_hierarchy.json"
  esco_relaciones: "database/embeddings/esco_occupation_skills.json"
  esco_extractor: "scripts/extract_esco_complete.py"

# ============================================
# COMANDOS FRECUENTES
# ============================================
comandos:
  reprocesar_matching: "run_matching_pipeline(offer_ids=[...]) en match_ofertas_v3.py"
  export_excel: "python scripts/exports/export_validation_excel.py --etapa completo --ids X"
  ver_estado: "python scripts/validar_ofertas.py --status"

# ============================================
# APRENDIZAJES DEL PROYECTO
# ============================================
learnings:
  - context: "Prioridad de matching"
    learning: "Reglas de negocio deben ejecutarse ANTES que diccionario argentino"
    date: 2026-01-14

  - context: "Export Excel L2"
    learning: "L1, L2, es_digital vienen del JSON source_classification, no de columnas directas"
    date: 2026-01-14

  - context: "Compactacion de conversacion"
    learning: "Actualizar learnings.yaml SIEMPRE despues de cambios significativos para no perder estado"
    date: 2026-01-14

  - context: "Run Tracking"
    learning: "SIEMPRE usar run_matching_pipeline(), NUNCA match_and_persist() directo. v3.3.2 emite WARNING si se llama sin run_id"
    date: 2026-01-14

  - context: "Codigos ESCO numericos"
    learning: "ESCO SI tiene codigos numericos (ej: 5244.1). Se extraen del RDF con skos:notation. Archivo: esco_occupations_full.json (3046 ocupaciones)"
    date: 2026-01-14

  - context: "Labels ISCO vs ESCO"
    learning: "isco_label es el grupo ISCO-08 (ej: Vendedores por telefono). esco_label es la ocupacion especifica (ej: vendedor de centros de contacto). Distincion importante para dashboard"
    date: 2026-01-14

  - context: "Extraccion ESCO del RDF"
    learning: "Usar rdflib+SPARQL sobre RDF local (1.3GB). skos:notation para codigos, skos:broader para jerarquia. Script: extract_esco_complete.py. Para skills sin L1, caminar jerarquia con _walk_hierarchy_for_code()"
    date: 2026-01-14

  - context: "Jerarquia skills ESCO"
    learning: "Skills tienen broader -> categoria con codigo (S1, S1.5, K, T). 2.3% no tienen broader (top-level). L1 = codigo nivel 2 (S1, K, T1), L2 = codigo nivel 3 (S1.5, K, T1.1)"
    date: 2026-01-14

  - context: "Categorizer sin hardcoding"
    learning: "skill_categorizer.py v2.0 hace lookup directo por URI en esco_skills_full.json. 97.5% cobertura vs ~50% anterior. NO vectorizar relaciones ocu-skill, son para lookup/filtrado"
    date: 2026-01-14

  - context: "Tabla esco_associations"
    learning: "match_by_skills.py usa tabla esco_associations (no JSON). Para actualizar relaciones ESCO: truncar tabla + insertar desde esco_occupation_skills.json. Backup antes de actualizar."
    date: 2026-01-14

  - context: "Pipeline supervision"
    learning: "auto_validator.py lee validation_rules.json (15 reglas). Query debe partir de ofertas_esco_matching (no ofertas) para validar solo las procesadas. Regex V07 necesita negative lookahead para excluir terminos tech."
    date: 2026-01-14

  - context: "Encoding provincias scraping"
    learning: "Algunas provincias con acentos vienen corruptas del scraping (Cordoba, Rio Negro). El postprocessor no puede parsearlas. Solucion: UPDATE manual en ofertas_nlp o fix en scraping."
    date: 2026-01-14

  - context: "Expansion Gold Set"
    learning: "Para expandir: seleccionar ofertas diversas (IT, Ventas, Salud, Logistica, etc. + distintas regiones). Procesar NLP, luego Matching, luego validar. Si hay errores: agregar reglas de negocio + corregir provincias."
    date: 2026-01-14

  - context: "Pipeline supervision completo"
    learning: |
      Flujo: auto_validator.py (15 reglas) -> si error -> Claude revisa cadena completa (review_offer_chain.py) -> diagnostica punto falla -> modifica config/*.json o BD -> re-procesa -> valida.
      Claude NO hace trabajo del LLM, solo supervisa y crea reglas para que el sistema aprenda.
    date: 2026-01-15

  - context: "Reglas negocio requieren activa=true"
    learning: "Las reglas en matching_rules_business.json necesitan 'activa': true para ser evaluadas. Sin este flag, se ignoran."
    date: 2026-01-15

  - context: "Integracion Supabase"
    learning: |
      Dashboard Next.js consume de Supabase. Sync manual con sync_to_supabase.py.
      Soporta --since para incremental, --dry-run para preview.
      Free tier: ~50k ofertas. Ejecutar schema SQL primero en Supabase Dashboard.
    date: 2026-01-15

# ============================================
# DECISIONES TOMADAS
# ============================================
decisions:
  - decision: "Matching v3.3.2 con prioridad Reglas > Diccionario > Semantico"
    reason: "El semantico solo no es confiable, las reglas especificas deben tener prioridad"
    date: 2026-01-14

  - decision: "100 ofertas para validacion inicial"
    reason: "Suficiente para encontrar patrones de error antes de escalar"
    date: 2026-01-14

  - decision: "Extraer ESCO del RDF local en lugar de API"
    reason: "RDF tiene datos completos (skills, jerarquias, relaciones), API es limitada y lenta"
    date: 2026-01-14

# ============================================
# COSAS QUE NO FUNCIONARON
# ============================================
failures:
  - attempt: "Diccionario argentino con prioridad sobre reglas"
    problem: "Casos especificos como 'operador sim' matcheaban con 'operador' generico"
    date: 2026-01-14

  - attempt: "Llamar match_and_persist() directo sin run_id"
    problem: "93 ofertas quedaron sin tracking, imposible comparar corridas"
    date: 2026-01-14
