# ğŸ”„ FLUJO COMPLETO: BUMERAN WEBSCRAPING â†’ DASHBOARD

**Fecha:** 30 de octubre de 2025
**VersiÃ³n:** 1.0
**Mantenedor:** OEDE - Observatorio de Empleo y DinÃ¡mica Empresarial

---

## ğŸ“‹ Tabla de Contenidos

1. [Resumen Ejecutivo](#resumen-ejecutivo)
2. [Diagrama de Flujo](#diagrama-de-flujo)
3. [Etapa 1: Scraping](#etapa-1-scraping)
4. [Etapa 2: ConsolidaciÃ³n](#etapa-2-consolidaciÃ³n)
5. [Etapa 3: ExtracciÃ³n NLP](#etapa-3-extracciÃ³n-nlp)
6. [Etapa 4: Matching ESCO](#etapa-4-matching-esco)
7. [Etapa 5: Dashboard Shiny](#etapa-5-dashboard-shiny)
8. [Comandos Ejecutables](#comandos-ejecutables)
9. [Problemas Conocidos](#problemas-conocidos)
10. [Calidad de Datos](#calidad-de-datos)

---

## ğŸ“Š Resumen Ejecutivo

### Estado Actual

| MÃ©trica | Valor |
|---------|-------|
| **Ofertas disponibles en Bumeran** | ~12,000 |
| **Ofertas scrapeadas** | 2,460 (20%) |
| **Calidad descripciones** | 100% âœ… |
| **Tiempo de scraping** | ~2 horas (con 55 keywords) |
| **Scripts funcionales** | 2/4 principales |
| **Modo incremental** | âœ… Activo |
| **Estado pipeline** | âœ… Funcional |

### Archivos Clave

```
ğŸ“ UbicaciÃ³n base: D:\OEDE\Webscrapping\

ğŸ“„ CSV final raw: 01_sources/bumeran/data/raw/bumeran_full_20251023_213057.csv
ğŸ“„ CSV con NLP: 02.5_nlp_extraction/data/processed/bumeran_nlp_20251025_140906.csv
ğŸ“„ CSV consolidado: 02_consolidation/data/consolidated/ofertas_consolidadas_*.csv
ğŸ“„ Tracking: data/tracking/bumeran_scraped_ids.json
```

---

## ğŸ”€ Diagrama de Flujo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        API BUMERAN                                  â”‚
â”‚  https://www.bumeran.com.ar/api/avisos/searchV2                    â”‚
â”‚                                                                      â”‚
â”‚  â€¢ Ofertas disponibles: ~12,000                                     â”‚
â”‚  â€¢ MÃ©todo: POST con headers especiales                              â”‚
â”‚  â€¢ PaginaciÃ³n: 20 ofertas/pÃ¡gina                                    â”‚
â”‚  â€¢ âš ï¸ CRÃTICO: Requiere keywords, sin ellas solo 20 ofertas         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ETAPA 1: SCRAPING                                â”‚
â”‚  ğŸ“ 01_sources/bumeran/scrapers/bumeran_scraper.py                  â”‚
â”‚                                                                      â”‚
â”‚  INPUTS:                                                            â”‚
â”‚  â€¢ master_keywords.json (estrategias: completa ~55 keywords)        â”‚
â”‚  â€¢ bumeran_scraped_ids.json (tracking incremental)                  â”‚
â”‚                                                                      â”‚
â”‚  PARÃMETROS:                                                        â”‚
â”‚  â€¢ delay_between_requests: 2.0s                                     â”‚
â”‚  â€¢ incremental: True (solo ofertas nuevas)                          â”‚
â”‚  â€¢ max_paginas: None (todas las pÃ¡ginas disponibles)                â”‚
â”‚                                                                      â”‚
â”‚  OUTPUTS:                                                           â”‚
â”‚  âœ… bumeran_full_20251023_213057.csv                                â”‚
â”‚     - 2,460 ofertas                                                 â”‚
â”‚     - 32 columnas raw                                               â”‚
â”‚     - TamaÃ±o: 4.2 MB                                                â”‚
â”‚     - UbicaciÃ³n: 01_sources/bumeran/data/raw/                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                ETAPA 2: CONSOLIDACIÃ“N                               â”‚
â”‚  ğŸ“ 02_consolidation/scripts/consolidar_fuentes.py                  â”‚
â”‚  ğŸ“ Normalizer: normalizar_campos.py â†’ BumeranNormalizer()          â”‚
â”‚                                                                      â”‚
â”‚  PROCESO:                                                           â”‚
â”‚  1. Lee CSV raw de Bumeran                                          â”‚
â”‚  2. Aplica BumeranNormalizer.normalize()                            â”‚
â”‚  3. Mapea campos al schema unificado (50+ campos)                   â”‚
â”‚                                                                      â”‚
â”‚  TRANSFORMACIONES PRINCIPALES:                                      â”‚
â”‚  â€¢ id_oferta â†’ _metadata.source_id                                  â”‚
â”‚  â€¢ titulo â†’ informacion_basica.titulo                               â”‚
â”‚  â€¢ descripcion (HTML) â†’ descripcion_limpia (texto plano)            â”‚
â”‚  â€¢ "Ciudad, Provincia" â†’ provincia + ciudad separados               â”‚
â”‚  â€¢ "DD-MM-YYYY" â†’ ISO 8601 (YYYY-MM-DD)                             â”‚
â”‚  â€¢ Modalidades normalizadas ("Remoto" â†’ "remoto")                   â”‚
â”‚                                                                      â”‚
â”‚  OUTPUTS:                                                           â”‚
â”‚  âœ… ofertas_consolidadas_20251025_125307.csv                        â”‚
â”‚     - ~8,472 ofertas (todas las fuentes)                            â”‚
â”‚     - Schema unificado: 50+ campos                                  â”‚
â”‚     - TamaÃ±o: 792 MB                                                â”‚
â”‚     - UbicaciÃ³n: 02_consolidation/data/consolidated/                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               ETAPA 3: EXTRACCIÃ“N NLP                               â”‚
â”‚  ğŸ“ 02.5_nlp_extraction/scripts/run_nlp_extraction.py               â”‚
â”‚  ğŸ“ Extractor: extractors/bumeran_extractor.py                      â”‚
â”‚                                                                      â”‚
â”‚  PROCESO:                                                           â”‚
â”‚  1. Lee campo 'descripcion' del CSV raw de Bumeran                  â”‚
â”‚  2. Limpia HTML con HTMLStripper                                    â”‚
â”‚  3. Aplica regex patterns para extraer 23 campos:                   â”‚
â”‚                                                                      â”‚
â”‚     EXPERIENCIA:                                                    â”‚
â”‚     â€¢ experiencia_min_anios, experiencia_max_anios                  â”‚
â”‚     â€¢ experiencia_area                                              â”‚
â”‚                                                                      â”‚
â”‚     EDUCACIÃ“N:                                                      â”‚
â”‚     â€¢ nivel_educativo, estado_educativo                             â”‚
â”‚     â€¢ carrera_especifica, titulo_excluyente                         â”‚
â”‚                                                                      â”‚
â”‚     IDIOMAS:                                                        â”‚
â”‚     â€¢ idioma_principal, nivel_idioma_principal                      â”‚
â”‚     â€¢ idioma_secundario, nivel_idioma_secundario                    â”‚
â”‚                                                                      â”‚
â”‚     SKILLS:                                                         â”‚
â”‚     â€¢ skills_tecnicas_list, soft_skills_list                        â”‚
â”‚     â€¢ certificaciones_list, niveles_skills_list                     â”‚
â”‚                                                                      â”‚
â”‚     OTROS:                                                          â”‚
â”‚     â€¢ salario_min/max, jornada_laboral                              â”‚
â”‚     â€¢ requisitos_excluyentes/deseables                              â”‚
â”‚                                                                      â”‚
â”‚  OUTPUTS:                                                           â”‚
â”‚  âœ… bumeran_nlp_20251025_140906.csv                                 â”‚
â”‚     - 2,460 ofertas                                                 â”‚
â”‚     - 55 columnas (32 originales + 23 NLP)                          â”‚
â”‚     - TamaÃ±o: ~5 MB                                                 â”‚
â”‚     - UbicaciÃ³n: 02.5_nlp_extraction/data/processed/                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            ETAPA 4: MATCHING ESCO/ISCO                              â”‚
â”‚  ğŸ“ 03_esco_matching/scripts/esco_isco_llm_fallback.py              â”‚
â”‚  ğŸ“ Manual: manual_matcher_claude.py                                â”‚
â”‚                                                                      â”‚
â”‚  PROCESO:                                                           â”‚
â”‚  1. Lee titulo normalizado de cada oferta                           â”‚
â”‚  2. Match contra taxonomÃ­a ESCO con Claude AI                       â”‚
â”‚  3. Asigna cÃ³digo ESCO + ISCO + skills                              â”‚
â”‚  4. Enriquece con skills esenciales y opcionales                    â”‚
â”‚                                                                      â”‚
â”‚  CAMPOS AGREGADOS:                                                  â”‚
â”‚  â€¢ claude_esco_id, claude_esco_label                                â”‚
â”‚  â€¢ claude_isco_code (4 dÃ­gitos ISCO-08)                             â”‚
â”‚  â€¢ isco_nivel1, isco_nivel1_nombre                                  â”‚
â”‚  â€¢ isco_nivel2, isco_4d                                             â”‚
â”‚  â€¢ esco_skills_esenciales (pipe-separated)                          â”‚
â”‚  â€¢ esco_skills_opcionales (pipe-separated)                          â”‚
â”‚  â€¢ claude_confidence, claude_razonamiento                           â”‚
â”‚                                                                      â”‚
â”‚  OUTPUTS:                                                           â”‚
â”‚  âœ… ofertas_esco_shiny.csv (subset perfecto de 268 ofertas)         â”‚
â”‚     - 268 ofertas clasificadas manualmente                          â”‚
â”‚     - 48 columnas                                                   â”‚
â”‚     - 100% con clasificaciÃ³n ESCO perfecta                          â”‚
â”‚     - 100% con URLs recuperadas                                     â”‚
â”‚     - UbicaciÃ³n: Visual--/ofertas_esco_shiny.csv                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               ETAPA 5: DASHBOARD SHINY                              â”‚
â”‚  ğŸ“ Visual--/app.R                                                  â”‚
â”‚                                                                      â”‚
â”‚  INPUT:                                                             â”‚
â”‚  â€¢ ofertas_esco_shiny.csv (268 ofertas, 48 columnas)                â”‚
â”‚                                                                      â”‚
â”‚  DASHBOARD FEATURES:                                                â”‚
â”‚  â€¢ 5 pestaÃ±as interactivas                                          â”‚
â”‚  â€¢ AutenticaciÃ³n con shinymanager                                   â”‚
â”‚  â€¢ Filtros: Provincia, Fecha, Ãrbol ESCO navegable                  â”‚
â”‚  â€¢ GrÃ¡ficos: plotly interactivos                                    â”‚
â”‚  â€¢ Tablas: DT con bÃºsqueda y paginaciÃ³n                             â”‚
â”‚                                                                      â”‚
â”‚  DEPLOYED:                                                          â”‚
â”‚  ğŸŒ https://dos1tv-gerardo-breard.shinyapps.io/dashboard-esco-...   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¥ ETAPA 1: SCRAPING

### ğŸ¯ Objetivo
Extraer ofertas laborales de la API de Bumeran Argentina.

### ğŸ“ UbicaciÃ³n
`D:\OEDE\Webscrapping\01_sources\bumeran\`

### ğŸ”§ Scripts Principales

#### 1. bumeran_scraper.py (Script Principal)

**PropÃ³sito:** Scraper directo de la API REST de Bumeran

**CaracterÃ­sticas:**
- Modo incremental (evita re-scrapear ofertas ya procesadas)
- Rate limiting (2s entre requests)
- Soporte para keywords
- Genera CSV/JSON/Excel

**Uso bÃ¡sico:**
```python
from bumeran_scraper import BumeranScraper

scraper = BumeranScraper()
ofertas = scraper.scrapear_todo(
    max_paginas=None,      # Todas las pÃ¡ginas
    query="python",        # Keyword de bÃºsqueda
    incremental=True       # Solo ofertas nuevas
)
scraper.save_all_formats(ofertas, 'bumeran_full')
```

#### 2. scrapear_con_diccionario.py (RECOMENDADO)

**PropÃ³sito:** Scraping multi-keyword usando diccionario maestro

**Ventajas:**
- Usa mÃºltiples keywords automÃ¡ticamente
- DeduplicaciÃ³n incorporada
- Mejor cobertura (~55 keywords)
- Estrategias predefinidas

**Uso:**
```python
from scrapear_con_diccionario import BumeranMultiSearch

scraper = BumeranMultiSearch()
df = scraper.scrapear_multiples_keywords(
    estrategia='completa',          # 55 keywords
    max_paginas_por_keyword=10,
    incremental=True,
    date_window_days=7              # Ãšltimos 7 dÃ­as
)
scraper.guardar_resultados(df)
```

### ğŸ“Š ConfiguraciÃ³n API

```python
# Endpoint
URL = "https://www.bumeran.com.ar/api/avisos/searchV2"

# Headers OBLIGATORIOS
headers = {
    'x-site-id': 'BMAR',                      # Bumeran Argentina
    'x-pre-session-token': str(uuid.uuid4()),  # Token Ãºnico por sesiÃ³n
    'Content-Type': 'application/json'
}

# Payload
{
    "pageSize": 20,        # Ofertas por pÃ¡gina (max: 100)
    "page": 0,             # NÃºmero de pÃ¡gina (0-indexed)
    "sort": "FECHA",       # FECHA o RELEVANTES
    "query": "python"      # âš ï¸ CRÃTICO: Sin keyword solo 20 ofertas
}
```

### âš ï¸ LIMITACIONES CRÃTICAS

1. **Sin keyword â†’ solo 20 ofertas**
   - Problema: API retorna mÃ¡ximo 20 ofertas si no hay `query`
   - SoluciÃ³n: SIEMPRE usar keywords del `master_keywords.json`

2. **Rate limiting**
   - Delay mÃ­nimo: 2 segundos entre requests
   - Reducir puede causar bloqueo de IP

3. **PaginaciÃ³n limitada**
   - MÃ¡ximo 100 ofertas por request con `pageSize=100`
   - Ã“ptimo: 20 ofertas por request (mÃ¡s estable)

### ğŸ“¦ Outputs Generados

| Archivo | UbicaciÃ³n | DescripciÃ³n |
|---------|-----------|-------------|
| `bumeran_full_YYYYMMDD_HHMMSS.csv` | `data/raw/` | CSV con 32 columnas raw |
| `bumeran_consolidacion.json` | `data/raw/` | Backup en JSON |
| `bumeran_consolidacion.xlsx` | `data/raw/` | Backup en Excel |
| `bumeran_scraped_ids.json` | `../../data/tracking/` | Tracking incremental |

### ğŸ“‹ Columnas Raw (32 campos)

```
IdentificaciÃ³n:
- id_oferta, id_empresa

BÃ¡sicas:
- titulo, empresa, descripcion (HTML), confidencial

UbicaciÃ³n:
- localizacion ("Ciudad, Provincia")
- modalidad_trabajo, tipo_trabajo

Fechas:
- fecha_publicacion, fecha_hora_publicacion, fecha_modificado

Detalles:
- cantidad_vacantes, apto_discapacitado

CategorizaciÃ³n:
- id_area, id_subarea, id_pais

Empresa:
- logo_url, empresa_validada, empresa_pro, promedio_empresa

Otros:
- plan_publicacion_id, portal, tipo_aviso
- url_oferta, scrapeado_en
```

---

## ğŸ”„ ETAPA 2: CONSOLIDACIÃ“N

### ğŸ¯ Objetivo
Normalizar datos de Bumeran al schema unificado multi-fuente.

### ğŸ“ UbicaciÃ³n
`D:\OEDE\Webscrapping\02_consolidation\`

### ğŸ”§ Script Principal

**Archivo:** `scripts/consolidar_fuentes.py`
**Normalizer:** `scripts/normalizar_campos.py` â†’ clase `BumeranNormalizer`

### ğŸ”€ Transformaciones Principales

```python
# Ejemplo de normalizaciÃ³n

# ANTES (raw):
{
    'id_oferta': '123456',
    'titulo': 'Desarrollador Python',
    'descripcion': '<p>DescripciÃ³n con <b>HTML</b></p>',
    'localizacion': 'CABA, Buenos Aires',
    'fecha_publicacion': '23-10-2025',
    'modalidad_trabajo': 'Remoto'
}

# DESPUÃ‰S (normalizado):
{
    '_metadata.source': 'bumeran',
    '_metadata.source_id': '123456',
    '_metadata.unified_id': 'bumeran_123456',
    '_metadata.url_oferta': 'https://www.bumeran.com.ar/empleos/123456.html',

    'informacion_basica.titulo': 'Desarrollador Python',
    'informacion_basica.titulo_normalizado': 'desarrollador python',
    'informacion_basica.descripcion': '<p>DescripciÃ³n con <b>HTML</b></p>',
    'informacion_basica.descripcion_limpia': 'DescripciÃ³n con HTML',

    'ubicacion.pais': 'Argentina',
    'ubicacion.provincia': 'Buenos Aires',
    'ubicacion.ciudad': 'CABA',
    'ubicacion.ubicacion_raw': 'CABA, Buenos Aires',

    'fechas.fecha_publicacion': '2025-10-23',  # ISO 8601

    'modalidad.modalidad_trabajo': 'remoto',   # Normalizado lowercase
    'modalidad.tipo_trabajo': 'full_time'      # Inferido si no estÃ¡
}
```

### ğŸ“Š Schema Unificado

El schema tiene **50+ campos** organizados en secciones:

1. `_metadata`: Metadatos de scraping
2. `informacion_basica`: TÃ­tulo, empresa, descripciÃ³n
3. `ubicacion`: PaÃ­s, provincia, ciudad
4. `modalidad`: Tipo de trabajo, modalidad
5. `fechas`: PublicaciÃ³n, modificaciÃ³n, cierre
6. `requisitos`: Experiencia, educaciÃ³n, idiomas (se llena en NLP)
7. `compensacion`: Salario, beneficios (generalmente vacÃ­o en Bumeran)
8. `detalles`: Vacantes, Ã¡rea, nivel
9. `clasificacion_esco`: ESCO/ISCO (se llena en etapa 4)
10. `source_specific`: Campos Ãºnicos de Bumeran

**Ver schema completo:** `shared/schemas/schema_unificado.json`

### ğŸ“¦ Output

| Archivo | DescripciÃ³n |
|---------|-------------|
| `ofertas_consolidadas_YYYYMMDD_HHMMSS.csv` | CSV con todas las fuentes consolidadas |
| TamaÃ±o: ~792 MB | |
| Ofertas: ~8,472 | Incluye Bumeran + otras fuentes |
| Columnas: 50+ | Schema unificado |

---

## ğŸ§  ETAPA 3: EXTRACCIÃ“N NLP

### ğŸ¯ Objetivo
Extraer informaciÃ³n estructurada de las descripciones en texto libre usando regex.

### ğŸ“ UbicaciÃ³n
`D:\OEDE\Webscrapping\02.5_nlp_extraction\`

### ğŸ”§ Scripts

**Principal:** `scripts/run_nlp_extraction.py`
**Extractor:** `extractors/bumeran_extractor.py` â†’ clase `BumeranExtractor`

### ğŸ” Campos ExtraÃ­dos (23 campos)

#### 1. Experiencia (3 campos)
```python
# Ejemplo de texto:
"Requisitos: Experiencia de 2 a 3 aÃ±os en desarrollo Python"

# ExtracciÃ³n:
{
    'experiencia_min_anios': 2,
    'experiencia_max_anios': 3,
    'experiencia_area': 'desarrollo python'
}
```

#### 2. EducaciÃ³n (4 campos)
```python
# Texto: "TÃ­tulo universitario en IngenierÃ­a en Sistemas (excluyente)"

# ExtracciÃ³n:
{
    'nivel_educativo': 'universitario',
    'estado_educativo': 'completo',
    'carrera_especifica': 'IngenierÃ­a en Sistemas',
    'titulo_excluyente': True
}
```

#### 3. Idiomas (4 campos)
```python
# Texto: "InglÃ©s avanzado (excluyente), portuguÃ©s intermedio deseable"

# ExtracciÃ³n:
{
    'idioma_principal': 'inglÃ©s',
    'nivel_idioma_principal': 'avanzado',
    'idioma_secundario': 'portuguÃ©s',
    'nivel_idioma_secundario': 'intermedio'
}
```

#### 4. Skills (2+ campos)
```python
# Texto: "Requisitos tÃ©cnicos: Python, Django, PostgreSQL, Docker"

# ExtracciÃ³n:
{
    'skills_tecnicas_list': ['Python', 'Django', 'PostgreSQL', 'Docker'],
    'soft_skills_list': ['trabajo en equipo', 'comunicaciÃ³n'],
}
```

### ğŸ“Š Calidad de ExtracciÃ³n (Bumeran)

| Campo | Cobertura | Confidence Promedio |
|-------|-----------|---------------------|
| Experiencia | ~60% | 0.5-0.8 |
| EducaciÃ³n | ~55% | 0.5-0.7 |
| Idiomas | ~45% | 0.4-0.7 |
| Skills tÃ©cnicas | ~70% | 0.5-0.8 |
| Soft skills | ~40% | 0.3-0.5 |
| Jornada | ~50% | 0.6-0.9 |
| Salario | ~5% | 0.7-0.9 |

**Nota:** Bumeran tiene la mejor calidad de descripciones (100% cobertura, bien estructuradas).

### ğŸ“¦ Output

| Archivo | DescripciÃ³n |
|---------|-------------|
| `bumeran_nlp_YYYYMMDD_HHMMSS.csv` | CSV con campos NLP extraÃ­dos |
| Ofertas: 2,460 | |
| Columnas: 55 | 32 originales + 23 NLP |
| TamaÃ±o: ~5 MB | |

---

## ğŸ·ï¸ ETAPA 4: MATCHING ESCO

### ğŸ¯ Objetivo
Clasificar ofertas segÃºn taxonomÃ­a ESCO/ISCO-08 y extraer skills asociadas.

### ğŸ“ UbicaciÃ³n
`D:\OEDE\Webscrapping\03_esco_matching\`

### ğŸ”§ Scripts

1. `scripts/esco_isco_llm_fallback.py` - Matching con Claude AI
2. `scripts/manual_matcher_claude.py` - Matching manual perfecto
3. `scripts/enriquecer_con_skills_esco.py` - Agregar skills ESCO
4. `scripts/02_preparar_csv_shiny.py` - Preparar para dashboard

### ğŸ”€ Proceso de Matching

```python
# INPUT
titulo = "Desarrollador Full Stack React + Node.js"

# MATCHING CON CLAUDE AI
â†“
claude_esco_id = "6d1e2801-..."
claude_esco_label = "desarrollador de aplicaciones/desarrolladora de aplicaciones"
claude_isco_code = "2514.1"
claude_confidence = "alta"
claude_razonamiento = "El tÃ­tulo menciona desarrollo full stack con tecnologÃ­as especÃ­ficas..."

# ENRIQUECIMIENTO ESCO SKILLS
â†“
esco_skills_esenciales = [
    "desarrollar prototipos de interfaz de usuario",
    "utilizar marcos de aplicaciones",
    "utilizar lenguajes de programaciÃ³n",
    ...
] (54 skills promedio)

esco_skills_opcionales = [
    "gestiÃ³n de proyectos de TIC",
    "consultar usuarios de TIC",
    ...
] (67 skills promedio)

# PREPARACIÃ“N PARA SHINY (R)
â†“
# Listas Python â†’ strings pipe-separated
esco_skills_esenciales = "desarrollar prototipos | utilizar marcos | ..."
```

### ğŸ“Š Cobertura ESCO

| MÃ©trica | Valor |
|---------|-------|
| Ofertas clasificadas | 268 de 8,472 (3.2%) |
| MÃ©todo | Matching manual perfecto con Claude AI |
| Confidence alta | 156 (58.2%) |
| Confidence media | 44 (16.4%) |
| Confidence baja | 68 (25.4%) |
| Skills promedio/oferta | 54 esenciales + 67 opcionales |

**Nota:** Solo un subset de 268 ofertas tiene clasificaciÃ³n ESCO completa debido al costo de la API de Claude. El resto puede procesarse posteriormente.

### ğŸ“¦ Output Final

| Archivo | DescripciÃ³n |
|---------|-------------|
| `ofertas_esco_shiny.csv` | CSV preparado para dashboard Shiny |
| UbicaciÃ³n | `Visual--/ofertas_esco_shiny.csv` |
| Ofertas | 268 (subset perfecto) |
| Columnas | 48 |
| Features | 100% con ESCO/ISCO + skills + URLs |
| TamaÃ±o | 1.2 MB |

**Columnas clave agregadas:**
- `claude_esco_id`, `claude_esco_label`
- `claude_isco_code`, `isco_nivel1`, `isco_nivel2`, `isco_4d`
- `esco_skills_esenciales` (pipe-separated)
- `esco_skills_opcionales` (pipe-separated)
- `url_oferta` (recuperada del consolidado)

---

## ğŸ“Š ETAPA 5: DASHBOARD SHINY

### ğŸ¯ Objetivo
VisualizaciÃ³n interactiva de ofertas laborales clasificadas con ESCO.

### ğŸ“ UbicaciÃ³n
`D:\OEDE\Webscrapping\Visual--\`

### ğŸŒ Dashboard en ProducciÃ³n

**URL:** https://dos1tv-gerardo-breard.shinyapps.io/dashboard-esco-argentina/

**VersiÃ³n actual:** 2.4.0

**Requiere autenticaciÃ³n:** SÃ­

**Credenciales de prueba:**
- Usuario: `admin` / ContraseÃ±a: `admin123`
- Usuario: `invitado` / ContraseÃ±a: `demo2024`

### ğŸ“Š PestaÃ±as del Dashboard

1. **ğŸ“Š Panorama General**
   - 3 ValueBoxes: Ofertas, Ocupaciones, Skills ESCO
   - DistribuciÃ³n por ISCO Nivel 1 (grÃ¡fico pie)
   - Top 10 ocupaciones mÃ¡s demandadas
   - DistribuciÃ³n geogrÃ¡fica (provincias)

2. **ğŸ‘¤ Perfil Demandado**
   - Requisitos educativos (pie chart)
   - Experiencia requerida por ISCO
   - Top 20 soft skills parseadas
   - Top 20 skills tÃ©cnicas parseadas

3. **ğŸ¯ AnÃ¡lisis de Skills ESCO**
   - Skills esenciales ESCO (top 20)
   - Skills opcionales ESCO (top 30)
   - Tabla skills por categorÃ­a ISCO

4. **ğŸ¢ Ocupaciones ESCO**
   - Tabla: OcupaciÃ³n - ISCO - Provincia
   - DistribuciÃ³n ISCO Nivel 2

5. **ğŸ” Explorador de Ofertas**
   - Buscador por tÃ­tulo
   - Filtro por ISCO (Ã¡rbol navegable en sidebar)
   - Tabla con links clickeables a ofertas originales
   - Descarga de datos filtrados

### ğŸ”§ Filtros Globales

**Barra horizontal superior:**
- Provincia (dropdown)
- Rango de Fechas (dateRangeInput)
- BotÃ³n "Limpiar Todo"

**Sidebar:**
- Ãrbol ESCO navegable (4 niveles jerÃ¡rquicos)
- Click en nodo filtra todo el dashboard

### ğŸ“¦ TecnologÃ­as

```r
# R Packages
library(shiny)              # Framework dashboard
library(shinydashboard)     # Layout y componentes UI
library(shinymanager)       # AutenticaciÃ³n
library(shinyTree)          # Ãrbol navegable
library(dplyr)              # ManipulaciÃ³n datos
library(ggplot2)            # GrÃ¡ficos base
library(plotly)             # GrÃ¡ficos interactivos
library(DT)                 # Tablas interactivas
library(tidyr)              # Utilidades
library(stringr)            # ManipulaciÃ³n strings
library(scales)             # Formatos numÃ©ricos
```

---

## âš¡ Comandos Ejecutables

### ğŸš€ Pipeline Completo (Recomendado)

```bash
# Ejecutar pipeline completo de Bumeran
cd D:\OEDE\Webscrapping
python run_full_pipeline.py --source bumeran

# Con lÃ­mite (testing)
python run_full_pipeline.py --source bumeran --limit 100
```

### ğŸ“¥ Solo Scraping

```bash
# OpciÃ³n 1: Scraping multi-keyword (RECOMENDADO)
cd D:\OEDE\Webscrapping\01_sources\bumeran\scrapers
python scrapear_con_diccionario.py

# OpciÃ³n 2: Scraping directo
python bumeran_scraper.py
```

### ğŸ”„ Solo ConsolidaciÃ³n

```bash
cd D:\OEDE\Webscrapping\02_consolidation\scripts
python consolidar_fuentes.py --fuentes bumeran
```

### ğŸ§  Solo ExtracciÃ³n NLP

```bash
cd D:\OEDE\Webscrapping\02.5_nlp_extraction\scripts
python run_nlp_extraction.py --source bumeran
```

### ğŸ·ï¸ Solo Matching ESCO

```bash
cd D:\OEDE\Webscrapping\03_esco_matching\scripts
python esco_isco_llm_fallback.py --limit 300
```

### ğŸ“Š Dashboard Local

```r
# En RStudio o R terminal
setwd("D:/OEDE/Webscrapping/Visual--")
shiny::runApp("app.R")
```

---

## âš ï¸ Problemas Conocidos

### ğŸ”´ CrÃ­ticos

#### 1. API sin keywords retorna solo 20 ofertas

**Problema:**
```python
# SIN keyword
payload = {"pageSize": 100, "page": 0}
# â†’ API retorna 20 ofertas (independiente de paginaciÃ³n)

# CON keyword
payload = {"query": "python", "pageSize": 100, "page": 0}
# â†’ API retorna hasta 100 ofertas por pÃ¡gina
```

**SoluciÃ³n:**
- SIEMPRE usar keywords del `master_keywords.json`
- Usar `scrapear_con_diccionario.py` que itera automÃ¡ticamente

**UbicaciÃ³n del cÃ³digo:**
`01_sources/bumeran/scrapers/bumeran_scraper.py:108-112`

---

#### 2. Tracking incremental puede corromperse

**Problema:**
Si el archivo `bumeran_scraped_ids.json` se corrompe (encoding, interrupciÃ³n), se pierde el histÃ³rico de IDs scrapeados.

**SoluciÃ³n:**
- Hay backups automÃ¡ticos en `data/tracking/*.bak`
- Validar JSON antes de usar

**CÃ³digo de recuperaciÃ³n:**
```bash
# Restaurar desde Ãºltimo backup
cd D:\OEDE\Webscrapping\data\tracking
copy bumeran_scraped_ids_YYYYMMDD.bak bumeran_scraped_ids.json
```

---

### âš ï¸ Advertencias

#### 3. Modalidad de trabajo incompleta

**Problema:**
~30% de ofertas de Bumeran no especifican modalidad (presencial/remoto/hÃ­brido).

**Impacto:**
AnÃ¡lisis de trabajo remoto incompleto.

**SoluciÃ³n:**
Usar extracciÃ³n NLP como fallback (campo `jornada_laboral`).

---

#### 4. Salarios no publicados

**Problema:**
<5% de ofertas de Bumeran tienen informaciÃ³n salarial.

**Impacto:**
AnÃ¡lisis salarial imposible solo con Bumeran.

**SoluciÃ³n:**
Combinar con otras fuentes (LinkedIn, Indeed) que tienen mejor cobertura de salarios.

---

#### 5. Parsing de ubicaciÃ³n puede fallar

**Problema:**
Formato "Ciudad, Provincia" no siempre es consistente:
- "CABA, Buenos Aires"
- "San Miguel de TucumÃ¡n, TucumÃ¡n"
- "Capital Federal"

**SoluciÃ³n:**
Mapeo manual de provincias principales en `normalizar_campos.py:399-442`.

---

### ğŸ’¡ Mejoras Futuras

#### 6. Rate limiting conservador

**Mejora:** Delay de 2s podrÃ­a reducirse a 1.5s sin riesgo de bloqueo.

#### 7. HTML en descripciones

**Mejora:** Limpiar HTML en scraping para reducir tamaÃ±o de archivos (actualmente se limpia en NLP).

---

## ğŸ“Š Calidad de Datos

### ğŸ“ˆ Completitud por Campo

| Campo | Completitud | Calidad |
|-------|-------------|---------|
| **id_oferta** | 100% | â­â­â­â­â­ |
| **titulo** | 100% | â­â­â­â­â­ |
| **descripcion** | 100% | â­â­â­â­â­ (mejor de todas las fuentes) |
| **empresa** | ~95% | â­â­â­â­ (algunas confidenciales) |
| **localizacion** | ~98% | â­â­â­â­ |
| **modalidad_trabajo** | ~70% | â­â­â­ (muchas sin especificar) |
| **tipo_trabajo** | ~60% | â­â­â­ |
| **fecha_publicacion** | 100% | â­â­â­â­â­ |
| **cantidad_vacantes** | ~30% | â­â­ |
| **salario** | <5% | â­ (rara vez publicado) |

### ğŸ¯ EstadÃ­sticas NLP Extraction

| CategorÃ­a | Cobertura | Confidence |
|-----------|-----------|------------|
| Experiencia | ~60% | 0.5-0.8 |
| EducaciÃ³n | ~55% | 0.5-0.7 |
| Idiomas | ~45% | 0.4-0.7 |
| Skills tÃ©cnicas | ~70% | 0.5-0.8 |
| Soft skills | ~40% | 0.3-0.5 |
| Jornada | ~50% | 0.6-0.9 |

**Nota importante:** Bumeran tiene las mejores descripciones de todas las fuentes analizadas (100% cobertura, bien estructuradas, con detalles tÃ©cnicos).

---

## ğŸ“š DocumentaciÃ³n Adicional

### ğŸ“„ Archivos de DocumentaciÃ³n

1. **README.md de Bumeran**
   - UbicaciÃ³n: `01_sources/bumeran/README.md`
   - Contenido: DocumentaciÃ³n tÃ©cnica completa del scraper

2. **Schema Unificado**
   - UbicaciÃ³n: `shared/schemas/schema_unificado.json`
   - Contenido: EspecificaciÃ³n completa de todos los campos

3. **API de Bumeran**
   - UbicaciÃ³n: `docs/ZONAJOBS_API_DOCUMENTATION.md` (similar para Bumeran)
   - Contenido: Endpoints, headers, parÃ¡metros

4. **DocumentaciÃ³n ESCO**
   - UbicaciÃ³n: `Visual--/docs/ESTRUCTURA_ESCO_ISCO.md`
   - Contenido: JerarquÃ­a completa ESCO (5 niveles)

### ğŸ”— Enlaces Ãštiles

- Dashboard en producciÃ³n: https://dos1tv-gerardo-breard.shinyapps.io/dashboard-esco-argentina/
- ClasificaciÃ³n ESCO: https://esco.ec.europa.eu/es/classification/occupation_main
- ISCO-08: https://www.ilo.org/public/english/bureau/stat/isco/

---

## ğŸ“ Soporte

**Proyecto:** Monitor de Ofertas Laborales - OEDE
**Mantenedor:** Observatorio de Empleo y DinÃ¡mica Empresarial
**Ãšltima actualizaciÃ³n:** 30 de octubre de 2025

---

**FIN DEL DOCUMENTO**
