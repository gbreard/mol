# MOL - Issues Linear v3.0

> **Fecha:** 2025-01-03
> **Estado:** Actualizado - NLP v10, Matching v2.1.1 BGE-M3, Postprocessor v1.0
> **PropÃ³sito:** Issues detallados para implementaciÃ³n con Claude Code

---

## Hitos Completados

| Issue | DescripciÃ³n | Estado | Fecha |
|-------|-------------|--------|-------|
| MOL-62 | NLP Schema v5 - 153 campos estructurados | âœ… Completado | 2025-12-10 |
| MOL-34 | Gold Set Matching expandido a 49 casos | âœ… Completado | 2025-12-10 |
| MOL-63 | Matching v2.1.1 BGE-M3 - 100% precisiÃ³n | âœ… Completado | 2025-12-10 |
| - | NLP Pipeline v10.0 completo | âœ… Completado | 2025-12-14 |
| - | NLP Postprocessor v1.0 | âœ… Completado | 2025-12-14 |
| - | Skills fusiÃ³n LLM+regex | âœ… Completado | 2025-12-14 |
| - | Gold Set NLP 49 casos validados | âœ… Completado | 2025-12-30 |

### Matching v2.1.1 BGE-M3 (ProducciÃ³n)
- **Modelo:** BAAI/bge-m3 (embeddings semÃ¡nticos)
- **PrecisiÃ³n Gold Set:** 100% (49/49 correctos)
- **Archivo principal:** `database/match_ofertas_v2.py`
- **Caso crÃ­tico corregido:** ID 1117984105 "Gerente de Ventas" â†’ Director de ventas (ISCO 1221)

### NLP v10.0 (ProducciÃ³n)
- **Pipeline:** `database/process_nlp_from_db_v10.py`
- **Postprocessor:** `database/nlp_postprocessor.py`
- **PrecisiÃ³n Gold Set:** 96-100% por campo
- **Campos:** 153 (NLP Schema v5)

---

## Resumen de Ã‰picas

| Ã‰pica | Issues | Prioridad Alta |
|-------|--------|----------------|
| 1. Scraping | 4 | 1 |
| 2. NLP | 5 | 3 |
| 3. Matching ESCO | 5 | 4 |
| 4. ValidaciÃ³n | 5 | 3 |
| 5. Dashboards | 5 | 2 |
| 6. Infraestructura | 6 | 1 |
| **Total** | **30** | **14** |

---

# Ã‰PICA 1: SCRAPING

---

## MOL-27: Dashboard Admin - Tab Scraping

### Contexto
El scraping actual tiene mÃºltiples scripts que causan confusiÃ³n. El error mÃ¡s comÃºn es usar `bumeran_scraper.py` directamente (trae ~20 ofertas) en lugar de `run_scheduler.py` (trae ~10,000).

**Estado actual:**
- 10,223 IDs en tracking
- 9,564 ofertas en BD
- 1,148 keywords activos
- Gap se cierra naturalmente (89% cobertura)

### Objetivo
Crear tab de Scraping en dashboard Streamlit que sea el Ãºnico punto de entrada.

### Archivos a Crear/Modificar

```
dashboards/admin/
â”œâ”€â”€ app.py                    # App principal Streamlit
â”œâ”€â”€ tabs/
â”‚   â””â”€â”€ scraping_tab.py       # Este issue
â”œâ”€â”€ components/
â”‚   â””â”€â”€ scraping_status.py    # Widget de estado
â””â”€â”€ utils/
    â””â”€â”€ scraping_runner.py    # Wrapper para run_scheduler
```

### EspecificaciÃ³n UI

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TAB: SCRAPING                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  âš ï¸ IMPORTANTE: Siempre usar este dashboard para scraping.                 â”‚
â”‚     NO ejecutar bumeran_scraper.py directamente.                           â”‚
â”‚                                                                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚                                                                             â”‚
â”‚  BUMERAN (Portal Principal)                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                     â”‚   â”‚
â”‚  â”‚  Estrategia: [ultra_exhaustiva_v3_2 â–¼]                             â”‚   â”‚
â”‚  â”‚  Keywords:   1,148                                                  â”‚   â”‚
â”‚  â”‚  PÃ¡ginas:    1 por keyword (workaround bug API)                    â”‚   â”‚
â”‚  â”‚                                                                     â”‚   â”‚
â”‚  â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€   â”‚   â”‚
â”‚  â”‚                                                                     â”‚   â”‚
â”‚  â”‚  Ãšltima ejecuciÃ³n:   [fecha de BD]                                 â”‚   â”‚
â”‚  â”‚  Ofertas en tracking: [count de tracking JSON]                     â”‚   â”‚
â”‚  â”‚  Ofertas en BD:       [count de SQLite]                            â”‚   â”‚
â”‚  â”‚  PrÃ³xima automÃ¡tica:  [calculado segÃºn config]                     â”‚   â”‚
â”‚  â”‚                                                                     â”‚   â”‚
â”‚  â”‚  [â–¶ï¸ Ejecutar Ahora]                    Estado: [spinner/listo]    â”‚   â”‚
â”‚  â”‚                                                                     â”‚   â”‚
â”‚  â”‚  â˜‘ï¸ Detectar bajas automÃ¡ticamente post-scraping                   â”‚   â”‚
â”‚  â”‚                                                                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚                                                                             â”‚
â”‚  OTROS PORTALES (Futuro)                                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Portal       â”‚ Estado      â”‚ Ãšltima    â”‚ Ofertas â”‚ AcciÃ³n          â”‚   â”‚
â”‚  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚   â”‚
â”‚  â”‚ ZonaJobs     â”‚ âœ… Listo    â”‚ -         â”‚ 0       â”‚ [Activar]       â”‚   â”‚
â”‚  â”‚ Computrabajo â”‚ âš ï¸ Revisar  â”‚ -         â”‚ 0       â”‚ [Configurar]    â”‚   â”‚
â”‚  â”‚ LinkedIn     â”‚ âš ï¸ Limited  â”‚ -         â”‚ 0       â”‚ [Configurar]    â”‚   â”‚
â”‚  â”‚ Indeed       â”‚ âš ï¸ Limited  â”‚ -         â”‚ 0       â”‚ [Configurar]    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚                                                                             â”‚
â”‚  ProgramaciÃ³n automÃ¡tica:                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚
â”‚  â”‚ DÃ­as: [Lun,Jue] â”‚ â”‚ Hora: [08:00]   â”‚  [Guardar Config]                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                   â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### CÃ³digo Referencia

```python
# dashboards/admin/utils/scraping_runner.py

import subprocess
import json
from pathlib import Path
from datetime import datetime

class ScrapingRunner:
    def __init__(self, base_path: str):
        self.base_path = Path(base_path)
        self.tracking_path = self.base_path / "data/tracking/bumeran_scraped_ids.json"
        self.db_path = self.base_path / "database/mol_database.db"
    
    def get_status(self) -> dict:
        """Obtener estado actual del scraping"""
        tracking_count = 0
        if self.tracking_path.exists():
            with open(self.tracking_path) as f:
                data = json.load(f)
                tracking_count = len(data.get("seen_ids", []))
        
        # Query SQLite para ofertas activas
        import sqlite3
        conn = sqlite3.connect(self.db_path)
        cursor = conn.execute("SELECT COUNT(*) FROM ofertas WHERE estado_oferta = 'activa'")
        db_count = cursor.fetchone()[0]
        conn.close()
        
        return {
            "tracking_count": tracking_count,
            "db_count": db_count,
            "last_run": self._get_last_run(),
            "next_run": self._get_next_run()
        }
    
    def run_scraping(self, detect_bajas: bool = True) -> dict:
        """Ejecutar scraping con detecciÃ³n de bajas opcional"""
        result = subprocess.run(
            ["python", "run_scheduler.py", "--test"],
            cwd=self.base_path,
            capture_output=True,
            text=True
        )
        
        if detect_bajas and result.returncode == 0:
            subprocess.run(
                ["python", "database/detectar_bajas_integrado.py"],
                cwd=self.base_path,
                capture_output=True
            )
        
        return {
            "success": result.returncode == 0,
            "output": result.stdout,
            "error": result.stderr
        }
```

### Criterios de AceptaciÃ³n

- [ ] Tab Scraping funcional en Streamlit
- [ ] Muestra estado actual (tracking, BD, Ãºltima ejecuciÃ³n)
- [ ] BotÃ³n ejecuta `run_scheduler.py --test`
- [ ] Checkbox para detectar bajas post-scraping
- [ ] Spinner durante ejecuciÃ³n
- [ ] Mensaje de Ã©xito/error al finalizar
- [ ] Config de programaciÃ³n guardable

### Prioridad: ğŸ”´ Alta

### Labels: `dashboard`, `scraping`, `feature`

### EstimaciÃ³n: 4h

---

## MOL-28: Activar Scraper ZonaJobs

### Contexto
ZonaJobs es el segundo portal mÃ¡s importante. El scraper existe y funciona pero no estÃ¡ integrado al scheduler.

### Objetivo
Integrar ZonaJobs al flujo de scraping semanal.

### Archivos Involucrados

```
01_sources/zonajobs/
â”œâ”€â”€ zonajobs_scraper_final.py   # Scraper existente
â””â”€â”€ config.py                   # ConfiguraciÃ³n

run_scheduler.py                # Agregar ZonaJobs
```

### Criterios de AceptaciÃ³n

- [ ] ZonaJobs se ejecuta despuÃ©s de Bumeran
- [ ] Ofertas se insertan en misma BD
- [ ] DeduplicaciÃ³n cross-portal funciona
- [ ] Tab Scraping muestra estado ZonaJobs

### Prioridad: ğŸŸ¡ Media

### Labels: `scraping`, `feature`

### EstimaciÃ³n: 3h

---

## MOL-29: DeduplicaciÃ³n Cross-Portal

### Contexto
Cuando se activen mÃºltiples portales, habrÃ¡ ofertas duplicadas (misma empresa publica en varios sitios).

### Objetivo
Detectar y marcar duplicados antes del procesamiento NLP.

### Algoritmo

```python
# Blocking: Provincia + semana (reduce O(nÂ²) a O(nÃ—k))
# Scoring: TÃ­tulo 40% + DescripciÃ³n 35% + Empresa 15% + Salario 10%
# Threshold: >= 0.85 duplicado, 0.70-0.84 revisar
# Grupos: Union-Find para clusters de duplicados
```

### Archivos a Crear

```
database/
â””â”€â”€ deduplicate_cross_portal.py

# Campos a agregar en BD:
# - grupo_duplicado: "DUP-00001"
# - es_duplicado: 0/1
# - es_canonico: 0/1 (cuÃ¡l es la versiÃ³n principal)
```

### Criterios de AceptaciÃ³n

- [ ] Script detecta duplicados con precisiÃ³n >= 95%
- [ ] No marca falsos positivos
- [ ] Campos agregados a BD
- [ ] Ejecutable desde dashboard

### Prioridad: ğŸŸ¡ Media

### Labels: `scraping`, `etl`, `feature`

### EstimaciÃ³n: 4h

---

# Ã‰PICA 2: NLP

---

## MOL-30: Gold Set NLP (200+ casos)

### Contexto
Actualmente no existe gold set para NLP. Se necesitan 200+ casos validados campo por campo para medir precisiÃ³n del pipeline.

### Objetivo
Crear gold set con 200+ ofertas validadas manualmente.

### Estructura Propuesta

```json
{
  "version": "1.0",
  "created": "2025-12-07",
  "cases": [
    {
      "id": "1118027662",
      "raw": {
        "titulo": "Vendedor Senior B2B",
        "descripcion": "Buscamos vendedor con 3+ aÃ±os...",
        "empresa": "Confidencial",
        "ubicacion": "CABA"
      },
      "expected": {
        "experiencia_min_anios": 3,
        "nivel_educativo": "secundario",
        "modalidad": "presencial",
        "area_funcional": "ventas",
        "nivel_seniority": "senior",
        "tech_skills": ["CRM"],
        "soft_skills": ["negociaciÃ³n", "comunicaciÃ³n"]
      },
      "validation_source": "manual",
      "validated_by": "gerardo",
      "validated_at": "2025-12-07"
    }
  ]
}
```

### Estrategia de Muestreo

| Criterio | Casos | % |
|----------|-------|---|
| Por familia funcional | 100 | 50% |
| Por score NLP | 50 | 25% |
| Por tipo de oferta | 30 | 15% |
| Aleatorio | 20 | 10% |

### Archivos a Crear

```
database/
â”œâ”€â”€ nlp_gold_set_v1.json        # Gold set
â”œâ”€â”€ test_nlp_gold_set.py        # Test automÃ¡tico
â””â”€â”€ generate_nlp_sample.py      # Generador de muestra
```

### Criterios de AceptaciÃ³n

- [ ] 200+ casos validados
- [ ] DistribuciÃ³n por familia funcional
- [ ] Test automÃ¡tico que mide precisiÃ³n por campo
- [ ] Baseline documentado

### Prioridad: ğŸ”´ Alta

### Labels: `nlp`, `eval-calidad`, `feature`

### EstimaciÃ³n: 8h (validaciÃ³n manual)

---

## MOL-31: Test AutomÃ¡tico NLP

### Contexto
Se necesita script que evalÃºe NLP pipeline contra gold set y reporte precisiÃ³n por campo.

### Objetivo
Crear `test_nlp.py` que ejecute evaluaciÃ³n completa.

### Output Esperado

```
=== NLP EVALUATION REPORT ===
Gold Set: nlp_gold_set_v1.json (200 cases)
Pipeline: v8.0

OVERALL METRICS:
  Precision: 91.2%
  Cases passed: 182/200

BY FIELD:
  experiencia_min_anios:  94.5% (189/200)
  nivel_educativo:        88.0% (176/200)
  area_funcional:         92.0% (184/200)
  modalidad:              96.5% (193/200)
  tech_skills:            85.0% (170/200)
  soft_skills:            82.5% (165/200)

BY FAMILY:
  comercial:    93.0% (28/30)
  tecnologia:   89.0% (27/30)
  salud:        91.0% (27/30)
  ...

FAILED CASES:
  1118027662: experiencia_min_anios expected 3, got 5
  1118028376: area_funcional expected admin, got negocios
  ...
```

### Archivos a Crear

```
database/
â””â”€â”€ test_nlp.py
```

### CÃ³digo Referencia

```python
# database/test_nlp.py

import json
from pathlib import Path
from nlp.nlp_pipeline_v8 import NLPPipeline

class NLPEvaluator:
    def __init__(self, gold_set_path: str):
        self.gold_set = self._load_gold_set(gold_set_path)
        self.pipeline = NLPPipeline()
        
    def evaluate(self) -> dict:
        results = {
            "total": len(self.gold_set["cases"]),
            "passed": 0,
            "by_field": {},
            "by_family": {},
            "failed_cases": []
        }
        
        for case in self.gold_set["cases"]:
            predicted = self.pipeline.process(case["raw"])
            case_result = self._compare(case["expected"], predicted)
            
            if case_result["passed"]:
                results["passed"] += 1
            else:
                results["failed_cases"].append({
                    "id": case["id"],
                    "errors": case_result["errors"]
                })
            
            # Agregar a mÃ©tricas por campo y familia
            self._update_metrics(results, case, case_result)
        
        return results
    
    def _compare(self, expected: dict, predicted: dict) -> dict:
        errors = []
        for field, expected_value in expected.items():
            predicted_value = predicted.get(field)
            if not self._values_match(expected_value, predicted_value):
                errors.append({
                    "field": field,
                    "expected": expected_value,
                    "predicted": predicted_value
                })
        
        return {
            "passed": len(errors) == 0,
            "errors": errors
        }

if __name__ == "__main__":
    evaluator = NLPEvaluator("database/nlp_gold_set_v1.json")
    results = evaluator.evaluate()
    evaluator.print_report(results)
```

### Criterios de AceptaciÃ³n

- [ ] Script ejecutable: `python database/test_nlp.py`
- [ ] Reporte por campo, familia, y casos fallidos
- [ ] Exit code 0 si >= 90%, 1 si < 90%
- [ ] Integrable en CI/CD

### Prioridad: ğŸ”´ Alta

### Labels: `nlp`, `eval-calidad`, `feature`

### EstimaciÃ³n: 3h

---

## MOL-32: Export NLP a S3

### Contexto
Los datos parseados deben exportarse a S3 para validaciÃ³n colaborativa.

### Objetivo
Crear `export_nlp.py` que sube datos a S3/experiment/nlp/.

### Formato de Export

```json
// S3/experiment/nlp/2025-W50/parsed.json.gz
{
  "version": "nlp-v8.0",
  "exported_at": "2025-12-07T10:00:00Z",
  "total_offers": 800,
  "offers": [
    {
      "id": "1118027662",
      "titulo": "Vendedor Senior B2B",
      "parsed": {
        "experiencia_min_anios": 3,
        "nivel_educativo": "secundario",
        // ... todos los campos NLP
      },
      "nlp_score": 5,
      "nlp_version": "v8.0"
    }
  ]
}
```

### Archivos a Crear

```
exports/
â””â”€â”€ export_nlp.py
```

### Criterios de AceptaciÃ³n

- [ ] Exporta a S3/experiment/nlp/{semana}/
- [ ] Formato JSON comprimido (gzip)
- [ ] Actualiza S3/experiment/nlp/latest.json
- [ ] Ejecutable desde dashboard

### Prioridad: ğŸ”´ Alta

### Labels: `nlp`, `infra`, `feature`

### EstimaciÃ³n: 2h

---

## MOL-33: Sync Validaciones NLP

### Contexto
Los validadores escriben feedback en S3. Necesitamos sincronizar esas validaciones al local.

### Objetivo
Crear `sync_validations.py` que descarga validaciones y actualiza gold set.

### Flujo

```
S3/experiment/nlp/{semana}/validations.json
                â”‚
                â–¼
sync_validations.py
                â”‚
                â”œâ”€â”€ Descarga validaciones nuevas
                â”œâ”€â”€ Merge con gold set local
                â””â”€â”€ Actualiza nlp_gold_set_v1.json
```

### Criterios de AceptaciÃ³n

- [ ] Descarga validaciones de S3
- [ ] Merge inteligente (no duplicados)
- [ ] Actualiza gold set local
- [ ] Log de cambios

### Prioridad: ğŸŸ¡ Media

### Labels: `nlp`, `infra`, `feature`

### EstimaciÃ³n: 2h

---

# Ã‰PICA 3: MATCHING ESCO

---

## MOL-5: Resolver sector_funcion (v8.4)

### Contexto
50% de errores actuales son tipo `sector_funcion`: ofertas matchean a ocupaciones ESCO de sectores completamente diferentes.

**Ejemplos:**
- "Ejecutivo de cuentas" â†’ "Agente de empleo" (deberÃ­a ser ventas)
- "Account Executive Hunter" â†’ "Reclutador" (deberÃ­a ser comercial)

**Historial:**
- v8.1: Ajustes nivel jerÃ¡rquico â†’ No resolviÃ³
- v8.2: 6 familias funcionales â†’ MejorÃ³ categorizaciÃ³n
- v8.3: +4 familias â†’ 57.9% â†’ 78.9%

### Objetivo
Alcanzar >= 95% precisiÃ³n en matching, con <= 1 error sector_funcion.

### Archivos Involucrados

```
database/
â”œâ”€â”€ matching_rules_v84.py       # CREAR (copiar de v83)
â”œâ”€â”€ matching_rules_v83.py       # Referencia
â”œâ”€â”€ gold_set_manual_v1.json     # 19 casos actuales
â””â”€â”€ test_gold_set_manual.py     # Actualizar para v84
```

### Estrategia Propuesta

1. **Keywords mÃ¡s especÃ­ficos por familia:**
   - VENTAS_B2B: "account executive", "hunter", "closer", "sales"
   - RRHH_ESCO: "agente de empleo", "reclutador interno"

2. **Reglas never_confirm:**
   - Si tÃ­tulo contiene "ventas/sales" â†’ nunca RRHH
   - Si tÃ­tulo contiene "account" sin "payable/receivable" â†’ nunca contabilidad

3. **Boost por contexto:**
   - Si descripciÃ³n menciona "cuota", "comisiÃ³n" â†’ boost ventas
   - Si menciona "selecciÃ³n de personal" â†’ boost RRHH

### Criterios de AceptaciÃ³n

- [ ] PrecisiÃ³n gold set >= 95% (actual: 78.9%)
- [ ] Errores sector_funcion <= 1 (actual: 4)
- [ ] Sin regresiones en casos correctos
- [ ] Documentado en CHANGELOG.md

### Prioridad: ğŸ”´ Alta

### Labels: `matching`, `esco`, `feature`

### EstimaciÃ³n: 6h

---

## MOL-34: Expandir Gold Set Matching (200+ casos)

### Contexto
El gold set actual tiene solo 19 casos. Se necesitan 200+ para evaluaciÃ³n confiable.

### Estrategia de Muestreo

| Familia | Casos | % |
|---------|-------|---|
| comercial | 30 | 15% |
| tecnologia | 25 | 12.5% |
| administracion | 25 | 12.5% |
| salud | 20 | 10% |
| manufactura | 20 | 10% |
| logistica | 20 | 10% |
| educacion | 15 | 7.5% |
| gastronomia | 15 | 7.5% |
| construccion | 15 | 7.5% |
| servicios | 15 | 7.5% |

**Dentro de cada familia:**
- 50% casos score alto (>= 0.70)
- 30% casos score medio (0.50-0.70)
- 20% casos score bajo (< 0.50)

### Archivos a Crear

```
database/
â”œâ”€â”€ matching_gold_set_v2.json   # Gold set expandido
â””â”€â”€ generate_matching_sample.py # Generador de muestra
```

### Criterios de AceptaciÃ³n

- [ ] 200+ casos validados
- [ ] DistribuciÃ³n por familia
- [ ] DistribuciÃ³n por score
- [ ] Formato compatible con test existente

### Prioridad: ğŸ”´ Alta

### Labels: `matching`, `eval-calidad`, `feature`

### EstimaciÃ³n: 8h (validaciÃ³n manual)

---

## MOL-35: Export Matching a S3

### Contexto
Los datos matcheados deben exportarse a S3 para validaciÃ³n.

### Formato de Export

```json
// S3/experiment/matching/2025-W50/matched.json.gz
{
  "version": "matching-v8.3",
  "exported_at": "2025-12-07T10:00:00Z",
  "offers": [
    {
      "id": "1118027662",
      "titulo": "Vendedor Senior B2B",
      "esco_uri": "http://data.europa.eu/esco/occupation/abc123",
      "esco_label": "representante tÃ©cnico de ventas",
      "isco_code": "3322",
      "match_score": 0.72,
      "familia_funcional": "comercial_ventas",
      "candidates": [
        {"uri": "...", "label": "...", "score": 0.72},
        {"uri": "...", "label": "...", "score": 0.68},
        {"uri": "...", "label": "...", "score": 0.65}
      ]
    }
  ]
}
```

### Criterios de AceptaciÃ³n

- [ ] Exporta a S3/experiment/matching/{semana}/
- [ ] Incluye top 3 candidatos
- [ ] Formato JSON comprimido
- [ ] Ejecutable desde dashboard

### Prioridad: ğŸ”´ Alta

### Labels: `matching`, `infra`, `feature`

### EstimaciÃ³n: 2h

---

# Ã‰PICA 4: VALIDACIÃ“N

---

## MOL-36: Dashboard Admin - Tab Tests

### Contexto
Necesitamos tab para ejecutar tests contra gold sets y ver resultados.

### UI Propuesta

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TAB: TESTS                                                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  NLP PIPELINE (v8.0)                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Gold Set: nlp_gold_set_v1.json (200 casos)                        â”‚   â”‚
â”‚  â”‚                                                                     â”‚   â”‚
â”‚  â”‚  Ãšltima ejecuciÃ³n: 2025-12-07 10:00                                â”‚   â”‚
â”‚  â”‚  PrecisiÃ³n: 91.2% âœ… (umbral: 90%)                                 â”‚   â”‚
â”‚  â”‚                                                                     â”‚   â”‚
â”‚  â”‚  [â–¶ï¸ Ejecutar Test]  [ğŸ“Š Ver Detalle]                              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                             â”‚
â”‚  MATCHING (v8.3)                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Gold Set: matching_gold_set_v2.json (200 casos)                   â”‚   â”‚
â”‚  â”‚                                                                     â”‚   â”‚
â”‚  â”‚  Ãšltima ejecuciÃ³n: 2025-12-07 10:00                                â”‚   â”‚
â”‚  â”‚  PrecisiÃ³n: 78.9% âŒ (umbral: 95%)                                 â”‚   â”‚
â”‚  â”‚                                                                     â”‚   â”‚
â”‚  â”‚  [â–¶ï¸ Ejecutar Test]  [ğŸ“Š Ver Detalle]                              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                             â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”‚
â”‚                                                                             â”‚
â”‚  DETALLE (expandible)                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Por Campo:                     Por Familia:                        â”‚   â”‚
â”‚  â”‚  experiencia: 94.5% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    comercial:    93.0% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        â”‚   â”‚
â”‚  â”‚  educacion:   88.0% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     tecnologia:   89.0% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        â”‚   â”‚
â”‚  â”‚  modalidad:   96.5% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   salud:        91.0% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ        â”‚   â”‚
â”‚  â”‚  ...                            ...                                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                             â”‚
â”‚  CASOS FALLIDOS                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  ID          â”‚ Campo/Match      â”‚ Esperado    â”‚ Obtenido           â”‚   â”‚
â”‚  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚   â”‚
â”‚  â”‚ 1118027662   â”‚ experiencia      â”‚ 3 aÃ±os      â”‚ 5 aÃ±os             â”‚   â”‚
â”‚  â”‚ 1118028376   â”‚ area_funcional   â”‚ admin       â”‚ negocios           â”‚   â”‚
â”‚  â”‚ ...          â”‚ ...              â”‚ ...         â”‚ ...                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Criterios de AceptaciÃ³n

- [ ] Muestra estado de ambos tests
- [ ] Indicador visual pass/fail
- [ ] BotÃ³n para ejecutar
- [ ] Detalle expandible por campo/familia
- [ ] Lista de casos fallidos

### Prioridad: ğŸ”´ Alta

### Labels: `dashboard`, `eval-calidad`, `feature`

### EstimaciÃ³n: 4h

---

## MOL-37: Dashboard Admin - Tab S3 Sync

### Contexto
Necesitamos tab para exportar datos a S3 y sincronizar validaciones.

### UI Propuesta

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TAB: S3 SYNC                                                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  EXPORTAR A S3                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                     â”‚   â”‚
â”‚  â”‚  Semana: [2025-W50 â–¼]                                              â”‚   â”‚
â”‚  â”‚                                                                     â”‚   â”‚
â”‚  â”‚  â˜‘ï¸ Exportar NLP (800 ofertas parseadas)                           â”‚   â”‚
â”‚  â”‚  â˜‘ï¸ Exportar Matching (800 ofertas matcheadas)                     â”‚   â”‚
â”‚  â”‚  â˜ Exportar a ProducciÃ³n (requiere tests pasados)                  â”‚   â”‚
â”‚  â”‚                                                                     â”‚   â”‚
â”‚  â”‚  [â–¶ï¸ Exportar]                           Estado: Listo             â”‚   â”‚
â”‚  â”‚                                                                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                             â”‚
â”‚  SINCRONIZAR VALIDACIONES                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                     â”‚   â”‚
â”‚  â”‚  Validaciones pendientes en S3: 45                                 â”‚   â”‚
â”‚  â”‚  Ãšltima sincronizaciÃ³n: 2025-12-06 18:00                           â”‚   â”‚
â”‚  â”‚                                                                     â”‚   â”‚
â”‚  â”‚  [â–¶ï¸ Sincronizar]                        [ğŸ“Š Ver Validaciones]     â”‚   â”‚
â”‚  â”‚                                                                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                             â”‚
â”‚  ESTADO S3                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Bucket: mol-validation-data                                       â”‚   â”‚
â”‚  â”‚  RegiÃ³n: sa-east-1                                                 â”‚   â”‚
â”‚  â”‚                                                                     â”‚   â”‚
â”‚  â”‚  /experiment/nlp/      12 semanas, 9,600 ofertas                   â”‚   â”‚
â”‚  â”‚  /experiment/matching/ 12 semanas, 9,600 ofertas                   â”‚   â”‚
â”‚  â”‚  /production/          48 semanas, 38,400 ofertas                  â”‚   â”‚
â”‚  â”‚  /goldset/             2 archivos                                  â”‚   â”‚
â”‚  â”‚                                                                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Criterios de AceptaciÃ³n

- [ ] Exportar NLP y Matching a S3
- [ ] Sincronizar validaciones de S3
- [ ] Mostrar estado del bucket
- [ ] Bloquear export producciÃ³n si tests no pasan

### Prioridad: ğŸ”´ Alta

### Labels: `dashboard`, `infra`, `feature`

### EstimaciÃ³n: 4h

---

## MOL-38: Generate Sample (Muestra Estratificada)

### Contexto
Para validaciÃ³n humana, necesitamos generar muestras estratificadas.

### EspecificaciÃ³n

```python
# generate_sample.py

def generate_sample(
    n: int = 90,
    by_family: bool = True,
    by_score: bool = True,
    include_random: float = 0.10
) -> pd.DataFrame:
    """
    Genera muestra estratificada para validaciÃ³n.
    
    Args:
        n: Total de casos
        by_family: Estratificar por familia funcional
        by_score: Estratificar por score
        include_random: Porcentaje aleatorio (control)
    
    Returns:
        DataFrame con ofertas seleccionadas
    """
```

### DistribuciÃ³n (90 casos)

| Estrato | Casos | % |
|---------|-------|---|
| Por familia (10 familias Ã— 5) | 50 | 56% |
| Score bajo (< 0.50) | 15 | 17% |
| Score medio (0.50-0.70) | 15 | 17% |
| Aleatorio (control) | 10 | 11% |

### Criterios de AceptaciÃ³n

- [ ] Genera muestra con distribuciÃ³n correcta
- [ ] Exporta a JSON para validaciÃ³n
- [ ] No incluye casos ya validados
- [ ] Reproducible con seed

### Prioridad: ğŸŸ¡ Media

### Labels: `eval-calidad`, `feature`

### EstimaciÃ³n: 2h

---

## MOL-39: Dashboard ValidaciÃ³n (Vercel)

### Contexto
Dashboard web para que los 3 admins validen ofertas remotamente.

### Stack

- Next.js 14
- TypeScript
- Tailwind CSS
- AWS SDK (S3)

### Funcionalidades

1. **Login simple** (3 usuarios predefinidos)
2. **Lista de ofertas** pendientes de validaciÃ³n
3. **Vista de validaciÃ³n NLP** (campo por campo)
4. **Vista de validaciÃ³n Matching** (ocupaciÃ³n correcta)
5. **Submit** â†’ escribe a S3

### UI ValidaciÃ³n NLP

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  VALIDACIÃ“N NLP - Oferta 1118027662                    [Anterior] [Siguiente]â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  OFERTA ORIGINAL                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  TÃ­tulo: Vendedor Senior B2B                                        â”‚   â”‚
â”‚  â”‚  Empresa: Confidencial                                              â”‚   â”‚
â”‚  â”‚                                                                     â”‚   â”‚
â”‚  â”‚  DescripciÃ³n:                                                       â”‚   â”‚
â”‚  â”‚  Buscamos vendedor con 3+ aÃ±os de experiencia en ventas B2B.       â”‚   â”‚
â”‚  â”‚  Requisitos: Secundario completo, manejo de CRM...                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                             â”‚
â”‚  CAMPOS EXTRAÃDOS                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Campo              â”‚ Valor extraÃ­do  â”‚ ValidaciÃ³n                 â”‚   â”‚
â”‚  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚   â”‚
â”‚  â”‚  experiencia_anios  â”‚ 3               â”‚ âœ… Correcto  âŒ Incorrecto â”‚   â”‚
â”‚  â”‚  nivel_educativo    â”‚ secundario      â”‚ âœ… Correcto  âŒ Incorrecto â”‚   â”‚
â”‚  â”‚  area_funcional     â”‚ ventas          â”‚ âœ… Correcto  âŒ Incorrecto â”‚   â”‚
â”‚  â”‚  tech_skills        â”‚ [CRM]           â”‚ âœ… Correcto  âŒ Incorrecto â”‚   â”‚
â”‚  â”‚  ...                â”‚ ...             â”‚                            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                             â”‚
â”‚  Comentario (opcional): [________________________________]                 â”‚
â”‚                                                                             â”‚
â”‚  [ğŸ’¾ Guardar y Siguiente]                                                  â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Criterios de AceptaciÃ³n

- [ ] Deploy en Vercel
- [ ] Login funcional (3 usuarios)
- [ ] ValidaciÃ³n NLP campo por campo
- [ ] ValidaciÃ³n Matching con candidatos
- [ ] Escribe a S3 correctamente
- [ ] Responsive (mobile friendly)

### Prioridad: ğŸŸ¡ Media

### Labels: `dashboard`, `feature`

### EstimaciÃ³n: 12h

---

## MOL-40: Export ProducciÃ³n

### Contexto
Cuando NLP >= 90% y Matching >= 95%, exportar a S3/production/.

### Formato Parquet

```python
# Columnas principales
columns = [
    "id", "titulo", "empresa", "provincia", "localidad",
    "fecha_publicacion", "url_fuente", "portal",
    
    # NLP
    "experiencia_min_anios", "nivel_educativo", "modalidad",
    "area_funcional", "nivel_seniority", "tech_skills", "soft_skills",
    
    # Matching
    "esco_uri", "esco_label", "isco_code", "match_score",
    "familia_funcional",
    
    # ESCO Skills
    "esco_essential_skills", "esco_optional_skills",
    "esco_essential_knowledge", "esco_optional_knowledge",
    
    # Permanencia
    "estado_oferta", "dias_publicada", "categoria_permanencia"
]
```

### Estructura S3

```
S3/production/
â”œâ”€â”€ current/
â”‚   â””â”€â”€ ofertas.parquet          # Lambda lee esto
â”œâ”€â”€ history/
â”‚   â””â”€â”€ year=2025/
â”‚       â”œâ”€â”€ week=49/ofertas.parquet
â”‚       â””â”€â”€ week=50/ofertas.parquet
â””â”€â”€ metadata.json
```

### Criterios de AceptaciÃ³n

- [ ] Solo exporta si tests pasan
- [ ] Formato Parquet particionado
- [ ] Actualiza /current/ y /history/
- [ ] Actualiza metadata.json
- [ ] Log de export

### Prioridad: ğŸ”´ Alta

### Labels: `infra`, `feature`

### EstimaciÃ³n: 3h

---

# Ã‰PICA 5: DASHBOARDS

---

## MOL-41: Dashboard Admin - App Principal

### Contexto
App Streamlit principal que integra todos los tabs.

### Estructura

```python
# dashboards/admin/app.py

import streamlit as st
from tabs import scraping_tab, pipeline_tab, tests_tab, s3_tab, logs_tab

st.set_page_config(
    page_title="MOL Admin",
    page_icon="ğŸ“Š",
    layout="wide"
)

# Sidebar con navegaciÃ³n
tab = st.sidebar.radio(
    "NavegaciÃ³n",
    ["Scraping", "Pipeline", "Tests", "S3 Sync", "Logs"]
)

# Render tab seleccionado
if tab == "Scraping":
    scraping_tab.render()
elif tab == "Pipeline":
    pipeline_tab.render()
# ...
```

### Criterios de AceptaciÃ³n

- [ ] App funcional con 5 tabs
- [ ] NavegaciÃ³n por sidebar
- [ ] Persistencia de estado entre tabs
- [ ] Ejecutable: `streamlit run dashboards/admin/app.py`

### Prioridad: ğŸ”´ Alta

### Labels: `dashboard`, `feature`

### EstimaciÃ³n: 2h

---

## MOL-42: Dashboard Admin - Tab Pipeline

### Contexto
Tab para ejecutar NLP y Matching sobre ofertas.

### UI Propuesta

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TAB: PIPELINE                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  OFERTAS PENDIENTES                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Sin procesar NLP:     847                                          â”‚   â”‚
â”‚  â”‚  Sin procesar Matching: 123                                         â”‚   â”‚
â”‚  â”‚  Listas para producciÃ³n: 9,441                                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                             â”‚
â”‚  EJECUTAR PIPELINE                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                                                                     â”‚   â”‚
â”‚  â”‚  Batch size: [100 â–¼]                                               â”‚   â”‚
â”‚  â”‚                                                                     â”‚   â”‚
â”‚  â”‚  â˜‘ï¸ Ejecutar NLP                                                   â”‚   â”‚
â”‚  â”‚  â˜‘ï¸ Ejecutar Matching                                              â”‚   â”‚
â”‚  â”‚  â˜ Solo ofertas nuevas                                             â”‚   â”‚
â”‚  â”‚                                                                     â”‚   â”‚
â”‚  â”‚  [â–¶ï¸ Ejecutar]                                                     â”‚   â”‚
â”‚  â”‚                                                                     â”‚   â”‚
â”‚  â”‚  Progreso: â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 60% (60/100)                       â”‚   â”‚
â”‚  â”‚  Tiempo estimado: 2:30 restantes                                   â”‚   â”‚
â”‚  â”‚                                                                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                             â”‚
â”‚  ÃšLTIMAS EJECUCIONES                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Fecha       â”‚ Tipo     â”‚ Ofertas â”‚ Tiempo  â”‚ Estado              â”‚   â”‚
â”‚  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚   â”‚
â”‚  â”‚  07/12 10:00 â”‚ NLP      â”‚ 100     â”‚ 4:32    â”‚ âœ… Completado       â”‚   â”‚
â”‚  â”‚  07/12 10:05 â”‚ Matching â”‚ 100     â”‚ 1:15    â”‚ âœ… Completado       â”‚   â”‚
â”‚  â”‚  06/12 18:00 â”‚ Full     â”‚ 800     â”‚ 45:00   â”‚ âœ… Completado       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Criterios de AceptaciÃ³n

- [ ] Muestra ofertas pendientes
- [ ] Ejecuta NLP y/o Matching
- [ ] Barra de progreso
- [ ] Historial de ejecuciones
- [ ] Manejo de errores

### Prioridad: ğŸŸ¡ Media

### Labels: `dashboard`, `feature`

### EstimaciÃ³n: 4h

---

## MOL-43: Dashboard ProducciÃ³n (Vercel)

### Contexto
Dashboard para analistas OEDE con datos limpios.

### Stack

- Next.js 14
- TypeScript
- Tailwind CSS
- Recharts (grÃ¡ficos)
- AWS Lambda (backend)

### 3 PestaÃ±as

Ver DASHBOARD_WIREFRAMES.md para wireframes completos.

| Tab | Contenido |
|-----|-----------|
| Panorama General | KPIs + EvoluciÃ³n + Top 10 ocupaciones |
| Requerimientos | 4 tortas + Top 20 skills |
| Ofertas Laborales | Tabla explorable |

### Criterios de AceptaciÃ³n

- [ ] Deploy en Vercel
- [ ] 3 tabs funcionales
- [ ] Filtros globales operativos
- [ ] GrÃ¡ficos con descarga Excel/CSV
- [ ] Responsive
- [ ] Sin siglas tÃ©cnicas (CIUO, ESCO)

### Prioridad: ğŸŸ¡ Media

### Labels: `dashboard`, `feature`

### EstimaciÃ³n: 16h

---

## MOL-44: Lambda API Backend

### Contexto
API serverless para dashboard de producciÃ³n.

### Endpoints

```
GET /ofertas
  ?territorio=nacional|provincial|localidad
  &periodo=semana|mes|aÃ±o
  &permanencia=todas|baja|media|alta
  &familia=comercial|tecnologia|...
  &page=1&limit=20

GET /metricas/panorama
  â†’ KPIs, evoluciÃ³n, top 10

GET /metricas/requerimientos
  â†’ Distribuciones edad, gÃ©nero, educaciÃ³n, skills

GET /ocupaciones/arbol
  â†’ Ãrbol jerÃ¡rquico de ocupaciones

GET /export
  ?format=csv|xlsx
  â†’ Descarga de datos filtrados
```

### Stack

- Python 3.11
- PyArrow (leer Parquet)
- Pandas (filtros)
- API Gateway + Lambda

### Criterios de AceptaciÃ³n

- [ ] 4 endpoints funcionales
- [ ] Lee de S3/production/current/ofertas.parquet
- [ ] Responde en < 500ms
- [ ] Free tier AWS
- [ ] CORS configurado

### Prioridad: ğŸŸ¡ Media

### Labels: `api`, `infra`, `feature`

### EstimaciÃ³n: 6h

---

# Ã‰PICA 6: INFRAESTRUCTURA

---

## MOL-23: Backup AutomÃ¡tico SQLite

### Estado: âœ… Completado

Script de backup ya implementado.

---

## MOL-45: Dashboard Admin - Tab Logs

### Contexto
Tab para ver logs de ejecuciones.

### UI Propuesta

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TAB: LOGS                                                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  Filtros: [Todos â–¼] [Ãšltimas 24h â–¼] [ğŸ” Buscar...]                        â”‚
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  2025-12-07 10:05:32 [INFO] Matching completado: 100 ofertas        â”‚   â”‚
â”‚  â”‚  2025-12-07 10:00:15 [INFO] NLP completado: 100 ofertas             â”‚   â”‚
â”‚  â”‚  2025-12-07 08:00:00 [INFO] Scraping iniciado                       â”‚   â”‚
â”‚  â”‚  2025-12-07 08:45:23 [INFO] Scraping completado: 701 nuevas         â”‚   â”‚
â”‚  â”‚  2025-12-07 08:46:00 [INFO] DetecciÃ³n bajas: 0 bajas                â”‚   â”‚
â”‚  â”‚  2025-12-06 18:00:00 [WARN] S3 sync: timeout, reintentando          â”‚   â”‚
â”‚  â”‚  2025-12-06 18:00:15 [INFO] S3 sync completado                      â”‚   â”‚
â”‚  â”‚  ...                                                                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                             â”‚
â”‚  [Exportar Logs]  [Limpiar Logs Antiguos]                                 â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Criterios de AceptaciÃ³n

- [ ] Muestra logs de todas las operaciones
- [ ] Filtros por tipo y fecha
- [ ] BÃºsqueda de texto
- [ ] Exportar a archivo
- [ ] Colores por nivel (INFO/WARN/ERROR)

### Prioridad: âšª Baja

### Labels: `dashboard`, `infra`, `feature`

### EstimaciÃ³n: 2h

---

## MOL-46: Alertas Email/Slack

### Contexto
Notificaciones cuando algo falla o requiere atenciÃ³n.

### Eventos a Notificar

| Evento | Canal | Prioridad |
|--------|-------|-----------|
| Scraping fallido | Email + Slack | Alta |
| PrecisiÃ³n < umbral | Email | Alta |
| Export S3 fallido | Email | Alta |
| Nuevas validaciones | Slack | Baja |

### Criterios de AceptaciÃ³n

- [ ] IntegraciÃ³n con SendGrid (email)
- [ ] IntegraciÃ³n con Slack webhook
- [ ] Configurable desde dashboard
- [ ] No spam (rate limit)

### Prioridad: âšª Baja

### Labels: `infra`, `feature`

### EstimaciÃ³n: 3h

---

## MOL-47: CI/CD GitHub Actions

### Contexto
Automatizar tests en cada PR.

### Workflow

```yaml
# .github/workflows/tests.yml
name: Tests
on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - run: pip install -r requirements.txt
      - run: python database/test_nlp.py
      - run: python database/test_gold_set_manual.py
```

### Criterios de AceptaciÃ³n

- [ ] Workflow ejecuta en cada PR
- [ ] Falla si precisiÃ³n < umbral
- [ ] Badge en README

### Prioridad: âšª Baja

### Labels: `infra`, `feature`

### EstimaciÃ³n: 2h

---

## MOL-48: Sistema de MÃ©tricas y Logging para Experimentos

### Contexto
Actualmente no hay forma de comparar versiones del pipeline ni medir el impacto de cambios. Los resultados estÃ¡n dispersos:
- Scores en `ofertas_esco_matching` (SQLite) - solo score final
- NLP en `validacion_v7` (SQLite) - sin timestamps
- Gold set en consola - no persiste
- Sin timing por componente

**Problema:** No podemos saber si ESCO-XLM reranker aporta valor, ni comparar v8.2 vs v8.3.

### Objetivo
Crear sistema centralizado para persistir y comparar resultados de experimentos.

### Archivos a Crear

```
metrics/
â”œâ”€â”€ experiments.json          # Resultados de experimentos
â”œâ”€â”€ gold_set_history.json     # HistÃ³rico de runs del gold set
â””â”€â”€ timing_logs.jsonl         # Tiempos por componente (append)

database/
â””â”€â”€ experiment_logger.py      # Clase para logging
```

### EspecificaciÃ³n

```python
# database/experiment_logger.py

import json
from datetime import datetime
from pathlib import Path
import time
from contextlib import contextmanager

class ExperimentLogger:
    def __init__(self, metrics_dir="metrics"):
        self.metrics_dir = Path(metrics_dir)
        self.metrics_dir.mkdir(exist_ok=True)
        self.experiments_file = self.metrics_dir / "experiments.json"
        self.timing_file = self.metrics_dir / "timing_logs.jsonl"
    
    def log_experiment(self, name: str, config: dict, results: dict):
        """Guarda resultado de un experimento"""
        experiments = self._load_experiments()
        
        key = f"{datetime.now().strftime('%Y-%m-%d_%H%M')}_{name}"
        experiments[key] = {
            "config": config,
            "results": results,
            "timestamp": datetime.now().isoformat()
        }
        
        self._save_experiments(experiments)
        return key
    
    @contextmanager
    def timer(self, component: str):
        """Context manager para medir tiempo de un componente"""
        start = time.perf_counter()
        yield
        duration_ms = (time.perf_counter() - start) * 1000
        self.log_timing(component, duration_ms)
    
    def log_timing(self, component: str, duration_ms: float):
        """Guarda timing de un componente"""
        with open(self.timing_file, "a") as f:
            f.write(json.dumps({
                "component": component,
                "duration_ms": round(duration_ms, 2),
                "timestamp": datetime.now().isoformat()
            }) + "\n")
    
    def get_timing_summary(self, last_n: int = 100) -> dict:
        """Obtiene resumen de tiempos por componente"""
        timings = {}
        if not self.timing_file.exists():
            return timings
        
        lines = self.timing_file.read_text().strip().split("\n")[-last_n:]
        for line in lines:
            entry = json.loads(line)
            comp = entry["component"]
            if comp not in timings:
                timings[comp] = []
            timings[comp].append(entry["duration_ms"])
        
        return {
            comp: {
                "avg_ms": sum(vals) / len(vals),
                "min_ms": min(vals),
                "max_ms": max(vals),
                "count": len(vals)
            }
            for comp, vals in timings.items()
        }
    
    def compare_experiments(self, exp1_key: str, exp2_key: str) -> dict:
        """Compara dos experimentos"""
        experiments = self._load_experiments()
        e1 = experiments.get(exp1_key, {})
        e2 = experiments.get(exp2_key, {})
        
        if not e1 or not e2:
            return {"error": "Experimento no encontrado"}
        
        r1 = e1.get("results", {})
        r2 = e2.get("results", {})
        
        return {
            "exp1": exp1_key,
            "exp2": exp2_key,
            "precision_diff": r2.get("precision", 0) - r1.get("precision", 0),
            "exp1_precision": r1.get("precision"),
            "exp2_precision": r2.get("precision"),
            "exp1_config": e1.get("config"),
            "exp2_config": e2.get("config")
        }
    
    def _load_experiments(self) -> dict:
        if self.experiments_file.exists():
            return json.loads(self.experiments_file.read_text())
        return {}
    
    def _save_experiments(self, data: dict):
        self.experiments_file.write_text(json.dumps(data, indent=2, ensure_ascii=False))
```

### Ejemplo de Uso

```python
# En test_gold_set_manual.py
from database.experiment_logger import ExperimentLogger

logger = ExperimentLogger()

# Al final del test:
logger.log_experiment(
    name="gold_set_matching_v83",
    config={
        "matching_version": "v8.3",
        "gold_set_version": "v1",
        "gold_set_size": 19,
        "use_reranker": True
    },
    results={
        "precision": 0.789,
        "errores_por_tipo": {
            "sector_funcion": 4,
            "nivel_jerarquico": 2
        },
        "casos_fallidos": ["1118027276", "1118028887"]
    }
)

# En match_ofertas_multicriteria.py
with logger.timer("bge_m3_embedding"):
    embeddings = model.encode(texto)

with logger.timer("esco_xlm_rerank"):
    reranked = reranker.rerank(candidates)
```

### Formato experiments.json

```json
{
  "2025-12-07_1430_gold_set_matching_v83": {
    "config": {
      "matching_version": "v8.3",
      "gold_set_version": "v1",
      "gold_set_size": 19,
      "use_reranker": true
    },
    "results": {
      "precision": 0.789,
      "errores_por_tipo": {
        "sector_funcion": 4,
        "nivel_jerarquico": 2
      }
    },
    "timestamp": "2025-12-07T14:30:00"
  },
  "2025-12-07_1445_gold_set_matching_v83_sin_reranker": {
    "config": {
      "matching_version": "v8.3",
      "gold_set_version": "v1", 
      "gold_set_size": 19,
      "use_reranker": false
    },
    "results": {
      "precision": 0.785,
      "errores_por_tipo": {
        "sector_funcion": 4,
        "nivel_jerarquico": 2
      }
    },
    "timestamp": "2025-12-07T14:45:00"
  }
}
```

### Criterios de AceptaciÃ³n

- [ ] `database/experiment_logger.py` creado
- [ ] `metrics/` directorio con .gitkeep
- [ ] `test_gold_set_manual.py` usa logger automÃ¡ticamente
- [ ] Timing integrado en `match_ofertas_multicriteria.py`
- [ ] Script `compare_experiments.py` para comparar 2 runs
- [ ] DocumentaciÃ³n de uso en CLAUDE.md

### Prioridad: ğŸ”´ Alta (prerequisito para experimentos)

### Labels: `infra`, `eval-calidad`, `feature`

### EstimaciÃ³n: 3h

---

## MOL-49: Spike - Evaluar si ESCO-XLM Reranker Aporta Valor

### Contexto
El pipeline actual usa ESCO-XLM-RoBERTa-Large como re-ranker, pero hay evidencia de que podrÃ­a ser subÃ³ptimo:

**Hallazgos del anÃ¡lisis:**
1. El modelo se usa con **mean pooling para embeddings**, pero fue diseÃ±ado para **clasificaciÃ³n**
2. En StackOverflow reportan que este approach "no funciona bien"
3. Solo aporta 30% al score final (70% BGE-M3 + 30% rerank)
4. Agrega ~480ms por oferta (10 candidatos Ã— ~50ms)

**Uso actual (match_ofertas_multicriteria.py:163-167):**
```python
hidden_states = outputs.last_hidden_state
mask_expanded = attention_mask.unsqueeze(-1).expand(hidden_states.size()).float()
sum_embeddings = torch.sum(hidden_states * mask_expanded, dim=1)
embedding = sum_embeddings / sum_mask  # Mean pooling â† POSIBLEMENTE SUBÃ“PTIMO
```

### Objetivo
Determinar si remover ESCO-XLM reranker mantiene precisiÃ³n similar con menos complejidad.

### Experimento

**Test A:** Pipeline actual (baseline)
- BGE-M3 â†’ Top 10 â†’ ESCO-XLM rerank â†’ Top 3 â†’ Rules

**Test B:** Pipeline sin reranker
- BGE-M3 â†’ Top 3 directo â†’ Rules

### MetodologÃ­a

1. Ejecutar gold set con pipeline A (ya tenemos baseline: 78.9%)
2. Modificar temporalmente para deshabilitar reranker
3. Ejecutar gold set con pipeline B
4. Comparar: precisiÃ³n, errores por tipo, timing

### CÃ³digo de ModificaciÃ³n

```python
# match_ofertas_multicriteria.py

# Agregar flag:
USE_RERANKER = True  # Cambiar a False para experimento

# En la funciÃ³n de matching:
if USE_RERANKER:
    candidatos = self.rerank_con_esco_xlm(candidatos_bge, oferta_texto)
else:
    candidatos = candidatos_bge[:3]  # Top 3 directo de BGE-M3
```

### Criterios de Ã‰xito

| Escenario | DecisiÃ³n |
|-----------|----------|
| B precision >= A - 2% | Remover reranker (simplificar) |
| B precision < A - 2% | Mantener reranker |
| B precision > A | Definitivamente remover |

### Resultados a Documentar

- [ ] PrecisiÃ³n A vs B
- [ ] Errores por tipo A vs B
- [ ] Timing A vs B
- [ ] Casos especÃ­ficos que cambian
- [ ] DecisiÃ³n Go/NoGo

### Criterios de AceptaciÃ³n

- [ ] Experimento ejecutado con ambas configuraciones
- [ ] Resultados guardados en `metrics/experiments.json`
- [ ] DocumentaciÃ³n de decisiÃ³n
- [ ] Si NoGo: cerrar issue
- [ ] Si Go: crear MOL-XX para implementar cambio

### Dependencias

- MOL-48 (Sistema de mÃ©tricas) debe estar completado

### Prioridad: ğŸ”´ Alta

### Labels: `spike`, `matching`, `eval-calidad`

### EstimaciÃ³n: 2h

---

## MOL-50: Spike - Evaluar BGE-M3 Hybrid Retrieval

### Contexto
BGE-M3 actualmente solo usa **dense retrieval**, pero soporta 3 modos:
- Dense: Embeddings semÃ¡nticos (actual)
- Sparse: Lexical matching (tipo BM25 mejorado)
- Multi-vector: ColBERT-style

**Oportunidad:** Hybrid (dense + sparse) podrÃ­a mejorar precisiÃ³n en tÃ©rminos tÃ©cnicos exactos como "Excel", "SAP", "Python".

### Estado Actual

```python
# Solo dense:
embeddings = model.encode(texts)
similarity = cosine_similarity(query_emb, doc_emb)
```

### Propuesta

```python
# Hybrid:
output = model.encode(texts, return_dense=True, return_sparse=True)
dense_score = cosine_similarity(query_dense, doc_dense)
sparse_score = compute_sparse_score(query_sparse, doc_sparse)
final_score = 0.7 * dense_score + 0.3 * sparse_score
```

### Experimento

1. Modificar embedding para retornar dense + sparse
2. Implementar scoring hÃ­brido
3. Evaluar contra gold set
4. Comparar precisiÃ³n y timing

### Criterios de Ã‰xito

| MÃ©trica | Baseline | Objetivo |
|---------|----------|----------|
| PrecisiÃ³n | 78.9% | >= 82% |
| Timing | ~100ms | <= 150ms |

### Criterios de AceptaciÃ³n

- [ ] Implementar hybrid retrieval
- [ ] Evaluar con gold set
- [ ] Documentar resultados
- [ ] DecisiÃ³n Go/NoGo
- [ ] Si Go: crear issue para integrar

### Dependencias

- MOL-48 (Sistema de mÃ©tricas)

### Prioridad: ğŸŸ¡ Media

### Labels: `spike`, `matching`, `embeddings`

### EstimaciÃ³n: 4h

---

## MOL-51: Spike - Evaluar GLiNER para ExtracciÃ³n de Skills

### Contexto
Qwen2.5:14b tarda 2-5 segundos por oferta para extraer 8 campos semÃ¡nticos. GLiNER es un modelo compacto (~200M params) que:
- Supera a ChatGPT en zero-shot NER
- Soporta espaÃ±ol, francÃ©s, alemÃ¡n, italiano, portuguÃ©s
- Procesa en ~100ms

**Papers relevantes:**
- "GLiNER: Generalist Model for Named Entity Recognition" (NAACL 2024)
- Skill-LLM alcanzÃ³ 64.8% F1 en SkillSpan dataset

### Riesgo
GLiNER no estÃ¡ entrenado especÃ­ficamente en job market espaÃ±ol. Hay que validar.

### Experimento

```python
from gliner import GLiNER

model = GLiNER.from_pretrained("urchade/gliner_medium-v2.1")

# Labels para job postings
labels = [
    "skill tÃ©cnico", 
    "skill blanda", 
    "tecnologÃ­a", 
    "certificaciÃ³n",
    "beneficio",
    "requisito"
]

# Extraer entidades
entities = model.predict_entities(descripcion_oferta, labels, threshold=0.5)
```

### MetodologÃ­a

1. Seleccionar 50 ofertas con skills validados manualmente
2. Extraer skills con GLiNER
3. Extraer skills con Qwen2.5 (baseline)
4. Comparar: precision, recall, F1
5. Comparar timing

### Criterios de Ã‰xito

| MÃ©trica | Qwen2.5 (baseline) | GLiNER objetivo |
|---------|-------------------|-----------------|
| F1 skills | ~90% | >= 85% |
| Timing/oferta | 2-5s | < 500ms |

**Trade-off aceptable:** -5% F1 si ganamos 10x velocidad.

### Criterios de AceptaciÃ³n

- [ ] Dataset de 50 ofertas con skills anotados
- [ ] Benchmark Qwen2.5 vs GLiNER
- [ ] MÃ©tricas: precision, recall, F1 por tipo de skill
- [ ] Timing comparativo
- [ ] AnÃ¡lisis de errores
- [ ] DecisiÃ³n Go/NoGo

### Dependencias

- MOL-48 (Sistema de mÃ©tricas)
- Anotar 50 ofertas con skills (puede ser subset del gold set NLP)

### Prioridad: ğŸŸ¡ Media

### Labels: `spike`, `nlp`, `eval-calidad`

### EstimaciÃ³n: 6h

---

## MOL-55: Agregar Funciones Ejecutables al Dashboard Admin

### Contexto
El Dashboard Admin (MOL-41) actualmente muestra datos pero no permite ejecutar acciones. El objetivo es convertirlo en un **centro de control** donde el administrador pueda operar el sistema sin usar terminal.

### Objetivo
Agregar botones y controles que ejecuten las funciones principales del sistema.

---

### FASE 1: Funciones CrÃ­ticas (Prioridad Alta)

#### Tab Scraping
| AcciÃ³n | UI | Comando |
|--------|-----|---------|
| Iniciar scraping | ğŸŸ¢ BotÃ³n "Iniciar Scraping" | `run_scheduler.py --test` |
| Detectar bajas | ğŸ”µ BotÃ³n "Detectar Bajas" | `detectar_bajas_integrado.py` |
| Ver Ãºltimas ofertas | Tabla expandible | Query SQLite Ãºltimas 50 |

#### Tab Pipeline
| AcciÃ³n | UI | Comando |
|--------|-----|---------|
| Procesar lote NLP | ğŸŸ¢ BotÃ³n "Procesar 100" | `process_nlp_from_db_v7.py --limit 100` |
| Ver progreso | Barra de progreso | Query ofertas por versiÃ³n |
| Detener proceso | ğŸ”´ BotÃ³n "Detener" | Kill subprocess |

#### Tab Tests
| AcciÃ³n | UI | Comando |
|--------|-----|---------|
| Ejecutar Gold Set | ğŸŸ¢ BotÃ³n "Correr Test" | `test_gold_set_manual.py` |
| Ver resultados | Tabla con casos | Lee gold_set_history.json |

**EstimaciÃ³n Fase 1:** 4h

---

### FASE 2: ValidaciÃ³n y ExploraciÃ³n (Prioridad Media)

#### Tab Pipeline
| AcciÃ³n | UI | Comando |
|--------|-----|---------|
| Ver oferta especÃ­fica | Input ID + ğŸ” "Ver" | Query SQLite + mostrar JSON |
| Reprocesar oferta | Input ID + ğŸ”„ "Reprocesar" | NLP en 1 oferta |
| Procesar todo | ğŸŸ  BotÃ³n (con confirmaciÃ³n) | Sin lÃ­mite |

#### Tab Tests
| AcciÃ³n | UI | Comando |
|--------|-----|---------|
| Probar oferta individual | Input ID + ğŸ§ª "Testear" | Matching de 1 oferta |
| Ver caso fallido | Select dropdown + "Detalles" | Muestra expected vs actual |
| Agregar al Gold Set | Input ID + ocupaciÃ³n + â• | Agrega a JSON |
| Comparar experimentos | 2 dropdowns + ğŸ“Š "Comparar" | Diff de mÃ©tricas |

**EstimaciÃ³n Fase 2:** 6h

---

### FASE 3: S3 y Sistema (Prioridad Baja)

#### Tab S3 Sync
| AcciÃ³n | UI | Comando |
|--------|-----|---------|
| Export NLP a S3 | ğŸ“¤ BotÃ³n "Exportar NLP" | Upload parsed.json.gz |
| Export Matching a S3 | ğŸ“¤ BotÃ³n "Exportar Matching" | Upload matched.json.gz |
| Export ProducciÃ³n | ğŸ“¤ BotÃ³n (bloqueado si tests < 90%) | Upload parquet |
| Sync validaciones | ğŸ“¥ BotÃ³n "Descargar" | Download de S3 |
| Ver estado bucket | ğŸ”„ BotÃ³n "Refresh" | Lista S3 |

#### Tab Logs
| AcciÃ³n | UI | Comando |
|--------|-----|---------|
| Filtrar por componente | Dropdown | Filtra timing_logs |
| Exportar mÃ©tricas | ğŸ“¥ BotÃ³n "Descargar CSV" | Genera CSV |
| Limpiar logs viejos | ğŸ—‘ï¸ BotÃ³n "Limpiar > 30d" | Borra archivos |

#### Sidebar Global
| AcciÃ³n | UI | FunciÃ³n |
|--------|-----|---------|
| Estado del sistema | Indicador ğŸŸ¢/ğŸ”´ | Verifica servicios |
| Proceso en background | Texto + spinner | Muestra quÃ© corre |
| Backup BD | ğŸ’¾ BotÃ³n "Backup" | Copia SQLite |
| Detener todo | ğŸ”´ BotÃ³n emergencia | Kill all |

**EstimaciÃ³n Fase 3:** 6h

---

### ImplementaciÃ³n TÃ©cnica

```python
# PatrÃ³n para ejecutar comandos
import subprocess
import streamlit as st

def ejecutar_comando(comando: list, descripcion: str):
    """Ejecuta comando y muestra resultado en Streamlit"""
    with st.spinner(f"Ejecutando {descripcion}..."):
        try:
            result = subprocess.run(
                comando,
                capture_output=True,
                text=True,
                timeout=300  # 5 min timeout
            )
            if result.returncode == 0:
                st.success(f"âœ… {descripcion} completado")
                with st.expander("Ver output"):
                    st.code(result.stdout[-2000:])
            else:
                st.error(f"âŒ Error en {descripcion}")
                st.code(result.stderr)
        except subprocess.TimeoutExpired:
            st.warning("â±ï¸ Proceso tomando mucho tiempo, corre en background")
```

```python
# Para procesos largos (background)
import threading

def run_in_background(comando, log_file):
    """Ejecuta en background sin bloquear UI"""
    def _run():
        with open(log_file, 'w') as f:
            subprocess.run(comando, stdout=f, stderr=f)
    
    thread = threading.Thread(target=_run, daemon=True)
    thread.start()
    st.session_state['background_process'] = {
        'comando': comando,
        'log_file': log_file,
        'thread': thread
    }
```

---

### Criterios de AceptaciÃ³n

**Fase 1:**
- [ ] BotÃ³n scraping ejecuta y muestra resultado
- [ ] BotÃ³n NLP procesa 100 ofertas
- [ ] BotÃ³n test corre gold set y muestra precisiÃ³n
- [ ] Indicador de proceso en background

**Fase 2:**
- [ ] Input para ver/reprocesar oferta especÃ­fica
- [ ] Probar matching de 1 oferta
- [ ] Agregar caso al gold set desde UI
- [ ] Comparar 2 experimentos

**Fase 3:**
- [ ] Exports a S3 funcionando
- [ ] Filtros en logs
- [ ] Backup de BD
- [ ] BotÃ³n emergencia

---

### Prioridad: ğŸ”´ Alta (Fase 1), ğŸŸ¡ Media (Fase 2), âšª Baja (Fase 3)

### Labels: `dashboard`, `feature`, `admin`

### EstimaciÃ³n Total: 16h (4h + 6h + 6h)

### Dependencias
- MOL-41 âœ… (Dashboard base creado)

---

## MOL-56: Sistema de OptimizaciÃ³n de Keywords

### Contexto
El scraping usa 1,148 keywords pero:
- 478 (41%) no traen resultados
- 6 son muy genÃ©ricos (traen >9,000 ofertas sin filtrar)
- No hay forma de medir el impacto de cambios
- No hay versionado ni trazabilidad

### Objetivo
Crear sistema completo para analizar, proponer, versionar y medir mejoras en keywords.

---

### Componentes

#### 1. Estructura de Versionado (1h)

```
data/config/
â”œâ”€â”€ master_keywords.json           # VersiÃ³n activa
â”œâ”€â”€ keywords_history/
â”‚   â”œâ”€â”€ v3.2_2025-11-15.json      # Versiones anteriores
â”‚   â”œâ”€â”€ v3.3_2025-12-08.json
â”‚   â””â”€â”€ changelog.json             # Registro de cambios
â””â”€â”€ keywords_proposals/
    â””â”€â”€ v3.3_proposal.json         # Propuestas pendientes
```

#### 2. Clase KeywordOptimizer (3h)

```python
# database/keyword_optimizer.py

class KeywordOptimizer:
    def analyze(self) -> dict:
        """Analiza keywords_performance y retorna mÃ©tricas"""
        pass
    
    def propose_changes(self, analysis: dict) -> dict:
        """Genera propuesta de cambios con justificaciÃ³n"""
        pass
    
    def apply_version(self, version: str, author: str):
        """Aplica propuesta: backup + cambios + changelog"""
        pass
    
    def compare_versions(self, v1: str, v2: str) -> dict:
        """Compara mÃ©tricas entre versiones"""
        pass
```

#### 3. Tab Dashboard Keywords (3h)

Mostrar:
- Resumen: total keywords, sin uso, genÃ©ricos, tasa novedad
- Tabla keywords problemÃ¡ticos
- Top 10 eficientes
- Historial de versiones con mÃ©tricas
- Comparador de versiones

#### 4. CLI del Optimizer (1h)

```bash
python -m database.keyword_optimizer analyze
python -m database.keyword_optimizer propose --output v3.3
python -m database.keyword_optimizer apply v3.3 --author "gerardo"
python -m database.keyword_optimizer compare v3.1 v3.2
```

---

### Ciclo de Uso

```
1. ANALIZAR (Dashboard) â†’ Ver mÃ©tricas, identificar problemas
2. PROPONER (Claude Code) â†’ "Analiza keywords y propone v3.3"
3. REVISAR (Admin) â†’ Aprobar o ajustar propuesta
4. APLICAR (Script) â†’ Backup automÃ¡tico + changelog
5. MEDIR (Dashboard) â†’ Comparar versiones post-scraping
```

---

### Criterios de AceptaciÃ³n

- [ ] Estructura de versionado creada
- [ ] KeywordOptimizer con analyze/propose/apply/compare
- [ ] CLI funcional
- [ ] Tab en dashboard con mÃ©tricas + historial
- [ ] DocumentaciÃ³n del proceso
- [ ] Al menos una optimizaciÃ³n v3.3 aplicada y medida

### Prioridad: ğŸŸ¡ Media

### Labels: `scraping`, `optimization`, `dashboard`

### EstimaciÃ³n: 8h

### Dependencias
- MOL-41 âœ… (Dashboard base)
- keywords_performance en BD âœ…

---

## MOL-52: Documentar Arquitectura de Modelos LLM/ML

### Contexto
No existe documentaciÃ³n clara de cÃ³mo funcionan los modelos y cÃ³mo interactÃºan.

### Objetivo
Crear documento tÃ©cnico que explique la arquitectura actual.

### Contenido a Documentar

```markdown
# Arquitectura de Modelos LLM/ML - MOL

## 1. Inventario de Modelos

| Modelo | Tipo | ParÃ¡metros | Uso | Timing |
|--------|------|------------|-----|--------|
| Qwen2.5:14b | LLM | 14B | NLP extraction | 2-5s/oferta |
| BGE-M3 | Embeddings | ~560M | Retrieval semÃ¡ntico | ~100ms/batch |
| ChromaDB | Vector DB | - | Storage ESCO | Disk-based |

## 2. Pipeline NLP (3 capas)

- Capa 0: Regex (70% campos, 100% precisiÃ³n)
- Capa 1: Qwen2.5 (30% campos, temp=0.0, top_p=0.1)
- Capa 2: Anti-alucinaciÃ³n (substring matching)

## 3. Pipeline Matching (3 pasos) - ACTUALIZADO

- Paso 1: BGE-M3 â†’ Top 3 candidatos (sin reranker)
- Paso 2: Score skills (threshold 0.50)
- Paso 3: Pesos dinÃ¡micos + rules v8.3

Nota: ESCO-XLM reranker REMOVIDO (MOL-49 demostrÃ³ que perjudicaba precisiÃ³n)

## 4. Pesos DinÃ¡micos

| Coverage | TÃ­tulo | Skills | DescripciÃ³n |
|----------|--------|--------|-------------|
| >= 80% | 50% | 40% | 10% |
| 40-80% | 60% | 30% | 10% |
| < 40% | 85% | 0% | 15% |
```

### Archivos a Crear

- `docs/ARQUITECTURA_MODELOS.md`

### Criterios de AceptaciÃ³n

- [ ] Documento completo con diagramas
- [ ] Thresholds y configuraciÃ³n documentados
- [ ] Documentar decisiÃ³n de remover ESCO-XLM (spike MOL-49)
- [ ] Referencias a archivos de cÃ³digo
- [ ] Integrado en CLAUDE.md

### Prioridad: âšª Baja

### Labels: `docs`, `nlp`, `matching`

### EstimaciÃ³n: 2h

---

# RESUMEN DE PRIORIDADES

## ğŸ”´ Alta Prioridad (Implementar Primero)

| Issue | TÃ­tulo | Ã‰pica | EstimaciÃ³n |
|-------|--------|-------|------------|
| MOL-48 | Sistema de MÃ©tricas y Logging | Infra | 3h |
| MOL-27 | Dashboard Admin - Tab Scraping | Scraping | 4h |
| MOL-30 | Gold Set NLP (200+ casos) | NLP | 8h |
| MOL-31 | Test AutomÃ¡tico NLP | NLP | 3h |
| MOL-32 | Export NLP a S3 | NLP | 2h |
| MOL-5 | Resolver sector_funcion (v8.4) | Matching | 6h |
| MOL-34 | Expandir Gold Set Matching | Matching | 8h |
| MOL-35 | Export Matching a S3 | Matching | 2h |
| MOL-49 | Spike - Evaluar ESCO-XLM Reranker | Matching | 2h |
| MOL-36 | Dashboard Admin - Tab Tests | ValidaciÃ³n | 4h |
| MOL-37 | Dashboard Admin - Tab S3 Sync | ValidaciÃ³n | 4h |
| MOL-40 | Export ProducciÃ³n | ValidaciÃ³n | 3h |
| MOL-41 | Dashboard Admin - App Principal | Dashboards | 2h |
| MOL-55 | Funciones Ejecutables Dashboard (Fase 1) | Dashboards | 4h |

**Total Alta Prioridad:** 55h

## ğŸŸ¡ Media Prioridad

| Issue | TÃ­tulo | Ã‰pica | EstimaciÃ³n |
|-------|--------|-------|------------|
| MOL-28 | Activar Scraper ZonaJobs | Scraping | 3h |
| MOL-29 | DeduplicaciÃ³n Cross-Portal | Scraping | 4h |
| MOL-33 | Sync Validaciones NLP | NLP | 2h |
| MOL-38 | Generate Sample | ValidaciÃ³n | 2h |
| MOL-39 | Dashboard ValidaciÃ³n (Vercel) | ValidaciÃ³n | 12h |
| MOL-42 | Dashboard Admin - Tab Pipeline | Dashboards | 4h |
| MOL-43 | Dashboard ProducciÃ³n (Vercel) | Dashboards | 16h |
| MOL-44 | Lambda API Backend | Dashboards | 6h |
| MOL-56 | Sistema OptimizaciÃ³n Keywords | Scraping | 8h |

**Total Media Prioridad:** 57h

## âšª Baja Prioridad

| Issue | TÃ­tulo | Ã‰pica | EstimaciÃ³n |
|-------|--------|-------|------------|
| MOL-45 | Dashboard Admin - Tab Logs | Infra | 2h |
| MOL-46 | Alertas Email/Slack | Infra | 3h |
| MOL-47 | CI/CD GitHub Actions | Infra | 2h |
| MOL-50 | Spike - BGE-M3 Hybrid Retrieval | Matching | 4h |
| MOL-51 | Spike - GLiNER para Skills | NLP | 6h |
| MOL-52 | Documentar Arquitectura Modelos | Docs | 2h |

**Total Baja Prioridad:** 19h

---

**Total General:** ~144h

---

# RESUMEN POR Ã‰PICA

## Ã‰pica 1: Scraping (4 issues)
- MOL-27: Dashboard Admin - Tab Scraping ğŸ”´
- MOL-28: Activar Scraper ZonaJobs ğŸŸ¡
- MOL-29: DeduplicaciÃ³n Cross-Portal ğŸŸ¡
- MOL-56: Sistema OptimizaciÃ³n Keywords ğŸŸ¡

## Ã‰pica 2: NLP (5 issues)
- MOL-30: Gold Set NLP (200+ casos) ğŸ”´
- MOL-31: Test AutomÃ¡tico NLP ğŸ”´
- MOL-32: Export NLP a S3 ğŸ”´
- MOL-33: Sync Validaciones NLP ğŸŸ¡
- MOL-51: Spike - GLiNER para Skills âšª

## Ã‰pica 3: Matching ESCO (5 issues)
- MOL-5: Resolver sector_funcion (v8.4) ğŸ”´
- MOL-34: Expandir Gold Set Matching ğŸ”´
- MOL-35: Export Matching a S3 ğŸ”´
- MOL-49: Spike - Evaluar ESCO-XLM Reranker ğŸ”´
- MOL-50: Spike - BGE-M3 Hybrid Retrieval âšª

## Ã‰pica 4: ValidaciÃ³n (5 issues)
- MOL-36: Dashboard Admin - Tab Tests ğŸ”´
- MOL-37: Dashboard Admin - Tab S3 Sync ğŸ”´
- MOL-38: Generate Sample ğŸŸ¡
- MOL-39: Dashboard ValidaciÃ³n (Vercel) ğŸŸ¡
- MOL-40: Export ProducciÃ³n ğŸ”´

## Ã‰pica 5: Dashboards (5 issues)
- MOL-41: Dashboard Admin - App Principal ğŸ”´ âœ…
- MOL-42: Dashboard Admin - Tab Pipeline ğŸŸ¡
- MOL-43: Dashboard ProducciÃ³n (Vercel) ğŸŸ¡
- MOL-44: Lambda API Backend ğŸŸ¡
- MOL-55: Funciones Ejecutables Dashboard ğŸ”´ (Fase 1)

## Ã‰pica 6: Infraestructura (6 issues)
- MOL-48: Sistema de MÃ©tricas y Logging ğŸ”´
- MOL-45: Dashboard Admin - Tab Logs âšª
- MOL-46: Alertas Email/Slack âšª
- MOL-47: CI/CD GitHub Actions âšª
- MOL-52: Documentar Arquitectura Modelos âšª

---

# ORDEN DE IMPLEMENTACIÃ“N SUGERIDO

## Fase 1: Fundamentos (Semana 1) - EN PROGRESO
1. **MOL-48**: Sistema de MÃ©tricas âœ… COMPLETADO
2. **MOL-49**: Spike ESCO-XLM âœ… COMPLETADO (DecisiÃ³n: REMOVER reranker)
3. **MOL-41**: Dashboard Admin - App Principal âœ… COMPLETADO
4. **MOL-54**: Validar NLP v8.0 âœ… COMPLETADO (78.9% precisiÃ³n)
5. **MOL-55**: Funciones Ejecutables Dashboard (Fase 1) â† SIGUIENTE

## Fase 2: NLP Completo (Semana 2)
6. Procesar 9,443 ofertas con NLP v8.0 (en background)
7. **MOL-30**: Gold Set NLP (200+ casos)
8. **MOL-31**: Test AutomÃ¡tico NLP
9. **MOL-27**: Dashboard Admin - Tab Scraping

## Fase 3: Tests y Matching (Semana 3)
10. **MOL-34**: Expandir Gold Set Matching
11. **MOL-36**: Dashboard Admin - Tab Tests
12. **MOL-32**: Export NLP a S3
13. **MOL-35**: Export Matching a S3

## Fase 4: Mejoras Matching (Semana 4)
14. **MOL-5**: Resolver sector_funcion v8.4
15. **MOL-37**: Dashboard Admin - Tab S3 Sync
16. **MOL-40**: Export ProducciÃ³n

## Fase 5: OptimizaciÃ³n (Semana 5+)
17. MOL-50: Spike - BGE-M3 Hybrid
18. MOL-51: Spike - GLiNER
19. MOL-55: Funciones Dashboard (Fases 2 y 3)
20. Resto de issues segÃºn prioridad

---

---

## MOL-62: Implementar NLP Schema v5 - Campos CrÃ­ticos

### Contexto
Gap Analysis revelÃ³:
- Schema diseÃ±ado (NLP_SCHEMA_V5.md): 147 campos en 16 bloques
- Implementado actual: 12 campos (8.2%)
- Campos crÃ­ticos faltantes impactan directamente el matching ESCO

**Campos mÃ¡s crÃ­ticos faltantes:**
| Campo | Bloque | Impacto Matching |
|-------|--------|------------------|
| tareas[] | Rol y Tareas | â˜…â˜…â˜…â˜…â˜… Confirma ocupaciÃ³n |
| area_funcional | Condiciones | â˜…â˜…â˜…â˜…â˜… Contexto sector |
| nivel_seniority | Condiciones | â˜…â˜…â˜…â˜…â˜… Nivel jerÃ¡rquico |
| tiene_gente_cargo | Rol y Tareas | â˜…â˜…â˜…â˜…â˜† Jefe vs IC |
| tipo_oferta | Metadatos NLP | â˜…â˜…â˜…â˜†â˜† Filtrar basura |

### Objetivo
Implementar extracciÃ³n de campos crÃ­ticos segÃºn NLP_SCHEMA_V5.md para mejorar matching.

### Fases de ImplementaciÃ³n

#### Fase 1: Campos CrÃ­ticos para Matching (Este Issue)
| Campo | Bloque | Tipo |
|-------|--------|------|
| tareas_explicitas | Rol y Tareas | [string] |
| tareas_inferidas | Rol y Tareas | [string] |
| tiene_gente_cargo | Rol y Tareas | boolean |
| area_funcional | Condiciones | string |
| nivel_seniority | Condiciones | string |
| sector_empresa | Empresa | string |
| tecnologias_list | Skills | [string] |
| tipo_oferta | Metadatos | string |
| licencia_conducir | Licencias | boolean |

#### Fase 2: Campos Importantes
- experiencia_nivel_previo
- producto_servicio
- titulo_requerido
- conocimientos_especificos[]
- tipo_contrato

#### Fase 3: Calidad y Flags
- tiene_requisitos_discriminatorios
- calidad_redaccion
- requisito_edad_min/max

#### Fase 4: Resto de Bloques
- CompensaciÃ³n completa
- Beneficios detallados
- UbicaciÃ³n/Movilidad
- Certificaciones

### Archivos a Crear/Modificar

```
database/migrations/
â””â”€â”€ 002_add_nlp_schema_v5_columns.sql   # CREAR

02.5_nlp_extraction/prompts/
â””â”€â”€ extraction_prompt_v9.py              # CREAR (expandir v8)

database/
â”œâ”€â”€ process_nlp_from_db_v7.py           # ACTUALIZAR schema
â””â”€â”€ ofertas_nlp                         # MIGRAR tabla
```

### Criterios de AceptaciÃ³n

- [ ] MigraciÃ³n ejecutada (9 columnas nuevas)
- [ ] Prompt v9 creado con campos nuevos
- [ ] process_nlp actualizado para v9
- [ ] Test con 5 ofertas muestra extracciÃ³n correcta
- [ ] Gold Set verificado post-migraciÃ³n

### Prioridad: ğŸ”´ Alta

### Labels: `nlp`, `schema`, `feature`

### EstimaciÃ³n: 8h

### Dependencias
- Gap Analysis completado âœ…

---

*Documento generado: 2025-12-07*
*Ãšltima actualizaciÃ³n: 2025-12-09*
*Para Linear: Copiar cada issue con su contexto completo*
