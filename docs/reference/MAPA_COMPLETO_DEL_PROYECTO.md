# ğŸ—ºï¸ Mapa Completo del Proyecto - De Scraping a AnÃ¡lisis

## ğŸ“Š Vista General del Flujo

```
INTERNET â†’ SCRAPING â†’ CONSOLIDACIÃ“N â†’ NLP EXTRACTION â†’ ESCO MATCHING â†’ ANÃLISIS
  (Web)      (1)          (2)              (3)              (4)           (5)
```

---

## ğŸ”„ Flujo Detallado por Fase

### FASE 0: ğŸŒ Web (Datos originales)

**Fuentes:**
- Bumeran.com.ar
- ZonaJobs.com.ar
- Indeed.com.ar
- ComputrabajoArgentina
- LinkedIn

---

### FASE 1: ğŸ“¥ SCRAPING (Carpeta: `01_sources/`)

**Objetivo:** Extraer ofertas laborales de cada portal web

#### ğŸ¯ Por cada fuente:

```
01_sources/
â”œâ”€â”€ bumeran/
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ bumeran_scraper.py          [Scraper principal]
â”‚   â”‚   â””â”€â”€ run_bumeran_scraper.py      [Ejecutor]
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”‚   â””â”€â”€ bumeran_full_YYYYMMDD.csv    [OUTPUT: Ofertas scrapeadas]
â”‚   â”‚   â””â”€â”€ tracking/
â”‚   â”‚       â””â”€â”€ bumeran_tracking.json        [Control de scraping incremental]
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ zonajobs/
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ zonajobs_scraper.py
â”‚   â”‚   â””â”€â”€ consolidar_zonajobs.py      [Consolida mÃºltiples archivos]
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”‚   â”œâ”€â”€ zonajobs_YYYYMMDD.csv         [Scraping individual]
â”‚   â”‚   â”‚   â””â”€â”€ zonajobs_consolidacion_*.csv  [OUTPUT: Consolidado]
â”‚   â”‚   â””â”€â”€ tracking/
â”‚   â”‚       â””â”€â”€ zonajobs_tracking.json
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ indeed/
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ indeed_scraper.py
â”‚   â”‚   â””â”€â”€ consolidar_indeed.py
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”‚   â”œâ”€â”€ indeed_YYYYMMDD_HHMMSS.json   [Scraping individual]
â”‚   â”‚   â”‚   â””â”€â”€ indeed_consolidacion.json     [OUTPUT: Consolidado]
â”‚   â”‚   â””â”€â”€ tracking/
â”‚   â”‚       â””â”€â”€ indeed_tracking.json
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ computrabajo/  [Similar estructura]
â””â”€â”€ linkedin/      [Similar estructura]
```

**Archivos clave de OUTPUT de Fase 1:**
- âœ… `01_sources/bumeran/data/raw/bumeran_full_20241025.csv` (2,460 ofertas)
- âœ… `01_sources/zonajobs/data/raw/zonajobs_consolidacion_20241025.csv` (3 ofertas)
- âœ… `01_sources/indeed/data/raw/indeed_consolidacion.json` (6,009 ofertas)

**CaracterÃ­sticas:**
- Tracking incremental (no duplica ofertas)
- Datos RAW sin procesar
- Columnas originales de cada portal

---

### FASE 2: ğŸ§  NLP EXTRACTION (Carpeta: `02.5_nlp_extraction/`)

**Objetivo:** Extraer informaciÃ³n estructurada de descripciones de texto

#### Estructura:

```
02.5_nlp_extraction/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ extractors/
â”‚   â”‚   â”œâ”€â”€ base_nlp_extractor.py       [Clase abstracta base]
â”‚   â”‚   â”œâ”€â”€ bumeran_extractor.py        [Extractor Bumeran - Regex]
â”‚   â”‚   â”œâ”€â”€ zonajobs_extractor.py       [Extractor ZonaJobs - Regex]
â”‚   â”‚   â”œâ”€â”€ indeed_extractor.py         [Extractor Indeed - Regex bilingÃ¼e]
â”‚   â”‚   â””â”€â”€ base_ner_extractor.py       [Extractor NER (Fase 2B)]
â”‚   â”‚
â”‚   â”œâ”€â”€ patterns/
â”‚   â”‚   â””â”€â”€ regex_patterns.py           [Patrones regex para extracciÃ³n]
â”‚   â”‚
â”‚   â”œâ”€â”€ run_nlp_extraction.py           [EJECUTOR: Procesa con Regex]
â”‚   â”œâ”€â”€ consolidate_nlp_sources.py      [Consolida multi-fuente]
â”‚   â”‚
â”‚   â”‚   â”€â”€ FASE 2B: NER (AnotaciÃ³n + Training) â”€â”€
â”‚   â”œâ”€â”€ prepare_ner_dataset.py          [Selecciona 500 muestras]
â”‚   â”œâ”€â”€ auto_annotate_with_ollama.py    [Anota con LLM local] â­ CORRIENDO
â”‚   â”œâ”€â”€ auto_annotate_with_llm.py       [Anota con API (OpenAI/Claude)]
â”‚   â”œâ”€â”€ auto_annotate_with_regex.py     [Pre-anota con Fase 1]
â”‚   â”œâ”€â”€ convert_annotations_to_spacy.py [Convierte a formato spaCy]
â”‚   â”œâ”€â”€ train_ner_model.py              [Entrena modelo NER]
â”‚   â””â”€â”€ compare_phase1_vs_phase2.py     [Compara Regex vs NER]
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ processed/
â”‚   â”‚   â”œâ”€â”€ bumeran_nlp_20251025.csv            [Bumeran con NLP Regex]
â”‚   â”‚   â”œâ”€â”€ zonajobs_nlp_20251025.csv           [ZonaJobs con NLP Regex]
â”‚   â”‚   â”œâ”€â”€ indeed_nlp_20251025.csv             [Indeed con NLP Regex]
â”‚   â”‚   â”œâ”€â”€ all_sources_nlp_20251025_141134.csv [OUTPUT FASE 2A: Consolidado Regex]
â”‚   â”‚   â””â”€â”€ all_sources_ner_YYYYMMDD.csv        [OUTPUT FASE 2B: Con NER]
â”‚   â”‚
â”‚   â””â”€â”€ ner_training/
â”‚       â”œâ”€â”€ ner_samples_for_annotation_*.jsonl  [500 muestras seleccionadas]
â”‚       â”œâ”€â”€ ner_samples_*_ollama_annotated.jsonl [Anotadas con Ollama] â­ GENERANDO
â”‚       â””â”€â”€ spacy_format/
â”‚           â”œâ”€â”€ train_data.json                  [80% para training]
â”‚           â””â”€â”€ dev_data.json                    [20% para validaciÃ³n]
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ ner_model/
â”‚       â”œâ”€â”€ model_YYYYMMDD_HHMMSS/              [Modelo NER entrenado]
â”‚       â””â”€â”€ latest/ â†’ symlink                    [Apunta al Ãºltimo]
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ fields_mapping.json             [Esquema de campos NLP]
â”‚   â””â”€â”€ skills_database.json            [215 skills tÃ©cnicas + 60 soft]
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ WEEK3_PROGRESS.md               [Reporte Fase 2A completada]
â”‚   â”œâ”€â”€ PHASE2_NER_WORKFLOW.md          [Workflow Fase 2B]
â”‚   â””â”€â”€ ANNOTATION_GUIDE.md             [GuÃ­a para anotadores]
â”‚
â””â”€â”€ reports/
    â””â”€â”€ phase1_vs_phase2_comparison_*.md [ComparaciÃ³n Regex vs NER]
```

**INPUT de Fase 2:**
- â¬…ï¸ `01_sources/*/data/raw/*.csv` (Datos scrapeados)

**OUTPUT de Fase 2A (Regex - COMPLETADO):**
- âœ… `all_sources_nlp_20251025_141134.csv` (8,472 ofertas con 23 campos NLP)
  - Campos extraÃ­dos: experiencia, educaciÃ³n, skills, idiomas, etc.
  - MÃ©todo: Patrones Regex
  - Confidence: 0.26 promedio
  - Cobertura: 29-63% segÃºn campo

**OUTPUT de Fase 2B (NER - EN PROCESO):**
- â³ Anotaciones: 55% completado (277/500) â­ CORRIENDO AHORA
- â³ Modelo NER: Pendiente training
- â³ `all_sources_ner_*.csv`: Pendiente procesamiento

---

### FASE 3: ğŸ·ï¸ ESCO MATCHING (Carpeta: `03_esco_matching/`)

**Objetivo:** Clasificar ocupaciones usando taxonomÃ­a ESCO/ISCO

```
03_esco_matching/
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ integrate_nlp_with_esco.py      [Matcher NLP â†’ ESCO]
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ esco_ocupaciones_con_isco_completo.json [TaxonomÃ­a ESCO]
â”‚
â””â”€â”€ output/
    â””â”€â”€ nlp_esco_enriched_*.csv         [OUTPUT: Ofertas + ESCO]
```

**INPUT de Fase 3:**
- â¬…ï¸ `02.5_nlp_extraction/data/processed/all_sources_nlp_*.csv`
- â¬…ï¸ `D:\Trabajos en PY\EPH-ESCO\07_esco_data\esco_ocupaciones_con_isco_completo.json`

**OUTPUT de Fase 3:**
- â³ `nlp_esco_enriched_*.csv` (Ofertas con cÃ³digo ESCO/ISCO)
- Matching en background (corriendo en paralelo)

**CaracterÃ­sticas:**
- Matching semÃ¡ntico: SequenceMatcher + Jaccard
- Threshold configurable (default: 0.6)
- Agrega: `ocupacion_esco_uri`, `isco_code`, `similarity_score`

---

### FASE 4: ğŸ“Š ANÃLISIS (Carpeta: `04_analysis/`)

**Objetivo:** AnÃ¡lisis exploratorio y visualizaciones

```
04_analysis/
â””â”€â”€ [FUTURO - No implementado aÃºn]
```

**INPUT de Fase 4:**
- â¬…ï¸ `03_esco_matching/output/nlp_esco_enriched_*.csv`

**OUTPUT esperado de Fase 4:**
- Dashboards
- Visualizaciones
- EstadÃ­sticas por ocupaciÃ³n/sector
- Tendencias de skills demandadas

---

## ğŸ“ˆ Estado Actual del Proyecto

### âœ… COMPLETADO

| Fase | DescripciÃ³n | Archivos Principales | Estado |
|------|-------------|---------------------|--------|
| **1. Scraping** | ExtracciÃ³n de web | `bumeran_full_*.csv` (2,460)<br>`indeed_consolidacion.json` (6,009)<br>`zonajobs_consolidacion_*.csv` (3) | âœ… 100% |
| **2A. NLP Regex** | ExtracciÃ³n con regex | `all_sources_nlp_20251025_141134.csv` (8,472)<br>23 campos NLP extraÃ­dos | âœ… 100% |

### â³ EN PROCESO

| Fase | DescripciÃ³n | Estado | ETA |
|------|-------------|--------|-----|
| **2B. NLP NER** | AnotaciÃ³n con Ollama | 55% (277/500) â­ | ~10 min |
| **3. ESCO Matching** | ClasificaciÃ³n ocupacional | Running background | ~15 min |

### ğŸ“‹ PENDIENTE

| Fase | DescripciÃ³n | Depende de |
|------|-------------|------------|
| **2B. NER Training** | Entrenar modelo spaCy | AnotaciÃ³n Ollama |
| **2B. NER Processing** | Procesar 8,472 ofertas con NER | Modelo entrenado |
| **2B. Comparison** | Comparar Regex vs NER | NER processing |
| **4. AnÃ¡lisis** | Dashboards y visualizaciones | ESCO matching |

---

## ğŸ”€ Flujo de Datos Completo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     INTERNET (5 portales)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FASE 1: SCRAPING (01_sources/)                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚  Bumeran    â”‚  â”‚  ZonaJobs   â”‚  â”‚   Indeed    â”‚  ...       â”‚
â”‚  â”‚  scraper.py â”‚  â”‚  scraper.py â”‚  â”‚  scraper.py â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚         â†“               â†“                 â†“                     â”‚
â”‚  bumeran_full.csv  zonajobs_*.csv  indeed_*.json               â”‚
â”‚    (2,460)            (3)            (6,009)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FASE 2A: NLP EXTRACTION - REGEX (02.5_nlp_extraction/)  âœ…    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  run_nlp_extraction.py                                   â”‚ â”‚
â”‚  â”‚    â”œâ”€ BumeranExtractor  (regex_patterns.py)             â”‚ â”‚
â”‚  â”‚    â”œâ”€ ZonaJobsExtractor                                 â”‚ â”‚
â”‚  â”‚    â””â”€ IndeedExtractor                                   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                         â†“                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  consolidate_nlp_sources.py                              â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                         â†“                                      â”‚
â”‚  all_sources_nlp_20251025_141134.csv (8,472 ofertas)          â”‚
â”‚  Columnas: 56 (originales + 23 NLP)                           â”‚
â”‚  - experiencia_min_anios, experiencia_max_anios               â”‚
â”‚  - nivel_educativo, titulo_requerido                          â”‚
â”‚  - idioma_principal, nivel_idioma_principal                   â”‚
â”‚  - skills_tecnicas_list, soft_skills_list                     â”‚
â”‚  - jornada_laboral, modalidad_trabajo                         â”‚
â”‚  - nlp_confidence_score (0.26 promedio)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FASE 2B: NLP EXTRACTION - NER (02.5_nlp_extraction/)    â³   â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  1. prepare_ner_dataset.py                         âœ…  â”‚  â”‚
â”‚  â”‚     â””â”€ Selecciona 500 muestras estratificadas          â”‚  â”‚
â”‚  â”‚        â””â”€ ner_samples_for_annotation_*.jsonl           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                         â†“                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  2. auto_annotate_with_ollama.py               â³ 55%  â”‚  â”‚
â”‚  â”‚     â””â”€ Anota con llama3 local                          â”‚  â”‚
â”‚  â”‚        â””â”€ ner_samples_*_ollama_annotated.jsonl         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                         â†“                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  3. convert_annotations_to_spacy.py            â³      â”‚  â”‚
â”‚  â”‚     â””â”€ train_data.json + dev_data.json                 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                         â†“                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  4. train_ner_model.py                         â³      â”‚  â”‚
â”‚  â”‚     â””â”€ models/ner_model/model_YYYYMMDD/                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                         â†“                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  5. base_ner_extractor.process_dataframe()     â³      â”‚  â”‚
â”‚  â”‚     â””â”€ all_sources_ner_YYYYMMDD.csv (8,472 + NER)      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                         â†“                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  6. compare_phase1_vs_phase2.py                â³      â”‚  â”‚
â”‚  â”‚     â””â”€ phase1_vs_phase2_comparison.md                  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FASE 3: ESCO MATCHING (03_esco_matching/)            â³      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  integrate_nlp_with_esco.py                              â”‚ â”‚
â”‚  â”‚    â”œâ”€ INPUT: all_sources_nlp_*.csv                       â”‚ â”‚
â”‚  â”‚    â”œâ”€ ESCO: esco_ocupaciones_con_isco_completo.json     â”‚ â”‚
â”‚  â”‚    â””â”€ Matching: SequenceMatcher + Jaccard               â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                         â†“                                      â”‚
â”‚  nlp_esco_enriched_YYYYMMDD.csv                                â”‚
â”‚  Nuevas columnas:                                              â”‚
â”‚  - ocupacion_esco_uri                                          â”‚
â”‚  - ocupacion_esco_codigo                                       â”‚
â”‚  - ocupacion_esco_label                                        â”‚
â”‚  - isco_code (clasificaciÃ³n internacional)                    â”‚
â”‚  - similarity_score                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FASE 4: ANÃLISIS (04_analysis/)                      ğŸ“‹      â”‚
â”‚  [FUTURO - No implementado]                                    â”‚
â”‚  - Dashboards interactivos                                     â”‚
â”‚  - AnÃ¡lisis por sector/ocupaciÃ³n                              â”‚
â”‚  - Tendencias de skills                                        â”‚
â”‚  - Visualizaciones                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Archivos Clave del Proyecto

### ğŸ”´ ARCHIVOS FINALES (Los que importan)

| Archivo | DescripciÃ³n | Filas | Columnas |
|---------|-------------|-------|----------|
| **`01_sources/bumeran/data/raw/bumeran_full_20241025.csv`** | Ofertas Bumeran RAW | 2,460 | ~30 |
| **`01_sources/indeed/data/raw/indeed_consolidacion.json`** | Ofertas Indeed RAW | 6,009 | ~25 |
| **`01_sources/zonajobs/data/raw/zonajobs_consolidacion_*.csv`** | Ofertas ZonaJobs RAW | 3 | ~28 |
| **`02.5_nlp_extraction/data/processed/all_sources_nlp_20251025_141134.csv`** â­ | **Ofertas + NLP Regex** | **8,472** | **56** |
| `02.5_nlp_extraction/data/processed/all_sources_ner_*.csv` â³ | **Ofertas + NLP NER** (futuro) | 8,472 | ~60 |
| `03_esco_matching/output/nlp_esco_enriched_*.csv` â³ | **Ofertas + NLP + ESCO** (futuro) | 8,472 | ~65 |

### ğŸŸ¢ ARCHIVOS INTERMEDIOS (Proceso)

| Archivo | PropÃ³sito |
|---------|-----------|
| `02.5_nlp_extraction/data/ner_training/ner_samples_*_ollama_annotated.jsonl` â³ | Anotaciones para NER |
| `02.5_nlp_extraction/data/ner_training/spacy_format/train_data.json` | Training NER |
| `02.5_nlp_extraction/models/ner_model/latest/` | Modelo NER entrenado |

---

## ğŸ¯ Comandos para Reproducir el Flujo

### 1. Scraping (COMPLETADO âœ…)

```bash
# Bumeran
cd D:\OEDE\Webscrapping\01_sources\bumeran\scripts
python run_bumeran_scraper.py

# Indeed
cd D:\OEDE\Webscrapping\01_sources\indeed\scripts
python indeed_scraper.py
python consolidar_indeed.py

# ZonaJobs
cd D:\OEDE\Webscrapping\01_sources\zonajobs\scripts
python zonajobs_scraper.py
python consolidar_zonajobs.py
```

### 2A. NLP Extraction - Regex (COMPLETADO âœ…)

```bash
cd D:\OEDE\Webscrapping\02.5_nlp_extraction\scripts

# Procesar cada fuente
python run_nlp_extraction.py --source all

# Consolidar
python consolidate_nlp_sources.py

# OUTPUT: all_sources_nlp_20251025_141134.csv âœ…
```

### 2B. NLP Extraction - NER (EN PROCESO â³)

```bash
cd D:\OEDE\Webscrapping\02.5_nlp_extraction\scripts

# 1. Preparar dataset âœ…
python prepare_ner_dataset.py

# 2. Anotar con Ollama â³ CORRIENDO AHORA (55%)
python auto_annotate_with_ollama.py --model llama3

# 3. Convertir a spaCy (despuÃ©s de anotaciÃ³n)
python convert_annotations_to_spacy.py \
    --input ../data/ner_training/ner_samples_*_ollama_annotated.jsonl

# 4. Entrenar modelo NER
python train_ner_model.py \
    --train-data ../data/ner_training/spacy_format/train_data.json \
    --dev-data ../data/ner_training/spacy_format/dev_data.json

# 5. Procesar dataset completo con NER
python -c "
from extractors.base_ner_extractor import BaseNERExtractor
import pandas as pd
df = pd.read_csv('../data/processed/all_sources_nlp_20251025_141134.csv')
extractor = BaseNERExtractor()
df_ner = extractor.process_dataframe(df)
df_ner.to_csv('../data/processed/all_sources_ner_YYYYMMDD.csv', index=False)
"

# 6. Comparar
python compare_phase1_vs_phase2.py \
    --phase1 ../data/processed/all_sources_nlp_20251025_141134.csv \
    --phase2 ../data/processed/all_sources_ner_YYYYMMDD.csv
```

### 3. ESCO Matching (EN BACKGROUND â³)

```bash
cd D:\OEDE\Webscrapping\03_esco_matching\scripts

python integrate_nlp_with_esco.py \
    --nlp-dataset ../../02.5_nlp_extraction/data/processed/all_sources_nlp_20251025_141134.csv \
    --esco-data "D:\Trabajos en PY\EPH-ESCO\07_esco_data\esco_ocupaciones_con_isco_completo.json" \
    --threshold 0.5

# OUTPUT: nlp_esco_enriched_*.csv
```

---

## ğŸ” CÃ³mo Encontrar Archivos

### Por Fase:

```bash
# FASE 1: Datos scrapeados
ls D:\OEDE\Webscrapping\01_sources\*/data\raw\

# FASE 2A: NLP Regex (ACTUAL)
ls D:\OEDE\Webscrapping\02.5_nlp_extraction\data\processed\all_sources_nlp_*.csv

# FASE 2B: NER training
ls D:\OEDE\Webscrapping\02.5_nlp_extraction\data\ner_training\

# FASE 2B: Modelo NER
ls D:\OEDE\Webscrapping\02.5_nlp_extraction\models\ner_model\

# FASE 3: ESCO matching
ls D:\OEDE\Webscrapping\03_esco_matching\output\
```

### Archivo Principal Actual:

```bash
# â­ ESTE ES EL ARCHIVO MÃS IMPORTANTE AHORA:
D:\OEDE\Webscrapping\02.5_nlp_extraction\data\processed\all_sources_nlp_20251025_141134.csv

# Contiene:
# - 8,472 ofertas de trabajo
# - 56 columnas (33 originales + 23 NLP)
# - ExtraÃ­das de Bumeran (2,460) + Indeed (6,009) + ZonaJobs (3)
# - Con campos NLP: experiencia, educaciÃ³n, skills, idiomas, etc.
```

---

## ğŸ“š DocumentaciÃ³n por Fase

| Fase | Documentos |
|------|------------|
| **General** | `MAPA_COMPLETO_DEL_PROYECTO.md` (este archivo) |
| **Scraping** | `01_sources/*/README.md` |
| **NLP Regex** | `02.5_nlp_extraction/docs/WEEK3_PROGRESS.md` |
| **NLP NER** | `02.5_nlp_extraction/docs/PHASE2_NER_WORKFLOW.md`<br>`USAR_OLLAMA_GRATIS.md`<br>`ANNOTATION_OPTIONS.md` |
| **ESCO** | `03_esco_matching/scripts/integrate_nlp_with_esco.py` (docstrings) |

---

## â“ FAQ

**P: Â¿CuÃ¡l es el archivo mÃ¡s actual con todos los datos?**
R: `02.5_nlp_extraction/data/processed/all_sources_nlp_20251025_141134.csv` (8,472 ofertas con NLP Regex)

**P: Â¿QuÃ© estoy ejecutando ahora mismo?**
R: AnotaciÃ³n automÃ¡tica con Ollama para entrenar modelo NER (Fase 2B, paso 2/6, 55% completado)

**P: Â¿CuÃ¡ntos registros tengo en total?**
R: 8,472 ofertas Ãºnicas de trabajo

**P: Â¿De dÃ³nde vienen esos 8,472?**
R: Bumeran (2,460) + Indeed (6,009) + ZonaJobs (3)

**P: Â¿QuÃ© columnas tiene el archivo principal?**
R: 56 columnas: ~33 originales (tÃ­tulo, descripciÃ³n, empresa, fecha, etc.) + 23 NLP (experiencia, educaciÃ³n, skills, etc.)

**P: Â¿CuÃ¡l es la diferencia entre NLP Regex y NLP NER?**
R:
- **Regex (Fase 2A):** Patrones fijos, 0.26 confidence, 29-40% cobertura âœ… HECHO
- **NER (Fase 2B):** Modelo ML entrenado, esperado 0.6 confidence, 60-70% cobertura â³ EN PROCESO

**P: Â¿Para quÃ© sirve ESCO Matching?**
R: Para clasificar cada oferta con un cÃ³digo ocupacional estÃ¡ndar (ESCO/ISCO), Ãºtil para anÃ¡lisis por ocupaciÃ³n

**P: Â¿CuÃ¡ndo estarÃ¡ todo terminado?**
R:
- AnotaciÃ³n Ollama: ~10 minutos
- Training NER: ~30 minutos
- Processing NER: ~15 minutos
- **Total:** ~1 hora desde ahora

---

**Creado:** 27 de Octubre, 2025
**Ãšltima actualizaciÃ³n:** Durante ejecuciÃ³n de anotaciÃ³n Ollama (55%)
