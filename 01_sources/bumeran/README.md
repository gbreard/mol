# Bumeran Scraper

## ğŸ¯ DescripciÃ³n

Scraper completo para Bumeran.com.ar que extrae ofertas laborales usando la API interna del sitio.

## ğŸ“Š Datos Clave

- **Ofertas disponibles**: ~12,000
- **MetodologÃ­a**: API REST directa
- **Campos extraÃ­dos**: 32 por oferta
- **Formato**: CSV, JSON, Excel

---

## ğŸ“ Estructura

```
bumeran/
â”œâ”€â”€ scrapers/
â”‚   â”œâ”€â”€ bumeran_scraper.py            # Scraper principal âœ…
â”‚   â”œâ”€â”€ bumeran_explorer.py           # Explorador tÃ©cnico
â”‚   â””â”€â”€ test_bumeran_api.py           # Tests de API
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/                          # Datos scrapeados
â”œâ”€â”€ config/
â”‚   â””â”€â”€ scraping.ini                  # ConfiguraciÃ³n
â””â”€â”€ README.md                         # Este archivo
```

---

## ğŸš€ Uso RÃ¡pido

### InstalaciÃ³n

```bash
cd 01_sources/bumeran
pip install requests pandas openpyxl
```

### Ejecutar Scraper

```bash
cd scrapers
python bumeran_scraper.py
```

Esto scrapearÃ¡:
- 100 ofertas generales
- 40 ofertas de "python"
- GuardarÃ¡ en CSV, JSON y Excel

---

## ğŸ’» Uso ProgramÃ¡tico

### Ejemplo BÃ¡sico

```python
from bumeran_scraper import BumeranScraper

# Crear scraper
scraper = BumeranScraper(delay_between_requests=2.0)

# Scrapear primeras 200 ofertas
ofertas = scraper.scrapear_todo(max_paginas=10, max_resultados=200)

# Guardar en todos los formatos
files = scraper.save_all_formats(ofertas)
```

### BÃºsqueda EspecÃ­fica

```python
# Buscar ofertas de Python
ofertas_python = scraper.scrapear_todo(
    max_paginas=5,
    max_resultados=100,
    query="python"
)

scraper.save_to_csv(ofertas_python, "bumeran_python.csv")
```

### Filtrado Local

```python
# Scrapear todas y filtrar despuÃ©s
todas = scraper.scrapear_todo(max_paginas=20)

# Filtrar por keyword
data_jobs = scraper.filtrar_local(todas, "data")
developer_jobs = scraper.filtrar_local(todas, "developer")
```

---

## ğŸ”§ API Descubierta

### Endpoint

```
POST https://www.bumeran.com.ar/api/avisos/searchV2
```

### Headers Necesarios

```python
headers = {
    'User-Agent': 'Mozilla/5.0...',
    'Accept': 'application/json',
    'Content-Type': 'application/json',
    'x-site-id': 'BMAR',  # Bumeran Argentina
    'x-pre-session-token': '{UUID}'  # Generar con uuid.uuid4()
}
```

### Payload

```json
{
  "pageSize": 20,       // Ofertas por pÃ¡gina (mÃ¡x: probablemente 100)
  "page": 0,           // PÃ¡gina (0-indexed)
  "sort": "RELEVANTES", // RELEVANTES, FECHA, etc.
  "query": "python"    // Opcional: bÃºsqueda por keyword
}
```

### Respuesta

```json
{
  "total": 12066,      // Total de ofertas disponibles
  "number": 0,         // NÃºmero de pÃ¡gina actual
  "size": 20,          // TamaÃ±o de pÃ¡gina
  "content": [...]     // Array de ofertas
}
```

---

## ğŸ“Š Campos Disponibles

### IdentificaciÃ³n
- `id`: ID Ãºnico de la oferta
- `id_empresa`: ID de la empresa

### InformaciÃ³n BÃ¡sica
- `titulo`: TÃ­tulo de la oferta
- `empresa`: Nombre de la empresa
- `detalle`: DescripciÃ³n HTML completa
- `confidencial`: Si la empresa es confidencial

### UbicaciÃ³n y Modalidad
- `localizacion`: "Ciudad, Provincia"
- `modalidad_trabajo`: Presencial/Remoto/HÃ­brido
- `tipo_trabajo`: Full-time/Part-time/etc.

### Fechas
- `fecha_publicacion`: DD-MM-YYYY
- `fecha_hora_publicacion`: DD-MM-YYYY HH:MM:SS
- `fecha_modificado`: DD-MM-YYYY HH:MM:SS

### Detalles
- `cantidad_vacantes`: NÃºmero de vacantes
- `apto_discapacitado`: Boolean

### Empresa
- `logo_url`: URL del logo
- `empresa_validada`: Boolean
- `empresa_pro`: Boolean
- `promedio_empresa`: Rating

### CategorizaciÃ³n
- `id_area`: Ãrea de trabajo
- `id_subarea`: SubÃ¡rea
- `id_pais`: PaÃ­s (1 = Argentina)

### Plan
- `plan_publicacion.id`: ID del plan
- `plan_publicacion.nombre`: Nombre del plan

### Otros
- `portal`: "bumeran"
- `tipo_aviso`: "simple", "talento", etc.
- `tiene_preguntas`: Boolean
- `salario_obligatorio`: Boolean

**Total**: 32+ campos

---

## âš™ï¸ ConfiguraciÃ³n

### ParÃ¡metros del Scraper

```python
scraper = BumeranScraper(
    delay_between_requests=2.0  # Segundos entre requests
)

scraper.scrapear_todo(
    max_paginas=10,        # MÃ¡ximo de pÃ¡ginas
    max_resultados=200,    # MÃ¡ximo de ofertas
    page_size=20,          # Ofertas por pÃ¡gina
    query=None             # Keyword de bÃºsqueda
)
```

### Rate Limiting

Por defecto: **2 segundos** entre requests.

RecomendaciÃ³n: No bajar de 1 segundo para evitar bloqueos.

---

## ğŸ“ˆ Performance

- **Velocidad**: ~20 ofertas/minuto (con delay 2s)
- **Recursos**: CPU < 5%, RAM ~50 MB
- **Almacenamiento**: ~3-4 KB por oferta

---

## ğŸ”„ IntegraciÃ³n con Pipeline

### ConsolidaciÃ³n

Las ofertas de Bumeran se normalizan automÃ¡ticamente al schema unificado:

```bash
cd ../../02_consolidation/scripts
python consolidar_fuentes.py --fuentes bumeran
```

Mapeo de campos:
- `id_oferta` â†’ `_metadata.source_id`
- `titulo` â†’ `informacion_basica.titulo`
- `localizacion` â†’ `ubicacion.ubicacion_raw` (parseado a provincia/ciudad)
- `modalidad_trabajo` â†’ `modalidad.modalidad_trabajo` (normalizado)
- etc.

### Pipeline Completo

```bash
cd ../..
python pipeline_completo.py --all --fuentes bumeran
```

Ejecuta:
1. Scraping (este scraper)
2. NormalizaciÃ³n
3. ESCO Matching
4. AnÃ¡lisis
5. Productos finales

---

## ğŸ§ª Tests

### Test de API

```bash
python test_bumeran_api.py
```

Prueba:
- âœ… ConexiÃ³n con API
- âœ… Headers correctos
- âœ… BÃºsqueda sin filtros
- âœ… BÃºsqueda con keyword
- âœ… PaginaciÃ³n

### Test del Scraper

```bash
python bumeran_scraper.py
```

Scrapea ofertas de ejemplo y guarda en todos los formatos.

---

## âš–ï¸ Consideraciones Legales

### âœ… Antes de Usar

1. Lee los [TÃ©rminos de Servicio](https://www.bumeran.com.ar/terminos-y-condiciones)
2. Verifica [robots.txt](https://www.bumeran.com.ar/robots.txt)
3. Implementa rate limiting (mÃ­nimo 2 segundos)
4. Usa User-Agent identificable
5. Solo para investigaciÃ³n/anÃ¡lisis personal

### LÃ­mites Recomendados

- **Delay mÃ­nimo**: 2 segundos
- **Ofertas por sesiÃ³n**: Hasta 1,000
- **Frecuencia**: No mÃ¡s de 1 vez por hora

---

## ğŸ› Troubleshooting

### Error 400: "No se incluyo el header x-site-id"

**SoluciÃ³n**: El scraper ya incluye este header automÃ¡ticamente. Si usas requests directamente, asegÃºrate de incluir:
```python
headers['x-site-id'] = 'BMAR'
headers['x-pre-session-token'] = str(uuid.uuid4())
```

### No se obtienen ofertas

**Problema**: El payload podrÃ­a estar mal formado.

**SoluciÃ³n**: Verifica que el JSON tenga `pageSize`, `page` y `sort`.

### Ofertas con descripciÃ³n HTML

**SoluciÃ³n**: La descripciÃ³n viene en HTML. Usa `_limpiar_html()` o procesa en normalizaciÃ³n.

---

## ğŸ“ Ejemplos de Uso

### Caso 1: AnÃ¡lisis del Mercado IT

```python
scraper = BumeranScraper()

# Keywords relevantes
keywords = ["python", "javascript", "data", "devops"]

resultados = {}
for keyword in keywords:
    ofertas = scraper.scrapear_todo(max_paginas=5, query=keyword)
    resultados[keyword] = len(ofertas)
    scraper.save_to_csv(ofertas, f"bumeran_{keyword}.csv")

print(resultados)
# {'python': 21, 'javascript': 45, 'data': 88, 'devops': 12}
```

### Caso 2: Ofertas Remotas

```python
todas = scraper.scrapear_todo(max_paginas=50, max_resultados=1000)

remotas = [
    o for o in todas
    if o.get('modalidadTrabajo') == 'Remoto'
]

print(f"Ofertas remotas: {len(remotas)}/{len(todas)}")
scraper.save_to_excel(remotas, "bumeran_remotas.xlsx")
```

### Caso 3: Por Provincia

```python
import pandas as pd

todas = scraper.scrapear_todo(max_paginas=100)
df = scraper.procesar_ofertas(todas)

# Agrupar por provincia
por_provincia = df.groupby('localizacion').size().sort_values(ascending=False)

print(por_provincia.head(10))
```

---

## ğŸ“š DocumentaciÃ³n Adicional

- [API Bumeran (descubierta)](../../docs/BUMERAN_API_DOCUMENTATION.md) *(pendiente)*
- [Schema Unificado](../../shared/schemas/SCHEMA_DOCUMENTATION.md)
- [Pipeline Completo](../../docs/arquitectura.md)

---

## ğŸ”— Enlaces Ãštiles

- [Bumeran Argentina](https://www.bumeran.com.ar)
- [TÃ©rminos de Servicio](https://www.bumeran.com.ar/terminos-y-condiciones)
- [robots.txt](https://www.bumeran.com.ar/robots.txt)

---

## ğŸ“Š EstadÃ­sticas

### Datos de ImplementaciÃ³n (2025-10-21)

- **Ofertas disponibles**: ~12,000
- **Ofertas scrapeadas (prueba)**: 140
- **Campos por oferta**: 32
- **Formatos de exportaciÃ³n**: CSV, JSON, Excel
- **Tiempo de implementaciÃ³n**: 3 horas

### Comparativa vs ZonaJobs

| MÃ©trica | Bumeran | ZonaJobs |
|---|---|---|
| Ofertas | ~12,000 | ~3,000 |
| MetodologÃ­a | API REST | API REST |
| Complejidad | Media | Media |
| Campos | 32 | 33 |

---

**Scraper implementado**: 2025-10-21
**VersiÃ³n**: 1.0
**Estado**: âœ… Funcional
**Mantenedor**: OEDE
