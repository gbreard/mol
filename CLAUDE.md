# MOL - Monitor de Ofertas Laborales

## LEER PRIMERO: Estado Actual

**ANTES DE HACER CUALQUIER COSA, leer `.ai/learnings.yaml` para el estado actual del trabajo.**

El archivo `learnings.yaml` contiene:
- `current_state`: QuÃ© estamos haciendo AHORA (ofertas, versiones, prÃ³ximo paso)
- `ultimo_trabajo`: QuÃ© se hizo en la Ãºltima sesiÃ³n
- `problemas_conocidos`: Issues actuales
- **`conteos`**: SINGLE SOURCE OF TRUTH para cantidades (reglas, skills, etc.)

**Comando del usuario: "GuardÃ¡ estado"** â†’ Ejecutar `python scripts/sync_learnings.py` + agregar notas en ultimo_trabajo si es necesario.

**AUTO-SYNC + REPORTE DE FASES (v2.0):** Al iniciar sesiÃ³n, Claude recibe automÃ¡ticamente:
- **Reporte de las 3 fases** con mÃ©tricas actuales (ofertas, NLP, matching, validaciÃ³n)
- **Sugerencia de fase** basada en quÃ© necesita atenciÃ³n (errores, pendientes, etc.)
- **Conteos actualizados** desde configs y BD

Triggers:
- **Al iniciar sesiÃ³n** â†’ Hook SessionStart (`.claude/settings.json`)
- Al ejecutar pipeline â†’ `sync_learnings_yaml()` al final
- Manual: `python scripts/sync_learnings.py` (con `--human` para formato detallado)

---

## Descripcion
Sistema de monitoreo del mercado laboral argentino para OEDE. Scrapea ofertas de empleo, extrae informacion con NLP, clasifica segun taxonomia ESCO, y provee dashboards para analistas.

## Estado Actual

> **CONTEOS OFICIALES:** Ver `.ai/learnings.yaml` secciÃ³n `conteos` (single source of truth)

- NLP v11.3 (20 campos + postprocessor + qwen2.5:7b)
- **Matching v3.4.2 ESCO-FIRST** - ESCO es target, ISCO se deriva
- **Conteos dinÃ¡micos** (ver `learnings.yaml`): reglas_negocio, reglas_validacion, sinonimos_argentinos
- **Auto-sync** de learnings.yaml activado (v1.0)

### Matching v3.4.2 ESCO-First (2026-01-21)
```
PRINCIPIO: ESCO es el TARGET, ISCO es CONSECUENCIA

FLUJO DE PRIORIDAD:
1. REGLAS DE NEGOCIO (si aplican) â†’ GANAN SIEMPRE
   - Buscan ocupaciÃ³n ESCO por label exacto
   - ISCO se deriva de la ocupaciÃ³n encontrada

2. DICCIONARIO ARGENTINO (si no hay regla)
   - Mapea tÃ©rminos argentinos a ISCO

3. SEMÃNTICO (fallback)
   - Skills + tÃ­tulo embeddings

METADATA GUARDADA:
- isco_semantico, score_semantico (siempre calculado)
- isco_regla, regla_aplicada (si aplica regla)
- dual_coinciden: 1=mismo, 0=difieren, NULL=solo semÃ¡ntico
- decision_metodo: "regla_prioridad" | "semantico_default"
```

### Trabajo en Curso
- Validando 110 ofertas para dashboard (prÃ³ximo paso: revisiÃ³n en Google Sheets)
- Gold Set de referencia: 49 casos (archivo histÃ³rico)

### Sistema de PriorizaciÃ³n v1.0 (2026-01-20)

El pipeline procesa ofertas **por prioridad**, no por orden de scraping.

**Criterios de scoring:**
| Criterio | Peso | LÃ³gica |
|----------|------|--------|
| Fecha publicaciÃ³n | 40% | MÃ¡s reciente = mayor score |
| Cantidad vacantes | 30% | MÃ¡s vacantes = mayor impacto |
| Permanencia | 30% | Baja permanencia = alta demanda |

**Tabla:** `ofertas_prioridad` (estados: pendiente â†’ en_proceso â†’ procesado)

**Comandos:**
```bash
# Ver estado de la cola
python scripts/get_priority_batch.py --queue-status

# Procesar lote de 100 por prioridad
python scripts/run_validated_pipeline.py --limit 100

# Ver prÃ³ximo lote sin procesar
python scripts/get_priority_batch.py --size 100
```

**Bloqueo por errores:** El sistema **NO avanza** al siguiente lote si hay errores pendientes.
```
Lote 1 â†’ 5 errores â†’ [BLOQUEADO] â†’ Resolver errores â†’ [DESBLOQUEADO] â†’ Lote 2
```

Para forzar (NO recomendado): `--force-new-batch`

---

## Modelo de 3 Fases

El proyecto se organiza en 3 macro-fases independientes:

| Fase | Descripcion | Ubicacion Principal | Salida |
|------|-------------|---------------------|--------|
| 1. Adquisicion | Scraping, deteccion bajas | `01_sources/`, `run_scheduler.py` | BD cruda |
| 2. Procesamiento | NLP, Skills, Matching, **Validacion** | `database/`, `config/`, `export_validation_excel.py` | Excel validacion + datos validados |
| 3. Presentacion | Dashboard (solo validados) | `fase3_dashboard/`, `Visual--/`, `sync_to_supabase.py` | Dashboard usuarios finales |

**Para trabajar en una fase especifica**, indicar en `learnings.yaml`:
```yaml
fase_actual: "procesamiento"  # adquisicion | procesamiento | presentacion
```

**REGLA:** Si modificas el pipeline de una fase, actualizar `docs/reference/ARQUITECTURA_3_FASES.md`.

> Arquitectura completa: `docs/reference/ARQUITECTURA_3_FASES.md`

---

## DocumentaciÃ³n Extendida

| Tema | Documento | CuÃ¡ndo leer |
|------|-----------|-------------|
| **Arquitectura 3 Fases** | `docs/reference/ARQUITECTURA_3_FASES.md` | Entender macro-estructura |
| **Colaboracion (multi-dev)** | `docs/guides/COLABORACION.md` | Trabajo en equipo, sync git |
| Pipeline completo (5 etapas) | `docs/reference/PIPELINE.md` | Entender flujo de datos |
| Run Tracking y Versionado | `docs/guides/RUN_TRACKING.md` | Comparar corridas |
| Sistema de ValidaciÃ³n | `docs/guides/VALIDACION.md` | Estados, protecciÃ³n datos |
| Flujos de OptimizaciÃ³n | `docs/guides/OPTIMIZACION.md` | Corregir errores NLP/Matching |
| SincronizaciÃ³n Supabase | `docs/guides/SUPABASE_SYNC.md` | Subir datos al dashboard |

**IMPORTANTE:** Antes de optimizar el pipeline, LEER `docs/guides/OPTIMIZACION.md`.

---

## Flujo de OptimizaciÃ³n â†’ ValidaciÃ³n Humana (v2.2)

El sistema tiene dos fases separadas:

```
FASE 1: OPTIMIZACIÃ“N (Claude)     FASE 2: VALIDACIÃ“N (Humano)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Claude itera:                     Solo cuando converge:
- Procesa lote                    - Recibe Excel
- Detecta errores                 - Revisa en Google Sheets
- Crea reglas en JSONs            - Marca OK/ERROR
- Reprocesa                       - Devuelve feedback
- Repite hasta tasa < 5%          - Aprueba o rechaza
```

### Estados de un Lote

| Estado | DescripciÃ³n | Siguiente acciÃ³n |
|--------|-------------|------------------|
| `optimizacion` | Claude iterando | Procesar, detectar errores, crear reglas |
| `listo_validacion` | Tasa < 5% (convergido) | Enviar a humano |
| `en_validacion` | Humano revisando | Esperar feedback |
| `validado` | Humano aprobÃ³ | Listo para producciÃ³n |
| `rechazado` | Humano pidiÃ³ mÃ¡s trabajo | Reabrir y continuar |

### Comandos del Flujo

```python
from scripts.run_tracking import RunTracker
tracker = RunTracker()

# 1. Crear lote
lote_id = tracker.create_batch("Lote 100 ofertas", offer_ids=[...])

# 2. Iterar (Claude optimiza)
while True:
    stats = run_matching_pipeline(offer_ids, source="optimizacion")
    tracker.add_run_to_batch(lote_id, stats['run_id'])

    result = tracker.check_convergence(lote_id)
    if result['convergido']:
        print(f"CONVERGIDO: Tasa {result['tasa']}% < 5%")
        break
    # ... detectar errores, crear reglas, reprocesar ...

# 3. Enviar a humano
tracker.send_to_human_validation(lote_id)  # Genera Excel

# 4. DespuÃ©s del feedback humano
tracker.complete_human_validation(lote_id, aprobado=True)  # o False

# Si rechazado, reabrir
tracker.reopen_batch_for_optimization(lote_id)
```

### Visualizar Estado

```bash
python scripts/show_learning_evolution.py --batches
```

---

## â›” PROHIBIDO IMPROVISAR - FLUJO OBLIGATORIO

**Claude: ANTES de ejecutar CUALQUIER comando, verificar este checklist:**

```
â–¡ 1. Â¿Existe un script para esto? â†’ USAR ESE SCRIPT
â–¡ 2. Â¿El script maneja dependencias (NLP antes de Matching)? â†’ CONFIAR EN Ã‰L
â–¡ 3. Â¿Necesito verificar algo? â†’ EL SCRIPT YA LO HACE
â–¡ 4. Â¿Quiero hacer una query manual? â†’ NO, USAR EL SCRIPT
```

### Flujo ÃšNICO para OptimizaciÃ³n (NO hay alternativa)

```bash
# PASO 1: Procesar ofertas (NLP + Matching + ValidaciÃ³n automÃ¡tica)
python scripts/run_validated_pipeline.py --limit 10

# PASO 2: Ver errores detectados
python scripts/review_offer_chain.py --errores --limit 5

# PASO 3: Si hay errores, crear regla en config/*.json correspondiente

# PASO 4: Reprocesar SOLO los IDs con error
python scripts/run_validated_pipeline.py --ids X,Y,Z

# PASO 5: Comparar
python scripts/compare_runs.py --latest

# PASO 6: Cuando converge, exportar Excel
python scripts/exports/export_validation_excel.py --etapa completo --ids X,Y,Z
```

### âŒ PROHIBIDO (durante ejecuciÃ³n del pipeline)

| AcciÃ³n | Por quÃ© estÃ¡ mal |
|--------|------------------|
| Queries manuales a BD para verificar estado | El script ya verifica |
| Ejecutar matching sin verificar NLP | `run_validated_pipeline` ya lo maneja |
| Crear scripts "demo" o "test" ad-hoc | Ya existen los scripts |
| Inventar pasos no documentados | Todo estÃ¡ en CLAUDE.md |
| Hacer verificaciones "por las dudas" | ConfiÃ¡ en el pipeline |

### âœ… PERMITIDO SIEMPRE

| AcciÃ³n | CuÃ¡ndo |
|--------|--------|
| Editar `config/*.json` | Para crear reglas nuevas |
| Leer archivos para entender cÃ³digo | Antes de modificar |
| Ejecutar scripts documentados | Siempre |

### âœ… PERMITIDO INTERVENIR MANUALMENTE cuando:

| SituaciÃ³n | QuÃ© hacer |
|-----------|-----------|
| **Usuario pide ver datos especÃ­ficos** | Queries a BD para mostrar lo que pide |
| **Diagnosticar error que el script no resuelve** | Investigar cadena completa (NLP â†’ Skills â†’ Matching) |
| **Crear regla nueva** | Consultar BD para ver ejemplos similares, entender el patrÃ³n |
| **Entender por quÃ© fallÃ³ algo** | Leer logs, ver datos de la oferta especÃ­fica |
| **Usuario pregunta "Â¿quÃ© pasÃ³ con X?"** | Investigar libremente |
| **Depurar un bug en el pipeline** | Queries diagnÃ³sticas, leer cÃ³digo |
| **Explorar para planificar** | Antes de ejecutar, entender el estado actual |

### ðŸ”‘ REGLA CLAVE

```
EJECUCIÃ“N DE PIPELINE â†’ Usar scripts, no improvisar
DIAGNÃ“STICO/INVESTIGACIÃ“N â†’ Intervenir manualmente estÃ¡ OK
CREAR REGLAS â†’ Necesito ver datos para entender el patrÃ³n
```

**Preguntarse:** Â¿Estoy EJECUTANDO el pipeline o estoy INVESTIGANDO/DIAGNOSTICANDO?
- Ejecutando â†’ Scripts Ãºnicamente
- Investigando â†’ Queries manuales OK

---

## REGLAS CRÃTICAS - LEER PRIMERO

**ANTES de escribir cÃ³digo o crear archivos:**

1. **LEER este CLAUDE.md COMPLETO** - todo estÃ¡ documentado aquÃ­
2. **NUNCA crear scripts nuevos** - buscar si ya existe uno para la tarea
3. **Cambios van en `config/*.json`** - no en cÃ³digo Python
4. **Si hay que modificar un `.py`**:
   - Versionar (ej: `v3.py` â†’ `v4.py`)
   - Archivar versiÃ³n anterior en `archive_old_versions/`
   - Actualizar CLAUDE.md

### Entry Points del Sistema (NO crear alternativas)

| Tarea | Comando | NO hacer |
|-------|---------|----------|
| **â­ Pipeline Completo** | `python scripts/run_validated_pipeline.py --limit 100` | Scripts separados |
| **NLP lote** | `python database/process_nlp_from_db_v11.py --ids X` | Crear script nuevo |
| **Scraping** | `python run_scheduler.py` | Llamar scrapers directo |
| **Comparar runs** | `python scripts/compare_runs.py --latest` | Crear comparador custom |
| **Validar ofertas** | `python scripts/validar_ofertas.py --ids X --estado validado` | UPDATE manual en BD |
| **Export Excel** | `python scripts/exports/export_validation_excel.py --etapa completo --ids X` | - |
| **Sync Supabase** | `python scripts/exports/sync_to_supabase.py` (incremental) | Queries directas a Supabase |
| **Sync Full** | `python scripts/exports/sync_to_supabase.py --full` | - |
| **Reapply Rules** | `python scripts/reapply_rules_to_validated.py` | Reprocesar validadas manualmente |

**â­ REGLA CRÃTICA - Pipeline Integrado:**
- **SIEMPRE** usar `run_validated_pipeline.py` para procesar ofertas
- Ejecuta TODO automÃ¡ticamente: Matching â†’ ValidaciÃ³n â†’ CorrecciÃ³n â†’ Reporte
- Errores se persisten en tabla `validation_errors` (no se pierden)
- Si hay errores que requieren reglas nuevas â†’ genera `metrics/cola_claude_*.json`

---

## Pipeline de ValidaciÃ³n con Aprendizaje (v2.0)

**Principio:** Claude REVISA casos individuales para APRENDER y crear REGLAS en JSONs.
El sistema luego aplica las reglas automÃ¡ticamente. Claude NO reemplaza al LLM.

### Cadena de Dependencias

```
SCRAPING â†’ NLP â†’ SKILLS â†’ MATCHING
              â†“       â†“         â†“
           tareas  extraÃ­das  ESCO code
           ubicaciÃ³n  de tareas+tÃ­tulo
           seniority
           Ã¡rea

Si NLP extrae mal las tareas â†’ Skills quedan mal â†’ Matching falla
```

### Flujo de Trabajo (UN COMANDO)

```
COMANDO ÃšNICO (hace TODO automÃ¡ticamente):
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
python scripts/run_validated_pipeline.py --limit 100

EJECUTA AUTOMÃTICAMENTE:
  1. MATCHING     â†’ match_ofertas_v3.py
  2. VALIDACIÃ“N   â†’ auto_validator.py (detecta errores â†’ BD)
  3. CORRECCIÃ“N   â†’ auto_corrector.py (arregla lo que puede â†’ BD)
  4. REPORTE      â†’ genera cola_claude.json si hay errores escalados

OPCIONES:
  --limit N          Procesar N ofertas
  --ids X,Y,Z        Procesar IDs especÃ­ficos
  --export-markdown  Generar validation/feedback_*.md para GitHub

RESULTADO:
  - Errores detectados â†’ tabla validation_errors (persistidos)
  - Errores corregidos â†’ marcados corregido=1 en BD
  - Errores escalados â†’ metrics/cola_claude_*.json + escalado_claude=1 en BD
```

### Si Hay Errores Escalados

```
CLAUDE REVISA cola_claude_*.json:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
python scripts/review_offer_chain.py --errores --limit 5

Claude ve TODA la cadena:
1. SCRAPING: Â¿Datos completos?
2. NLP: Â¿Tareas, ubicaciÃ³n, seniority, Ã¡rea correctos?
3. SKILLS: Â¿Coherentes con tÃ­tulo y tareas?
4. MATCHING: Â¿ISCO correcto?

CREAR REGLA segÃºn dÃ³nde fallÃ³:
| Falla en | Config a modificar |
|----------|-------------------|
| NLP - tareas | prompt o nlp_extraction_patterns.json |
| NLP - ubicaciÃ³n | config/nlp_preprocessing.json |
| NLP - seniority | config/nlp_inference_rules.json |
| NLP - Ã¡rea | config/nlp_inference_rules.json |
| Skills - faltan | config/skills_database.json |
| Matching | config/matching_rules_business.json |

REPROCESAR IDs afectados:
python scripts/run_validated_pipeline.py --ids X,Y,Z
```

### Archivos del Sistema de ValidaciÃ³n

| Archivo | FunciÃ³n |
|---------|---------|
| `scripts/run_validated_pipeline.py` | **â­ ENTRY POINT PRINCIPAL** - orquesta todo |
| `config/validation_rules.json` | Reglas de auto-detecciÃ³n (ver conteos en learnings.yaml) |
| `config/diagnostic_patterns.json` | Patrones para identificar punto de falla |
| `config/auto_correction_map.json` | Mapeo diagnÃ³stico â†’ config a modificar |
| `database/auto_validator.py` | Validador automÃ¡tico (persiste en BD) |
| `database/auto_corrector.py` | Corrector automÃ¡tico (actualiza BD) |
| `scripts/review_offer_chain.py` | **RevisiÃ³n UNO POR UNO** (cadena completa) |

### Tablas de ValidaciÃ³n en BD

| Tabla | FunciÃ³n |
|-------|---------|
| `validation_errors` | Errores detectados por auto_validator (persistidos) |
| `ofertas_esco_matching` | Estado de matching y validaciÃ³n |
| `pipeline_runs` | Historial de corridas |

**Consultas Ãºtiles:**
```sql
-- Errores pendientes (no resueltos)
SELECT * FROM v_errores_pendientes;

-- Resumen por tipo de error
SELECT * FROM v_errores_por_tipo;

-- Errores escalados a Claude
SELECT * FROM validation_errors WHERE escalado_claude = 1 AND resuelto = 0;
```

### Ejemplo de RevisiÃ³n Claude

```
Caso: "Gerente de Ventas" â†’ ISCO 2433 (incorrecto, deberÃ­a ser 1221)

Claude revisa cadena:
1. SCRAPING: OK
2. NLP: nivel_seniority = NULL âŒ (deberÃ­a ser "manager")
3. SKILLS: OK
4. MATCHING: Sin seniority, no priorizÃ³ nivel directivo

DiagnÃ³stico: Falla RAÃZ en NLP (seniority no inferido de "Gerente")

Claude crea reglas:
1. nlp_inference_rules.json: {"keyword": "gerente", "nivel_seniority": "manager"}
2. matching_rules_business.json: R_GERENTE_VENTAS â†’ forzar_isco 1221

Reprocesar â†’ ISCO correcto
PrÃ³xima vez: Sistema aplica regla automÃ¡ticamente
```

â†’ **Plan completo:** `/home/gerardo/.claude/plans/elegant-crunching-hippo.md`
â†’ **GuÃ­a optimizaciÃ³n:** `docs/guides/OPTIMIZACION.md`

---

### Flujo de OptimizaciÃ³n LEGACY (sin revisiÃ³n Claude)

```
1. PROCESAR    â†’ run_matching_pipeline(ids, source="gold_set")
2. EXPORTAR   â†’ export_validation_excel.py --ids X
3. CORREGIR   â†’ Modificar config/*.json (NO cÃ³digo Python)
4. COMPARAR   â†’ compare_runs.py --latest
5. REPETIR    â†’ Pasos 2-4 hasta que estÃ© OK
6. VALIDAR    â†’ validar_ofertas.py --ids X --estado validado
```

â†’ **Detalles:** `docs/guides/VALIDACION.md`

### Feedback Loop via Google Sheets

```
FLUJO:
1. Exportar   â†’ python scripts/exports/export_validation_excel.py --etapa completo --ids X
2. Subir      â†’ Excel a Google Sheets (manual)
3. Humano     â†’ Edita en Google Sheets (columnas resultado, isco_correcto, comentario)
4. Claude     â†’ Usuario comparte link/CSV, Claude lee y crea reglas
```

**Columnas editables por humano:**
- `resultado`: `OK` | `ERROR` | `REVISAR`
- `isco_correcto`: ISCO esperado (si es ERROR)
- `comentario`: DescripciÃ³n del problema

### ProtecciÃ³n de Datos Validados (v2.0 - 2026-01-20)

**REGLA ABSOLUTA:** Una oferta con `estado_validacion = 'validado'` NUNCA debe:
- Ser reprocesada por NLP
- Ser reprocesada por Matching
- Aparecer en Excel de validaciÃ³n nuevo

**Capas de protecciÃ³n:**

| Capa | UbicaciÃ³n | QuÃ© hace |
|------|-----------|----------|
| Query filtrada | `export_validation_excel.py:476` | Excluye validadas de selecciÃ³n |
| Query filtrada | `auto_validator.py:590` | Excluye validadas de validaciÃ³n |
| Error explÃ­cito | `match_ofertas_v3.py:1368` | Lanza ValueError si hay validadas |
| Trigger BD | `migrations/016_*.sql` | Bloquea UPDATE en ofertas validadas |

**Verificar protecciÃ³n:**
```bash
python scripts/check_validated_protection.py
```

**Si NECESITO reprocesar una oferta validada (caso excepcional):**
```bash
# 1. Desbloquear con justificaciÃ³n obligatoria
python scripts/admin_unlock_validated.py --ids 123,456 --motivo "RazÃ³n del desbloqueo"

# 2. Reprocesar normalmente
python scripts/run_validated_pipeline.py --ids 123,456
```

**NO hacer:**
- Usar `force=True` en el pipeline (bypasea controles)
- UPDATE directo a BD sin usar script admin
- Cambiar estado manualmente a 'pendiente'

---

## VERSIONES ACTUALES - USAR SIEMPRE ESTAS

### NLP Pipeline

| Componente | Archivo ACTUAL | NO USAR |
|------------|----------------|---------|
| Pipeline NLP | `database/process_nlp_from_db_v11.py` | v7, v8, v9, v10 |
| Prompt | `database/prompts/extraction_prompt_lite_v1.py` | v8, v9, v10 |
| Regex Patterns | `database/patterns/regex_patterns_v4.py` | v1, v2, v3 |
| Normalizador | `database/normalize_nlp_values.py` | - |

**Arquitectura v11.3:**
```
CAPA 0: Regex (salarios, jornada) + Scraping directo (modalidad)
CAPA 1: LLM Qwen2.5:7b (20 campos)
CAPA 2: Postprocessor (config/nlp_*.json)
CAPA 3: Skills implÃ­citas (BGE-M3 + ESCO embeddings)
```

### Matching Pipeline v3.4.2 ESCO-First

| Componente | Archivo ACTUAL | NO USAR |
|------------|----------------|---------|
| Pipeline Matching | `database/match_ofertas_v3.py` v3.4.2 | v2.py, v8.x |
| Matcher por Skills | `database/match_by_skills.py` v1.2.0 | - |
| Skills Extractor | `database/skills_implicit_extractor.py` v2.3 | - |
| Skills Rules Config | `config/skills_rules.json` (25 reglas) | - |
| Skills Rules Matcher | `database/skills_rules_matcher.py` | - |
| Diccionario Argentino | `config/sinonimos_argentinos_esco.json` (13 ocup) | - |
| Config reglas negocio | `config/matching_rules_business.json` (124 reglas con ESCO vÃ¡lido) | hardcodeados |
| Config principal | `config/matching_config.json` | - |

**Arquitectura v3.4.2 (orden de prioridad):**
```
PRINCIPIO: ESCO es TARGET, ISCO es CONSECUENCIA

1. REGLAS DE NEGOCIO (GANAN SIEMPRE si aplican)
   â””â”€â”€ Buscan ESCO label exacto â†’ derivan ISCO
        â†“ (si no hay regla)
2. DICCIONARIO ARGENTINO â† Vocabulario local â†’ ISCO
        â†“ (si no matchea)
3. SEMÃNTICO (BGE-M3) â† Skills 60% + Titulo 40%
        â†“
4. PENALIZACIONES (sector, seniority)
        â†“
5. PERSISTIR EN BD (con metadata dual: isco_semantico, isco_regla)
```

â†’ **Detalles:** `docs/reference/PIPELINE.md`

### Skills Dual System v2.3 (2026-01-22)

Sistema DUAL para extracciÃ³n de skills (mismo patrÃ³n que ISCO matching):
- **Reglas de skills** (prioridad) + **SemÃ¡ntico BGE-M3** (fallback)
- Guarda AMBOS resultados para comparaciÃ³n y mÃ©tricas

| Componente | Archivo | PropÃ³sito |
|------------|---------|-----------|
| Skills Rules Config | `config/skills_rules.json` | 25 reglas que fuerzan skills especÃ­ficas |
| Skills Rules Matcher | `database/skills_rules_matcher.py` | Evaluador de reglas |
| Skills Extractor | `database/skills_implicit_extractor.py` v2.3 | MÃ©todo `extract_skills_dual()` |

**Arquitectura Dual:**
```
1. Evaluar REGLAS DE SKILLS (skills_rules.json)
   â””â”€â”€ Si matchea â†’ skills_regla (prioridad)
        â†“
2. Extraer SEMÃNTICO (BGE-M3 siempre)
   â””â”€â”€ skills_semantico
        â†“
3. Comparar ambos
   â””â”€â”€ dual_coinciden_skills: 1=igual, 0=difieren, NULL=solo semÃ¡ntico
        â†“
4. Merge final
   â””â”€â”€ skills_final = skills_regla + skills_semantico Ãºnicos
```

**Columnas en BD (`ofertas_esco_matching`):**
- `skills_regla_json`: Skills forzadas por regla (JSON array)
- `skills_semantico_json`: Skills de BGE-M3 (JSON array)
- `skills_regla_aplicada`: ID de regla aplicada (ej: "RS02_contador")
- `dual_coinciden_skills`: 1=coinciden, 0=difieren, NULL=sin regla

**Reglas de ValidaciÃ³n (V24-V30):**
| Regla | Detecta | Severidad |
|-------|---------|-----------|
| V24 | Skills no coherentes con ISCO (< 30%) | alto |
| V25 | Tareas vacÃ­as pero skills presentes | medio |
| V26 | Formato tareas incorrecto (`,` vs `;`) | medio |
| V27 | Divergencia regla vs semÃ¡ntico | warning |
| V28 | Sin skills esenciales del ISCO | alto |
| V29 | Tareas muy cortas (< 50 chars) | bajo |
| V30 | Puesto IT sin skills tÃ©cnicas | alto |

**MÃ©tricas en sync_learnings.py:**
```
SKILLS DUAL (v2.3):
  Por regla: 45% | Por semantico: 55%
  Dual coinciden: 78%
  Skills promedio: 6.2/oferta
```

### Tests y Gold Sets

| Conjunto | UbicaciÃ³n | Casos | Uso |
|----------|-----------|-------|-----|
| **Ofertas en validaciÃ³n** | BD `ofertas_esco_matching` | **100** | Validar para dashboard |
| Gold Set referencia | `database/gold_set_manual_v2.json` | 49 | Test de regresiÃ³n |
| NLP Extraction | `tests/nlp/gold_set.json` | 20+ | Test NLP |

**IMPORTANTE:** El trabajo actual es sobre las **100 ofertas en validaciÃ³n**, no el Gold Set de 49.

```bash
# Ejecutar tests
python -m pytest tests/ -v

# Test Gold Set Matching (referencia)
pytest tests/matching/test_gold_set_manual.py -v

# Ver estado de las 100 ofertas en validaciÃ³n
python scripts/validar_ofertas.py --status
```

---

## ConfiguraciÃ³n

### Configs NLP (Postprocessor)

| Archivo | PropÃ³sito |
|---------|-----------|
| `config/nlp_preprocessing.json` | Parsing ubicaciÃ³n |
| `config/nlp_inference_rules.json` | Inferencia Ã¡rea/seniority/modalidad |
| `config/nlp_validation.json` | ValidaciÃ³n tipos |
| `config/nlp_extraction_patterns.json` | Regex experiencia |
| `config/nlp_normalization.json` | CABA â†’ Capital Federal |

### Configs Matching

| Archivo | PropÃ³sito |
|---------|-----------|
| `config/matching_config.json` | Pesos, umbrales, penalizaciones |
| `config/matching_rules_business.json` | Reglas de negocio (ver conteos en learnings.yaml) |
| `config/area_funcional_esco_map.json` | Mapeo Ã¡rea â†’ ISCO |
| `config/sector_isco_compatibilidad.json` | Compatibilidad sector-ISCO |

### Diccionarios

| Archivo | PropÃ³sito |
|---------|-----------|
| `config/skills_database.json` | ~320 skills tÃ©cnicas |
| `config/oficios_arg.json` | ~170 oficios argentinos |

---

## Comandos Clave

```bash
# === SCRAPING ===
python run_scheduler.py --test

# === NLP ===
python database/process_nlp_from_db_v11.py --ids 123,456

# === MATCHING ===
pytest tests/matching/test_gold_set_manual.py -v

# === VALIDACIÃ“N ===
python scripts/validar_ofertas.py --status
python scripts/compare_runs.py --list
python scripts/compare_runs.py --latest
python scripts/validar_ofertas.py --ids 123,456 --estado validado

# === EXPORT ===
python scripts/exports/export_validation_excel.py --etapa completo --ids X
```

---

## GuÃ­a RÃ¡pida: Mapeo Error â†’ Config

| Tipo de Error | Config a Editar |
|---------------|-----------------|
| Provincia/Localidad mal | `config/nlp_preprocessing.json` |
| Seniority incorrecto | `config/nlp_inference_rules.json` |
| Modalidad incorrecta | `config/nlp_inference_rules.json` |
| Ãrea funcional incorrecta | `config/nlp_inference_rules.json` |
| ISCO incorrecto para tÃ­tulo X | `config/matching_rules_business.json` |

â†’ **Tabla completa:** `docs/guides/OPTIMIZACION.md`

---

## Regla de Versionado

**OBLIGATORIO:** Cuando se crea una nueva versiÃ³n:

1. Crear nueva versiÃ³n (ej: `v11.py`)
2. Archivar anterior en `database/archive_old_versions/`
3. Verificar que nada importe el archivo archivado
4. Actualizar CLAUDE.md

**NUNCA** dejar dos versiones activas en el mismo directorio.

---

## UbicaciÃ³n de Scripts

| Si el script es para... | Va en... |
|-------------------------|----------|
| Gold Set NLP | `scripts/nlp/gold_set/` |
| Gold Set Matching | `scripts/matching/gold_set/` |
| Backup/migrate BD | `scripts/db/` |
| Exportar (S3, Excel) | `scripts/exports/` |
| Linear | `scripts/` (raÃ­z) |

**NUNCA** crear `test_*.py` fuera de `tests/`.

---

## Estructura del Proyecto (Resumen)

```
MOL/
â”œâ”€â”€ 01_sources/          # Scraping (bumeran/, zonajobs/, etc.)
â”œâ”€â”€ database/            # BD, NLP processors, matching
â”‚   â”œâ”€â”€ prompts/         # Prompts LLM
â”‚   â”œâ”€â”€ patterns/        # Regex patterns
â”‚   â””â”€â”€ archive_old_versions/
â”œâ”€â”€ config/              # JSONs de configuraciÃ³n
â”œâ”€â”€ tests/               # Tests pytest
â”œâ”€â”€ scripts/             # Utilidades
â”‚   â”œâ”€â”€ db/              # BD
â”‚   â”œâ”€â”€ nlp/gold_set/    # OptimizaciÃ³n NLP
â”‚   â”œâ”€â”€ matching/        # OptimizaciÃ³n Matching
â”‚   â””â”€â”€ exports/         # Exportaciones
â”œâ”€â”€ docs/                # DocumentaciÃ³n
â”‚   â”œâ”€â”€ guides/          # RUN_TRACKING, VALIDACION, OPTIMIZACION
â”‚   â””â”€â”€ reference/       # PIPELINE
â”œâ”€â”€ fase3_dashboard/     # Fase 3: Dashboard y presentaciÃ³n
â”‚   â”œâ”€â”€ nextjs/          # Dashboard Next.js (desarrollo)
â”‚   â””â”€â”€ docs/            # Docs especÃ­ficos Fase 3
â”œâ”€â”€ Visual--/            # Dashboard R Shiny (legacy)
â””â”€â”€ run_scheduler.py     # Entry point scraping
```

---

## Modelos LLM/ML

| Modelo | Uso |
|--------|-----|
| **Qwen2.5:7b** | NLP: extracciÃ³n semÃ¡ntica |
| **BGE-M3** | Matching: embeddings |
| **ChromaDB** | Skills lookup |

**Requisitos:**
- Ollama en `localhost:11434` con `qwen2.5:7b`
- ChromaDB con vectores en `database/esco_vectors/`

---

## Reglas de Desarrollo

1. **Scraping:** SIEMPRE `run_scheduler.py`, NUNCA scrapers directo
2. **Tests:** Todo cambio NLP/Matching debe pasar Gold Set
3. **Umbrales:** NLP >= 90%, Matching >= 95%
4. **Linear:** Usar cache (`scripts/linear_*.py`), NUNCA MCP directo

---

## Flujo de Branches

```
main                    â† ProducciÃ³n (solo via PR)
  â””â”€â”€ develop           â† IntegraciÃ³n (pasÃ³ Gold Set)
        â”œâ”€â”€ feature/optimization-nlp
        â””â”€â”€ feature/optimization-matching
```

**NUNCA** push directo a `main`. **SIEMPRE** Gold Set antes de merge.

---

## Colaboracion Multi-Desarrollador

Este proyecto es trabajado por **multiples personas en distintas fases**.

**LEER:** `docs/guides/COLABORACION.md` para reglas de sync, division de trabajo y referencias a documentacion oficial de Claude Code.

---

## AI Platform Local

Plataforma en `D:\AI_Platform`.

```python
import httpx
GATEWAY = "http://localhost:8080"
```

| Endpoint | DescripciÃ³n |
|----------|-------------|
| `POST /v1/chat/completions` | LLM |
| `POST /v1/embeddings` | Embeddings |

Docs: http://localhost:8080/docs

---

> **Ãšltima actualizaciÃ³n:** 2026-01-16
