# Fase 2 - NER Custom Models - Workflow Completo

**Fecha de inicio:** 27 de Octubre, 2025
**Estado:** Scripts preparados - Pendiente anotaciÃ³n manual
**Objetivo:** Mejorar extracciÃ³n mediante modelo NER custom entrenado con spaCy

---

## Ãndice

1. [Resumen Ejecutivo](#resumen-ejecutivo)
2. [Contexto: Fase 1 vs Fase 2](#contexto-fase-1-vs-fase-2)
3. [Pipeline Completo](#pipeline-completo)
4. [Paso 1: PreparaciÃ³n del Dataset](#paso-1-preparaciÃ³n-del-dataset)
5. [Paso 2: AnotaciÃ³n Manual](#paso-2-anotaciÃ³n-manual)
6. [Paso 3: ConversiÃ³n a spaCy](#paso-3-conversiÃ³n-a-spacy)
7. [Paso 4: Entrenamiento del Modelo](#paso-4-entrenamiento-del-modelo)
8. [Paso 5: Procesamiento con NER](#paso-5-procesamiento-con-ner)
9. [Paso 6: ComparaciÃ³n y EvaluaciÃ³n](#paso-6-comparaciÃ³n-y-evaluaciÃ³n)
10. [MÃ©tricas Esperadas](#mÃ©tricas-esperadas)
11. [Troubleshooting](#troubleshooting)

---

## Resumen Ejecutivo

La Fase 2 implementa un modelo **Named Entity Recognition (NER) custom** entrenado con spaCy para mejorar la extracciÃ³n de informaciÃ³n estructurada de ofertas laborales.

**Principales ventajas sobre Fase 1 (Regex):**
- Captura variaciones lingÃ¼Ã­sticas no cubiertas por patrones
- Aprende contexto semÃ¡ntico de las entidades
- Puede detectar skills tÃ©cnicas implÃ­citas
- Mayor precisiÃ³n en extracciÃ³n de aÃ±os de experiencia
- Mejor handling de requisitos con estructura no estÃ¡ndar

**Limitaciones:**
- Requiere anotaciÃ³n manual de 500 ofertas (~8-10 horas de trabajo)
- Necesita reentrenamiento para nuevos tipos de entidades
- Mayor complejidad de deployment

---

## Contexto: Fase 1 vs Fase 2

### Resultados Fase 1 (Regex) - Baseline

| MÃ©trica | Valor | Objetivo |
|---------|-------|----------|
| **Total ofertas procesadas** | 8,472 | âœ… Completo |
| **Confidence promedio** | 0.260 | ğŸŸ¡ Bajo (obj: 0.60) |
| **Cobertura Experiencia** | 29.2% | âŒ Bajo (obj: 60%) |
| **Cobertura EducaciÃ³n** | 38.6% | âŒ Bajo (obj: 70%) |
| **Cobertura Skills TÃ©cnicas** | 40.3% | ğŸŸ¡ Aceptable (obj: 70%) |
| **Cobertura Soft Skills** | 63.1% | âœ… Excelente |

### Objetivos Fase 2 (NER)

| MÃ©trica | Fase 1 | Objetivo Fase 2 | Mejora esperada |
|---------|--------|-----------------|-----------------|
| **Confidence** | 0.260 | 0.600 | +130% |
| **Cobertura Experiencia** | 29% | 60% | +107% |
| **Cobertura EducaciÃ³n** | 39% | 70% | +79% |
| **Cobertura Skills TÃ©cnicas** | 40% | 70% | +75% |
| **Precision** | ~60% | 85% | +42% |

---

## Pipeline Completo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      FASE 2 - NER WORKFLOW                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. PREPARACIÃ“N DEL DATASET (âœ… COMPLETADO)
   â”œâ”€ Input: all_sources_nlp_20251025_141134.csv (8,472 ofertas)
   â”œâ”€ Script: prepare_ner_dataset.py
   â””â”€ Output:
      â”œâ”€ ner_samples_for_annotation.jsonl (500 ofertas)
      â”œâ”€ ner_samples_for_annotation.csv
      â”œâ”€ iob_annotation_template.json
      â””â”€ ANNOTATION_GUIDE.md

2. ANOTACIÃ“N MANUAL (â³ PENDIENTE - 8-10 horas)
   â”œâ”€ Herramienta: Doccano o Label Studio
   â”œâ”€ Entidades: YEARS, EDUCATION, SKILL, SOFT_SKILL, LANGUAGE, AREA
   â”œâ”€ Anotadores: 1-2 personas
   â””â”€ Output: annotated_data.jsonl

3. CONVERSIÃ“N A SPACY (â³ PENDIENTE)
   â”œâ”€ Input: annotated_data.jsonl
   â”œâ”€ Script: convert_annotations_to_spacy.py
   â””â”€ Output:
      â”œâ”€ train_data.json (400 ejemplos, 80%)
      â”œâ”€ dev_data.json (100 ejemplos, 20%)
      â””â”€ label_scheme.json

4. ENTRENAMIENTO DEL MODELO (â³ PENDIENTE)
   â”œâ”€ Input: train_data.json, dev_data.json
   â”œâ”€ Script: train_ner_model.py
   â”œâ”€ Base model: es_core_news_sm (o blank)
   â”œâ”€ Hyperparams: 30 iter, batch 8, dropout 0.3, lr 0.001
   â””â”€ Output: models/ner_model/model_YYYYMMDD_HHMMSS/

5. PROCESAMIENTO CON NER (â³ PENDIENTE)
   â”œâ”€ Input: all_sources_nlp_20251025_141134.csv
   â”œâ”€ Script: base_ner_extractor.py
   â”œâ”€ Model: models/ner_model/latest/
   â””â”€ Output: all_sources_ner_YYYYMMDD_HHMMSS.csv

6. COMPARACIÃ“N Y EVALUACIÃ“N (â³ PENDIENTE)
   â”œâ”€ Input: Fase 1 CSV + Fase 2 CSV
   â”œâ”€ Script: compare_phase1_vs_phase2.py
   â””â”€ Output:
      â”œâ”€ phase1_vs_phase2_comparison.json
      â””â”€ phase1_vs_phase2_comparison.md
```

---

## Paso 1: PreparaciÃ³n del Dataset

### âœ… Estado: COMPLETADO

**Objetivo:** Seleccionar 500 ofertas representativas para anotaciÃ³n manual.

### Script ejecutado

```bash
python prepare_ner_dataset.py --n-samples 500 --format both
```

### Resultados

- **Total seleccionadas:** 500 ofertas
- **DistribuciÃ³n por fuente:**
  - Indeed: 353 ofertas (70.6%)
  - Bumeran: 145 ofertas (29.0%)
  - ZonaJobs: 2 ofertas (0.4%)

- **EstratificaciÃ³n por riqueza NLP:**
  - Alta (4-5 campos): 40%
  - Media (2-3 campos): 40%
  - Baja (0-1 campos): 20%

### Archivos generados

```
02.5_nlp_extraction/data/ner_training/
â”œâ”€â”€ ner_samples_for_annotation_20251027_101013.jsonl  (1.3 MB)
â”œâ”€â”€ ner_samples_for_annotation_20251027_101013.csv    (1.3 MB)
â”œâ”€â”€ iob_annotation_template.json
â””â”€â”€ ANNOTATION_GUIDE.md
```

---

## Paso 2: AnotaciÃ³n Manual

### â³ Estado: PENDIENTE

**Objetivo:** Anotar manualmente 500 ofertas con entidades NER.

### Tipos de Entidades

| Entidad | DescripciÃ³n | Ejemplos |
|---------|-------------|----------|
| **YEARS** | AÃ±os de experiencia | "3 aÃ±os", "mÃ­nimo 5 aÃ±os", "2 a 4 aÃ±os" |
| **EDUCATION** | Nivel educativo / tÃ­tulo | "universitario completo", "licenciatura en sistemas" |
| **SKILL** | Habilidad tÃ©cnica | "Python", "Django", "SQL", "AWS" |
| **SOFT_SKILL** | Habilidad blanda | "trabajo en equipo", "liderazgo" |
| **LANGUAGE** | Idioma y nivel | "inglÃ©s avanzado", "portuguÃ©s intermedio" |
| **AREA** | Ãrea de experiencia | "desarrollo backend", "anÃ¡lisis de datos" |

### Herramientas Recomendadas

#### OpciÃ³n 1: Doccano (Recomendado)

**InstalaciÃ³n:**
```bash
pip install doccano
doccano init
doccano createuser --username admin --password admin
doccano webserver --port 8000
```

**Uso:**
1. Acceder a http://localhost:8000
2. Login con admin/admin
3. Crear proyecto "NER Job Offers"
4. Importar `ner_samples_for_annotation.jsonl`
5. Definir labels: YEARS, EDUCATION, SKILL, SOFT_SKILL, LANGUAGE, AREA
6. Anotar ofertas
7. Exportar como JSONL

#### OpciÃ³n 2: Label Studio

**InstalaciÃ³n:**
```bash
pip install label-studio
label-studio start
```

**Uso:**
1. Acceder a http://localhost:8080
2. Crear proyecto "NER Job Offers"
3. Configurar interfaz de Named Entity Recognition
4. Importar CSV o JSONL
5. Anotar
6. Exportar como JSON

### Tiempo Estimado

- **Tiempo por oferta:** 1-2 minutos
- **Total 500 ofertas:** 8-16 horas
- **Recomendado:** 2 anotadores Ã— 4-8 horas = 8-16 horas totales

### GuÃ­as de AnotaciÃ³n

Ver `ANNOTATION_GUIDE.md` para:
- Reglas de anotaciÃ³n detalladas
- Ejemplos por tipo de entidad
- Casos especiales y ambigÃ¼edades
- Formato IOB explicado

---

## Paso 3: ConversiÃ³n a spaCy

### â³ Estado: PENDIENTE (despuÃ©s de anotaciÃ³n)

**Objetivo:** Convertir anotaciones a formato de entrenamiento de spaCy.

### Script

```bash
python convert_annotations_to_spacy.py \
    --input annotated_data.jsonl \
    --format doccano \
    --dev-ratio 0.2 \
    --seed 42
```

### ParÃ¡metros

- `--input`: Archivo JSONL exportado de Doccano/Label Studio
- `--format`: Formato del archivo (`doccano` o `labelstudio`)
- `--dev-ratio`: ProporciÃ³n para validation set (default: 0.2 = 20%)
- `--seed`: Seed para reproducibilidad

### Output Esperado

```
02.5_nlp_extraction/data/ner_training/spacy_format/
â”œâ”€â”€ train_data.json       (400 ejemplos, 80%)
â”œâ”€â”€ dev_data.json         (100 ejemplos, 20%)
â””â”€â”€ label_scheme.json     (esquema de etiquetas)
```

### Validaciones AutomÃ¡ticas

El script valida:
- âœ… No hay anotaciones superpuestas
- âœ… `start < end` para todas las entidades
- âœ… Todas las entidades tienen texto asociado
- âœ… Balance de clases (warnings si alguna entidad <5% del total)

---

## Paso 4: Entrenamiento del Modelo

### â³ Estado: PENDIENTE (despuÃ©s de conversiÃ³n)

**Objetivo:** Entrenar modelo NER custom con spaCy.

### Prerrequisitos

```bash
# Instalar spaCy y modelo espaÃ±ol base
pip install spacy
python -m spacy download es_core_news_sm
```

### Script de Entrenamiento

```bash
python train_ner_model.py \
    --train-data data/ner_training/spacy_format/train_data.json \
    --dev-data data/ner_training/spacy_format/dev_data.json \
    --base-model es_core_news_sm \
    --n-iter 30 \
    --batch-size 8 \
    --dropout 0.3 \
    --learn-rate 0.001 \
    --seed 42
```

### Hyperparameters

| ParÃ¡metro | Valor | DescripciÃ³n |
|-----------|-------|-------------|
| `--n-iter` | 30 | NÃºmero de epochs |
| `--batch-size` | 8 | TamaÃ±o de batch |
| `--dropout` | 0.3 | Dropout rate (previene overfitting) |
| `--learn-rate` | 0.001 | Learning rate inicial |
| `--base-model` | es_core_news_sm | Modelo base (o blank) |

### Proceso de Entrenamiento

El script:
1. Carga modelo base de spaCy
2. Agrega componente NER con tipos de entidades custom
3. Entrena durante N iteraciones
4. EvalÃºa cada 5 iteraciones en dev set
5. Reporta mÃ©tricas (Precision, Recall, F-score)
6. Guarda modelo entrenado

### Output Esperado

```
02.5_nlp_extraction/models/ner_model/
â”œâ”€â”€ model_20251027_150000/
â”‚   â”œâ”€â”€ config.cfg
â”‚   â”œâ”€â”€ meta.json
â”‚   â”œâ”€â”€ metadata.json        (custom metadata)
â”‚   â”œâ”€â”€ ner/
â”‚   â”œâ”€â”€ tokenizer
â”‚   â””â”€â”€ vocab/
â””â”€â”€ latest -> model_20251027_150000  (symlink)
```

### MÃ©tricas Durante Entrenamiento

```
Iter   1 | Loss: 45.2314
Iter   2 | Loss: 38.4521
Iter   3 | Loss: 32.1234
Iter   4 | Loss: 27.8945
Iter   5 | Loss: 24.5612 | P: 0.723 | R: 0.651 | F: 0.685
...
Iter  30 | Loss: 8.2341 | P: 0.857 | R: 0.823 | F: 0.840
```

**Valores deseados al final:**
- Precision (P): > 0.85
- Recall (R): > 0.80
- F-score (F): > 0.82

---

## Paso 5: Procesamiento con NER

### â³ Estado: PENDIENTE (despuÃ©s de entrenamiento)

**Objetivo:** Procesar dataset completo con modelo NER entrenado.

### Script de Procesamiento

```bash
# Procesar con modelo NER
python -c "
from extractors.base_ner_extractor import BaseNERExtractor
import pandas as pd

# Cargar dataset Fase 1
df = pd.read_csv('data/processed/all_sources_nlp_20251025_141134.csv')

# Crear extractor NER (usa modelo latest automÃ¡ticamente)
extractor = BaseNERExtractor()

# Procesar
df_ner = extractor.process_dataframe(
    df,
    descripcion_col='descripcion',
    titulo_col='titulo'
)

# Guardar
df_ner.to_csv('data/processed/all_sources_ner_20251027.csv', index=False)

# Stats
stats = extractor.get_extraction_stats(df_ner)
print(stats)
"
```

### Output Esperado

```
02.5_nlp_extraction/data/processed/
â””â”€â”€ all_sources_ner_20251027_HHMMSS.csv  (~30 MB)
```

### Nuevas Columnas Agregadas

AdemÃ¡s de las columnas de Fase 1, se agregan:
- `ner_confidence_score`: Score de confianza NER
- `ner_processed_at`: Timestamp de procesamiento
- `ner_model`: Nombre del modelo usado

**Nota:** Los campos extraÃ­dos (experiencia, educaciÃ³n, skills, etc.) se sobrescriben con los valores del modelo NER.

---

## Paso 6: ComparaciÃ³n y EvaluaciÃ³n

### â³ Estado: PENDIENTE (despuÃ©s de procesamiento)

**Objetivo:** Comparar resultados Fase 1 vs Fase 2 y evaluar mejora.

### Script de ComparaciÃ³n

```bash
python compare_phase1_vs_phase2.py \
    --phase1 data/processed/all_sources_nlp_20251025_141134.csv \
    --phase2 data/processed/all_sources_ner_20251027.csv \
    --output-dir reports/
```

### Reportes Generados

```
02.5_nlp_extraction/reports/
â”œâ”€â”€ phase1_vs_phase2_comparison_YYYYMMDD_HHMMSS.json
â””â”€â”€ phase1_vs_phase2_comparison_YYYYMMDD_HHMMSS.md
```

### MÃ©tricas Analizadas

1. **Cobertura por campo:**
   - Experiencia, EducaciÃ³n, Skills, Idiomas, etc.
   - ComparaciÃ³n Fase 1 vs Fase 2
   - Delta absoluto y porcentual

2. **Confidence scores:**
   - Promedio Fase 1 vs Fase 2
   - Por fuente (Bumeran, Indeed, ZonaJobs)

3. **AnÃ¡lisis de mejoras:**
   - NÂ° de ofertas mejoradas (mÃ¡s campos extraÃ­dos)
   - NÂ° de ofertas sin cambio
   - NÂ° de ofertas empeoradas

4. **ComparaciÃ³n por fuente:**
   - MÃ©tricas separadas por fuente
   - Identificar quÃ© fuente se beneficiÃ³ mÃ¡s del NER

### Formato del Reporte Markdown

```markdown
# ComparaciÃ³n Fase 1 (Regex) vs Fase 2 (NER)

## Resumen Ejecutivo
- Total ofertas: 8,472
- Ofertas mejoradas: 3,456 (40.8%)
- Ofertas sin cambio: 4,012 (47.4%)
- Ofertas empeoradas: 1,004 (11.8%)

## ComparaciÃ³n de Cobertura
| Campo | Fase 1 | Fase 2 | Î” | Mejora |
|-------|--------|--------|---|--------|
| Experiencia | 29.2% | 58.3% | +29.1% | âœ… |
| EducaciÃ³n | 38.6% | 67.2% | +28.6% | âœ… |
| Skills tÃ©cnicas | 40.3% | 68.9% | +28.6% | âœ… |
...
```

---

## MÃ©tricas Esperadas

### Escenarios de Ã‰xito

| MÃ©trica | Actual (Fase 1) | Conservador | Optimista | Realista |
|---------|----------------|-------------|-----------|----------|
| **Confidence** | 0.260 | 0.450 | 0.650 | 0.550 |
| **Cob. Experiencia** | 29% | 50% | 70% | 58% |
| **Cob. EducaciÃ³n** | 39% | 60% | 80% | 68% |
| **Cob. Skills** | 40% | 60% | 80% | 67% |
| **Precision** | ~60% | 75% | 90% | 82% |

### Criterios de Ã‰xito

#### âœ… Ã‰xito Total
- Confidence > 0.60
- Cobertura promedio > 65%
- Precision > 85%
- Mejora >30% en al menos 4 campos

#### ğŸŸ¡ Ã‰xito Parcial
- Confidence > 0.45
- Cobertura promedio > 55%
- Precision > 75%
- Mejora >20% en al menos 3 campos

#### âŒ No Alcanza Expectativas
- Confidence < 0.40
- Cobertura promedio < 50%
- Precision < 70%
- Mejora <15% en mayorÃ­a de campos

### Consideraciones de Costo-Beneficio

| Aspecto | Fase 1 (Regex) | Fase 2 (NER) |
|---------|----------------|--------------|
| **Tiempo desarrollo** | 3 semanas | +2 semanas |
| **Tiempo anotaciÃ³n** | 0 horas | 8-16 horas |
| **Costo computacional** | Muy bajo | Bajo-Medio |
| **Mantenibilidad** | FÃ¡cil (editar regex) | Media (reentrenar modelo) |
| **Escalabilidad** | Media | Alta |
| **Accuracy esperada** | 60-65% | 80-85% |

**RecomendaciÃ³n:** Fase 2 justificada si:
1. Mejora > 25% en cobertura promedio
2. Precision > 80%
3. Se planea escalar a mÃ¡s fuentes/campos

---

## Troubleshooting

### Problema: Modelo NER no mejora durante entrenamiento

**SÃ­ntomas:**
- Loss no disminuye despuÃ©s de primeras iteraciones
- F-score en dev set < 0.50

**Posibles causas y soluciones:**

1. **Datos de entrenamiento insuficientes**
   - SoluciÃ³n: Anotar mÃ¡s ofertas (750-1000 en vez de 500)
   - O: Usar data augmentation

2. **Anotaciones inconsistentes**
   - SoluciÃ³n: Revisar guÃ­a de anotaciÃ³n
   - Verificar IAA (Inter-Annotator Agreement) si hay mÃºltiples anotadores
   - Reconciliar discrepancias

3. **Hyperparameters inadecuados**
   - SoluciÃ³n: Probar diferentes combinaciones:
     ```bash
     # MÃ¡s iteraciones
     --n-iter 50

     # Dropout mÃ¡s bajo (si overfitting)
     --dropout 0.2

     # Learning rate mÃ¡s bajo (si loss oscila)
     --learn-rate 0.0005
     ```

4. **Desbalance de clases**
   - SoluciÃ³n: Verificar distribuciÃ³n de entidades
   - Asegurar al menos 50 ejemplos por tipo de entidad

### Problema: Modelo overfittea

**SÃ­ntomas:**
- Loss en train muy bajo (<5) pero en dev alto (>20)
- F-score en train >0.90 pero en dev <0.60

**Soluciones:**
- Aumentar dropout: `--dropout 0.4` o `0.5`
- Reducir n_iter: `--n-iter 20`
- Agregar mÃ¡s datos de entrenamiento

### Problema: Entidades no detectadas en producciÃ³n

**SÃ­ntomas:**
- Modelo detecta pocas o ninguna entidad en nuevas ofertas
- Cobertura similar o peor que Fase 1

**Posibles causas:**
1. **Desajuste train/producciÃ³n:**
   - Ofertas de producciÃ³n muy diferentes a las anotadas
   - SoluciÃ³n: Revisar distribuciÃ³n de samples en Step 1

2. **Umbral de confianza muy alto:**
   - spaCy puede estar filtrando entidades con baja confianza
   - SoluciÃ³n: Ajustar threshold en el modelo

3. **TokenizaciÃ³n inconsistente:**
   - Textos con caracteres especiales mal manejados
   - SoluciÃ³n: Mejorar limpieza de texto en preprocessing

### Problema: Tiempo de procesamiento muy lento

**SÃ­ntomas:**
- Procesar 8,472 ofertas toma >1 hora
- CPU/GPU al 100% constante

**Soluciones:**
1. **Usar batch processing:**
   ```python
   # En vez de doc = nlp(text)
   docs = nlp.pipe(texts, batch_size=50)
   ```

2. **Deshabilitar pipes innecesarios:**
   ```python
   nlp = spacy.load(model_path, disable=['parser', 'tagger'])
   ```

3. **Usar GPU si disponible:**
   ```bash
   pip install spacy[cuda]
   spacy.require_gpu()
   ```

### Problema: Doccano/Label Studio no carga el JSONL

**SÃ­ntomas:**
- Error al importar archivo
- "Invalid format"

**Soluciones:**
1. Verificar encoding UTF-8
2. Verificar formato JSONL (un objeto por lÃ­nea)
3. Usar herramienta alternativa o formato CSV

---

## PrÃ³ximos Pasos (Post Fase 2)

### Fase 3: LLM Enhancement (Opcional)

Si Fase 2 no alcanza objetivos o se quiere maximizar accuracy:

1. **LLM Few-shot prompting:**
   - Usar GPT-4 / Claude con ejemplos anotados
   - Mayor accuracy pero mÃ¡s costoso

2. **Ensemble Regex + NER + LLM:**
   - Combinar predicciones de los 3 mÃ©todos
   - Maximizar recall (Regex) + precision (NER) + contexto (LLM)

3. **Fine-tuning de LLM:**
   - Fine-tune BERT/RoBERTa en espaÃ±ol para task especÃ­fico
   - Mejor que NER vanilla pero mÃ¡s complejo

### Mejoras Incrementales

- **Agregar mÃ¡s tipos de entidades:** Salario, Jornada, UbicaciÃ³n
- **Named Entity Linking:** Mapear skills a taxonomÃ­a estandarizada
- **NormalizaciÃ³n:** "Python" = "python" = "PYTHON"
- **Relaciones entre entidades:** "5 aÃ±os de Python" â†’ (YEARS=5, SKILL=Python)

---

## Archivos del Proyecto

### Scripts Creados (Fase 2)

```
02.5_nlp_extraction/scripts/
â”œâ”€â”€ prepare_ner_dataset.py                    (âœ… 320 lÃ­neas)
â”œâ”€â”€ convert_annotations_to_spacy.py           (âœ… 280 lÃ­neas)
â”œâ”€â”€ train_ner_model.py                        (âœ… 420 lÃ­neas)
â”œâ”€â”€ compare_phase1_vs_phase2.py               (âœ… 380 lÃ­neas)
â””â”€â”€ extractors/
    â””â”€â”€ base_ner_extractor.py                 (âœ… 480 lÃ­neas)
```

**Total Fase 2:** ~1,880 lÃ­neas de cÃ³digo

### DocumentaciÃ³n

```
02.5_nlp_extraction/docs/
â”œâ”€â”€ WEEK3_PROGRESS.md                         (Fase 1 completada)
â”œâ”€â”€ PHASE2_NER_WORKFLOW.md                    (Este documento)
â””â”€â”€ ANNOTATION_GUIDE.md                       (GuÃ­a para anotadores)
```

### Estructura de Directorios

```
02.5_nlp_extraction/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ extractors/
â”‚   â”‚   â”œâ”€â”€ base_nlp_extractor.py            (Fase 1)
â”‚   â”‚   â”œâ”€â”€ base_ner_extractor.py            (Fase 2)
â”‚   â”‚   â”œâ”€â”€ bumeran_extractor.py
â”‚   â”‚   â”œâ”€â”€ zonajobs_extractor.py
â”‚   â”‚   â””â”€â”€ indeed_extractor.py
â”‚   â”œâ”€â”€ patterns/
â”‚   â”‚   â””â”€â”€ regex_patterns.py
â”‚   â”œâ”€â”€ prepare_ner_dataset.py               (Fase 2)
â”‚   â”œâ”€â”€ convert_annotations_to_spacy.py      (Fase 2)
â”‚   â”œâ”€â”€ train_ner_model.py                   (Fase 2)
â”‚   â”œâ”€â”€ compare_phase1_vs_phase2.py          (Fase 2)
â”‚   â”œâ”€â”€ run_nlp_extraction.py                (Fase 1)
â”‚   â””â”€â”€ consolidate_nlp_sources.py           (Fase 1)
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ processed/
â”‚   â”‚   â”œâ”€â”€ all_sources_nlp_*.csv            (Fase 1 output)
â”‚   â”‚   â””â”€â”€ all_sources_ner_*.csv            (Fase 2 output)
â”‚   â””â”€â”€ ner_training/
â”‚       â”œâ”€â”€ ner_samples_for_annotation.jsonl
â”‚       â”œâ”€â”€ ner_samples_for_annotation.csv
â”‚       â”œâ”€â”€ iob_annotation_template.json
â”‚       â””â”€â”€ spacy_format/                    (post-conversiÃ³n)
â”‚           â”œâ”€â”€ train_data.json
â”‚           â”œâ”€â”€ dev_data.json
â”‚           â””â”€â”€ label_scheme.json
â”œâ”€â”€ models/
â”‚   â””â”€â”€ ner_model/
â”‚       â”œâ”€â”€ model_YYYYMMDD_HHMMSS/
â”‚       â””â”€â”€ latest/                          (symlink)
â”œâ”€â”€ config/
â”‚   â””â”€â”€ skills_database.json
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ WEEK3_PROGRESS.md
â”‚   â”œâ”€â”€ PHASE2_NER_WORKFLOW.md
â”‚   â””â”€â”€ ANNOTATION_GUIDE.md
â””â”€â”€ reports/                                  (Fase 2 comparisons)
    â”œâ”€â”€ phase1_vs_phase2_comparison.json
    â””â”€â”€ phase1_vs_phase2_comparison.md
```

---

## ConclusiÃ³n

### Estado Actual

âœ… **Scripts preparados y testeados**
âœ… **Dataset de 500 ofertas seleccionado estratificadamente**
âœ… **GuÃ­as de anotaciÃ³n creadas**
âœ… **Pipeline completo documentado**

â³ **Pendiente:**
1. AnotaciÃ³n manual (8-16 horas)
2. ConversiÃ³n a spaCy
3. Entrenamiento
4. EvaluaciÃ³n

### Esfuerzo Estimado

| Actividad | Tiempo | Responsable |
|-----------|--------|-------------|
| AnotaciÃ³n (500 ofertas) | 8-16 h | Anotador(es) |
| ConversiÃ³n + Training | 1-2 h | AutomÃ¡tico |
| Procesamiento dataset | 30 min | AutomÃ¡tico |
| AnÃ¡lisis resultados | 2-3 h | Analista |
| **TOTAL** | **12-22 h** | |

### RecomendaciÃ³n

**Proceder con Fase 2 si:**
- Hay presupuesto para 8-16 horas de anotaciÃ³n
- Los resultados de Fase 1 no son suficientes (cobertura <40%)
- Se planea usar el sistema en producciÃ³n (justifica inversiÃ³n)

**Considerar alternativas si:**
- Presupuesto limitado â†’ Mejorar patrones Regex primero
- Necesidad urgente â†’ Usar LLM few-shot (sin training)
- Datos insuficientes â†’ Anotar mÃ¡s ofertas o usar transfer learning

---

**Autor:** Claude Code
**Fecha:** 27 de Octubre, 2025
**VersiÃ³n:** 1.0
